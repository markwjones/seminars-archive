CREATE TABLE `seminar` (
  `seminarno` int(11) NOT NULL DEFAULT 0,
  `date` date NOT NULL DEFAULT '0000-00-00',
  `time` text NOT NULL,
  `place` text NOT NULL,
  `speaker` text NOT NULL,
  `speakerurl` text DEFAULT NULL,
  `institution` text DEFAULT NULL,
  `institutionurl` text DEFAULT NULL,
  `title` text DEFAULT NULL,
  `abstract` text DEFAULT NULL,
  `series` int(11) DEFAULT NULL,
  `photo` text DEFAULT NULL,
  PRIMARY KEY (`seminarno`)
);
INSERT INTO `seminar` VALUES (6,'2005-11-01','14:00','Robert Recorde Room','Neil Ghani','http://www.cs.nott.ac.uk/~nxg/','Nottingham','http://www.cs.nott.ac.uk/','Containers 2',' Containers were introduced to represent a calculus of concrete datatypes - more powerful than the usual polynomial functors, but without the problems of mixed variance datatypes or definitions by impredicativity.\r\n\r\nIn this talk I will recap this research and then introduce the latest developments from the East Midlands Container Corporation - Containers 2. Remarkably, for a small extension of the container paradigm, we get a significant increase in both the beauty, expressiveness and applicativity of the theory of containers. My talk will bring these ideas to the fore and will be of a high level overview.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Ghani,sq,n.jpg');

INSERT INTO `seminar` VALUES (5,'2005-10-25','14:00','Robert Recorde Room','Michael Harrison','http://www.cs.ncl.ac.uk/people/home.php?id=387','Newcastle upon Tyne','http://www.cs.ncl.ac.uk/','Analysing context in interactive systems','Mobility of ubiquitous systems offers the possibility of using the current context to infer information that might otherwise require user input. This can either make user interfaces more intuitive or cause subtle and confusing mode changes.\r\n\r\nThis talk aims to discuss the analysis of such systems to enable the designer to predict potential pitfalls before the design is fielded. Whereas the current predominant approach to understanding mobile systems is to build and explore experimental prototypes, our exploration highlights the possibility that early models of an interactive system might be used to predict problems with embedding in context before costly mistakes have been made.\r\n\r\nAnalysis based on model checking is used to contrast configuration and context issues in two interfaces to a process control system.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Harrison,sq,n.jpg');

INSERT INTO `seminar` VALUES (4,'2005-10-18','14:00','Robert Recorde Room','Graham Hutton','http://www.cs.nott.ac.uk/~gmh/','Nottingham','http://www.cs.nott.ac.uk/','Calculating an Exceptional Machine','In previous work we showed how to verify a compiler for a small language with exceptions [MPC 2004]. We have since discovered how to calculate, as opposed to verify, an abstract machine for this language. The key step is the use of \"defunctionalization\", an old program transformation technique that has recently been rejuvenated by the work of Danvy et al. In this talk I will review defunctionalization, and show how it can be used to calculate an abstract machine for exceptions.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Hutton,sq,n.jpg');

INSERT INTO `seminar` VALUES (3,'2005-10-11','14:00','Robert Recorde Room','George Buchanan','http://cs.swan.ac.uk/~csgeorge','Swansea','http://www.swan.ac.uk/compsci','Spatial Hypertext - Helping organise things you find ','Hypertext is familiar as documents interlinked, or connected by a graph of hyperlinks. In spatial hypertext, documents exist in a visual space and are connected visually - e.g. by being found close to each other. Whereas classical hypertext has become synonymous with reading and finding, spatial hypertext has a strong association with organising what the reader finds. Similarly, whereas connections are merely used by a reader of classical hypertext, the user in spatial hypertext is continually creating them. The key challenges in spatial hypertext centre around interpreting the visual organisation being done by the user, and then discovering how to exploit that organisation\r\n\r\nIn this seminar, I will discuss a number of the research challenges in spatial hypertext, and demonstrate some of the solutions to these that I have been exploring.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Buchanan,sq,n.jpg');

INSERT INTO `seminar` VALUES (2,'2005-10-04','14:00','Robert Recorde Room','Magne Haveraaen','http://www.ii.uib.no/~magne/','Bergen','http://www.ii.uib.no/','Guarded Algebras - handling errors the right way? ','Algebraic specifications is a very useful technology for domain analysis and engineering, as well as being valuable for verification and validation of the resulting software. One problem with the traditional specification methods is their inability to deal flexibly with error situations, such as non-termination and exceptions.\r\n\r\nGuarded algebras allow the specification of algebras where the presence of errors, both recoverable (exceptions) and irrecoverable (partiality) can be handled smoothly, i.e., without cluttering the axioms.\r\n\r\nThis presentation will be in two parts. First we will give an intuition of the ideas involved, showing how we specify several algebras with quite involved errors. We also show how we independently may specify error handlers.\r\n\r\nThen we use the concepts of institutions and generalised logics to show that guarded specifications are insensitive to whether the underlying models are total or partial, and that we hence may use the simpler total logics when reasoning about guarded specifications.\r\n\r\nThis work is done in cooperation with Eric Wagner.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Haveraaen,sq,n.jpg');

INSERT INTO `seminar` VALUES (10,'2006-02-07','14:00','Robert Recorde Room','Matt Jones','http://www.undofuture.com','Swansea','http://www.swan.ac.uk/compsci','Context and Contentment','',1,NULL);

INSERT INTO `seminar` VALUES (11,'2006-02-14','14:00','Robert Recorde Room','Tim Porter','http://www.informatics.bangor.ac.uk/~tporter/','Bangor','http://www.informatics.bangor.ac.uk/','Agents, attributes and observations: an overview of how (algebraic) topological models arise in CS, AI and Logic.','I will briefly examine three ``case studies''''.\r\n\r\n(i) Agents: Simple models of knowledge in multiagent systems (MAS) lead to Kripke frames for the modal logic S5n and its extensions. Such models are special cases of a mathematical construct from algebraic K-theory (groupoid atlases) and these form a cartesian closed category. An analysis of runs in the MAS can be attempted via simplicial complexes associated to the frame.\r\n\r\n(ii) Attributes (Formal Concept Analysis): A (binary) formal context consists of a set of objects and a set of attributes together with a relation between them (object x satisfies attribute y). The same simplicial complex constructions can be used here but also there are links with lattice theory and other parts of poset theory. (Possible\r\nparadigm: agents as attributes!)\r\n\r\n(iii) Observations: In observing a physical or a computational system, the observations can be organised by various simplicial complexes. If metric data is available then Topological Data Analysis gives geometric information on the data set. If the data set is to large, sampling leads to systems of complexes. Sorkin posets and the nerve construction will be examined.\r\n\r\nThroughout the link between the geometry and related logics will be sketched. The central themes will include simplicial complexes posets and, above all, Chu spaces.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Porter,sq,n.jpg');

INSERT INTO `seminar` VALUES (12,'2006-03-02','14:00','Robert Recorde Room','Michael Huth','','Imperial College London','','Semantic minimizations for temporal logics ','Three-valued models, in which properties of a system are either true,\r\nfalse or unknown, have recently been advocated as a better\r\nrepresentation for reactive program abstractions generated by automatic\r\ntechniques such as predicate abstraction. Indeed, for the same cost,\r\nmodel checking three-valued abstractions can be used to both prove and\r\ndisprove any temporal-logic property, whereas traditional conservative\r\nabstractions can only prove universal properties. Also, verification\r\nresults can be more precise with generalized model checking, which\r\nchecks whether there exists a concretization of an abstraction\r\nsatisfying a temporal-logic formula. Since generalized model checking\r\nincludes satisfiability as a special case (when everything in the model\r\nis unknown), it is in general more expensive than traditional model\r\nchecking. In this talk, we study how to reduce generalized model\r\nchecking to model checking by a temporal-logic formula transformation,\r\nwhich generalizes a transformation for propositional logic known as\r\nsemantic minimization in the literature. We show that many\r\ntemporal-logic formulas of practical interest are self-minimizing, i.e.,\r\nare their own semantic minimizations, and hence that model checking for\r\nthese formulas has the same precision as generalized model checking. \r\n<P>\r\n(Joint work with Patrice Godefroid.)\r\n\r\n',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Huth,sq,n.jpg');

INSERT INTO `seminar` VALUES (13,'2006-03-10','14:00','Robert Recorde Room','Marie Claude Gaudel','','LRI, Paris-Sud University & CNRS, Orsay, France','','Formal Methods and Testing: Hypotheses, and Correctness Approximations','It has been recognised for a while that formal specifications can bring much to software testing. Numerous methods have been proposed for the derivation of test cases from various kinds of formal specifications, their submission, and verdict. All these methods rely upon some hypotheses on the system under test that formalise the gap between the success of a test campaign and the correctness of the system under test.\r\n<P>\r\nIn this talk we recall the notions of testability hypotheses and selection hypotheses, and we show how they have been used or could be used on various kinds of formal methods. We also address the issues of observation and control of the system under test.  ',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Gaudel,sq,n.jpg');

INSERT INTO `seminar` VALUES (14,'2006-03-21','14:00','Robert Recorde Room','Hans Gellersen','http://www.comp.lancs.ac.uk/~hwg/','Lancaster University','http://www.comp.lancs.ac.uk/','TBA','TBA',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Gellersen,sq,n.jpg');

INSERT INTO `seminar` VALUES (15,'2006-03-14','14:00','Robert Recorde Room','Uli Berger','http://cs.swan.ac.uk/~csulrich/','Swansea','http://cs.swan.ac.uk','Denotational semantics - what and why?','In this talk I will explain what denotational semantics is and why it is useful for understanding programs. After a general introduction into the main ideas and results I will report on my current work in this area, focusing on domain-theoretic  normalisation proofs forapplied lambda-calculi.\r\n\r\nMost of the talk will be accessible for a general audience.',1,NULL);

INSERT INTO `seminar` VALUES (16,'2006-04-25','14:00','Robert Recorde Room','Paul Goldberg','http://www.dcs.warwick.ac.uk/~pwg/','Warwick','http://www.dcs.warwick.ac.uk/','Game Over! The end of the line for NASH','In 1951, Nash proved his classical result that every game admits mixed strategies that are optimal with respect to each other. Such a set of strategies is known as a Nash equilibrium. The proof is non-constructive, and the computational problem of constructing Nash equilibria has subsequently attracted considerable attention within the algorithmics community.\r\n\r\nIn this talk we review a sequence of recent papers which have culminated in the answer to this central question of algorithmic game theory. Namely, two-player games are as computationally hard to solve as other multi-player games. Moreover, these problems are all equivalent to the problem of finding generic Brouwer or Kakutani fixpoints.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Goldberg,sq,n.jpg');

INSERT INTO `seminar` VALUES (8,'2005-11-15','14:00','Robert Recorde Room','Reiko Heckel','http://www.cs.le.ac.uk/people/rh122/','Leicester','http://www.cs.le.ac.uk/','Stochastic Analysis of Graph Transformation Systems: A Case Study in P2P Networks','In distributed and mobile systems with volatile bandwidth and fragile connectivity, non-functional aspects like performance and reliability become more and more important. To formalise, measure, and predict these properties, stochastic methods are required. At the same time such systems are characterised by a high degree of architectural reconfiguration. Viewing the architecture of a distributed system as a graph, this is naturally modelled by graph transformations. To address these two concerns, stochastic graph transformation systems have been introduced associating with each rule its application rate?the rate of the exponential distribution governing the delay of its application. Deriving continuous-time Markov chains, Continuous Stochastic Logic is used to specify reliability properties and verify them through model checking. ,P> In particular, we study a protocol for the reconfiguration of P2P networks intended to improve their reliability by adding redundant connections. The modelling of this protocol as a (stochastic) graph transformation system takes advantage of negative application and conditions path expressions. The ensuing high-level style of specification helps to reduce the number of states and increases the capabilities for automated analysis.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Heckel,sq,n.jpg');

INSERT INTO `seminar` VALUES (9,'2005-12-06','14:00','Robert Recorde Room','Iman Poernomo','http://www.kcl.ac.uk/depsta/ppro/experts/expert/789','London','http://www.kcl.ac.uk/','Better Model Driven Architecture through Constructive Type Theory','Model Driven Architecture (MDA) is a methodology based on the Meta Object Framework (MOF) to develop software by means of successive refinements from abstract platform-independent models to concrete platform-specific models. The purpose is to promote a clear demarcation of abstract architecture and implementation-specific issues. Central to MDA is the ability to define transformations as mappings between metamodels. Such transformations are powerful, providing a systematic means of model refinement. They are also dangerous: a single error in a transformation mapping can result in the systematic introduction of a range of errors in a resulting model. This talk explores a way of solving this problem through a formalisation of metamodel transformations within constructive type theory.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Poernomo,sq,n.jpg');

INSERT INTO `seminar` VALUES (20,'2005-12-06','14:00','Robert Recorde Room','Joao Marques Silva','http://www.ecs.soton.ac.uk/~jpms/','Southampton','http://www.ecs.soton.ac.uk/','Model Checking with Boolean Satisfiability','The evolution of SAT technology over the last decade has motivated its application to model checking, initially through the utilization of SAT in bounded model checking and, more recently, in unbounded model checking. Among the techniques proposed for unbounded model checking, the utilization of interpolants entails significant advantages, that motivate its practical usage. This talk provides an overview of SAT-based bounded model checking and of the utilization of interpolants in unbounded model checking. Moreover, improvements to the original interpolant-based unbounded model checking algorithm are described.',1,NULL);

INSERT INTO `seminar` VALUES (22,'2005-01-27','14:00','Robert Recorde Room','Benjamin Mora','http://cs.swan.ac.uk/~csmora/','Swansea','http://www.swan.ac.uk/compsci/index.html','Accelerating volume rendering algorithms','Volume rendering is a processing demanding application, partially because of the large number of data to be visualized. However, several volume rendering algorithms, like isosurfacing and Maximum Intensity Projection (MIP) can be accelerated by using \"Intelligent\" approaches. After quickly introducing those algorithms, I will present the work I made during the last 5 years to optimize those algorithms. Especially, I will focus on Maximum Intensity Projection, where recent works have shown that the average complexity can be reduced from O(n3) to O(n2).',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Mora,sq,n.jpg');

INSERT INTO `seminar` VALUES (23,'2005-02-01','14:00','Robert Recorde Room','Dirk Pattinson','http://www.pst.informatik.uni-muenchen.de/personen/pattinso/','','','Data Types for Differentiable Functions','We introduce a domain-theoretic computational model for multi-variable differential calculus, which for the first time gives rise to data types for differentiable functions. Differentiable functions of n variables are represented as sub-domain of the product of n+1 copies of the function space on the domain of intervals by tupling together consistent information about locally Lipschitz (piecewise differentiable) functions and their differential properties (partial derivatives). We discuss two applications of the model: A second-order method for obtaining exact solutions of ordinary differential equations and a domain-theoretic approach to the implicit function theorem, which allows for the robust construction of smooth surfaces.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Pattinson,sq,n.jpg');

INSERT INTO `seminar` VALUES (24,'2005-02-08','14:00','Robert Recorde Room','Tom Melham','http://web.comlab.ox.ac.uk/oucl/people/tom.melham.html','Oxford','http://web.comlab.ox.ac.uk/oucl/','Integrating Model Checking and Theorem Proving for Industrial Hardware Verification in a Reflective Functional Language',' Forte is a formal verification system developed by Intel''s Strategic CAD Labs for applications in hardware design and verification. Forte integrates model checking and theorem proving within a functional programming language, which both serves as an extensible specification language and allows the system to be scripted and customized. Forte''s functional programming language is also the underlying term language for the higher order logic of its theorem prover.\r\n\r\nThe latest version of this language, called reFLect, has quotation and antiquotation constructs similar to those in LISP, but typed. These build and decompose expressions in the language itself and provide a combination of pattern-matching and metaprogramming features tailored especially for the Forte applications. The addition of some reflection principles in the higher order logic based on reFLect also provides a framework for making a logically principled connection between theorems in higher-order logic, program execution in the reFLect language, and the results of model checking verifications.\r\n\r\nThis talk will give an account of the reFLect functional language and its role in Forte.\r\n\r\nThis is joint work with Jim Grundy, Sava Kristic, and John O''Leary of Intel Corporation.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Melham,sq,n.jpg');

INSERT INTO `seminar` VALUES (25,'2005-02-15','14:00','Robert Recorde Room','Stefan Szeider','http://www.dur.ac.uk/stefan.szeider/','Durham','http://www.dur.ac.uk/',' Parameterized algorithms for propositional satisfiability','In the talk we will consider several parameterizations of the propositional satisfiability problem (SAT) that give rise to efficient parameterized algorithms. Parameterized algorithms provide a means for coping with computationally hard problems by guaranteeing worst-case time complexities which are exponential in terms of the parameter but uniformly polynomial in the size of the instance. In particular we will consider parameters that bound the acyclicity or the matching deficiency of graph representations of SAT instances and parameters that bound the distance of SAT instances from being Horn or bijunctive.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Szeider,sq,n.jpg');

INSERT INTO `seminar` VALUES (26,'2005-02-22','14:00','Robert Recorde Room','Philip Welch','http://www.maths.bris.ac.uk/~mapdw/','Bristol','http://www.maths.bris.ac.uk/','Quasi-inductive definitions and weak systems of determinacy','Quasi-inductive definitions can be considered a generalisation of the more common monotone inductive definitions, and we shall look at some examples that have arisen independently in philosophical theories of truth, in transfinite computation theory, and (much more briefly) in attempts to separate out various complexity classes. As a theory it is best studied as a subsystem of second order number theory, and then the question arises to relate its theoretical strength to other such subsystems. A natural benchmark is the levels of determinacy of Gale-Stewart two person perfect information games it can prove.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Welch,sq,n.jpg');

INSERT INTO `seminar` VALUES (27,'2005-03-10','14:00','Robert Recorde Room','Lutz Schroeder','http://www.tzi.de/~lschrode/','Bremen','http://www.informatik.uni-bremen.de/','Monadic Computational Logic in HasCASL','Following seminal work by Moggi, monads are being used for the encapsulation of side-effects in functional programming, in particular in Haskell. We report on work aimed at supporting programming with generic side effects in this sense with monad-based generic computational logics. In particular, we describe a generic Hoare calculus and a generic dynamic logic, along with notions of determinism and state preservation in monads relevant for the definition of state-dependent formula. While the generic Hoare calculus applies in principle (although at times with strong expressive limitations) to arbitrary monads, the semantics of dynamic logic is introduced axiomatically. By means of a general mechanism for extracting a set of states from a given monad, a sufficient criterion for interpretability of dynamic logic is obtained which covers most of the relevant cases; however, it turns out that the continuation monad fails to admit dynamic logic. Monadic computational logic may be used both for the verification of generic monadic programs and for the loose specification of side effects such as mutable references or non-determinism. As a running example, partial and total correctness of Dijkstra''s non-deterministic implementation of Euclid''s Algorithm are proved in a loosely specified non-deterministic dynamic reference monad, using the monadic Hoare calculus and a total Hoare calculus derived from monadic dynamic logic, respectively. Finally, we extend these methods to cover correctness of programs that make use of exceptions to manipulate the control flow. To this end, we give a categorical and an equational characterization of Moggi''s exception monad transformer, which in combination with the previously developed formalisms give rise to generic partial and total Hoare calculi for exceptional termination. These results apply e.g. to the so-called Java monad and subsume existing Hoare logics for Java w.r.t. aspects of exceptional termination.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Schroeder,sq,n.jpg');

INSERT INTO `seminar` VALUES (29,'2005-04-14','14:00','Robert Recorde Room','Peter Hancock','http://www.dcs.ed.ac.uk/home/pgh/','Edinburgh','http://www-compsci.swan.ac.uk/~csetzer/logic-server/edinburgh.html','Computational meaning of topological notions.','The notion of interaction structure has two concrete computational applications\r\n\r\n* representation of RPC interfaces\r\n\r\n* representation of multi-sorted algebraic signatures. The most natural notion of morphism between interaction structures corresponds closely to the notion of downward or forward simulation.\r\n\r\nAn interaction structure gives rise to a basic topology in Sambin''s terminology, which is basically a pair of closure and interior operators that have good mutual behaviour. But basic topology lacks a good notion of intersection, and the distinction between a point and a closed set. By adding some further structure, one arrives at \"real topology\", with a complete Heyting algebra of open sets, etc.\r\n\r\nThe talk will offer my opinion about what this extra structure means in computational terms: a form of restartability.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Hancock,sq,n.jpg');

INSERT INTO `seminar` VALUES (30,'2005-04-28','14:00','Robert Recorde Room','Harold Thimbleby','http://www.cs.swan.ac.uk/~csharold/','Swansea','http://www.swan.ac.uk/compsci/index.html','Weapons of maths construction','What are the Thimblebys up to, why is it worthwhile, and what''s happening next?\r\n\r\nOr: Calculators are ubiquitous and taken for granted, but they are needlessly bad at maths. We''ll exhibit some deep problems and suggest that, indeed, most gadgets -- from hospital equipment to aircraft -- suffer from similar problems. We''ll briefly analyse some of the problems (and hint at a range of formal approaches), but most interestingly, demonstrate some exciting ways forward.\r\n\r\nPlease bring your own calculator/mobile/laptop/abacus... to join in!',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Thimbleby,sq,n.jpg');

INSERT INTO `seminar` VALUES (31,'2005-05-03','14:00','Robert Recorde Room','Hamish Carr','http://www.cs.ucd.ie/staff/hcarr/default.htm','Dublin','http://www.cs.ucd.ie/contents.htm','Contour Trees and Flexible Isosurfaces','The contour tree is an important topological abstraction for visualizing scalar fields. I shall describe the contour tree itself, how it can be used as an index of individual contour surfaces, and how it can be used as the basis of an interface for interactive exploration of scalar fields.\r\n\r\nJoint work with Jack Snoeyink and Michiel van de Panne.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Carr,sq,n.jpg');

INSERT INTO `seminar` VALUES (32,'2005-05-12','14:00','Robert Recorde Room','Marc Price','http://www.fortunecity.co.uk/southbank/spiritual/21/prof.html','BBC','http://www.bbc.co.uk/rd/','BBC 3D Interactive: \"free-to-air\" computer games?','Should a public service broadcaster such as the BBC be entering into the digital interactive entertainment market? Well, as far as the BBC are concerned, the jury is still out on this one. However, Marc Price, the BBC''s leading expert on 3D Interactive technology will describe to us why he believes that this is an important market for the public broadcaster. As the basis for his argument, Marc will discuss the history of digital interactive entertainment technology, the current state-of-the-art, possible future trends, and how public broadcasting maps into this.',1,NULL);

INSERT INTO `seminar` VALUES (33,'2005-06-14','14:00','Esso Lecture Theatre','Bettina Buth','http://www.cpt.haw-hamburg.de/~buth/','Hamburg','http://www.cpt.haw-hamburg.de/','Deadlock and Livelock Analysis for the ISS - Experiences with Using Formal Methods in an Industrial Application','From 1995 till 1998 the Bremen Institute of Safe Systems (BISS) and Verified Systems International collaborated with Daimler-Chrysler Aerospace RI (now EADS Space Transportation) for the verification of critical aspects of the central computer of the Russian Module of the International Space Station (ISS). The FTC is a fault-tolerant computer system for controlling experiments as well as docking manouvers. The project objective was to define and perform a verification suite for the software layers implementing the avionics interface (AVI, MIL-STD 1553 bus) as well as the fault management layer (FML). The software consisted of about 11,000 lines of OCCAM code, which exhibits a high degree of concurrency. The verification objectives were to investigate problems predominantly related to the concurrency and the internal communication behaviour of the components. The use of OCCAM had introduced a new level of complexity not easily handled by conventional testing approaches.\r\n\r\nThese comprise freedom of deadlock, freedom of livelock, correct implementation of voting algorithms, correct implementation of the Byzantine Agreement Protocol, performance properties depending on clock rates, Hardware-In-The-Loop tests for the overall system.\r\n\r\nThe talk will focus on those aspects which were handled by using CSP and model checking as the basic approach. The general idea for the analysis of communication properties of OCCAM programs as proposed here is to exploit the fact that OCCAM channel communication can easily be modelled in CSP. The basic idea for both deadlock and livelock analysis performed in this project is to use FDR2 for model checking. After manually abstracting the OCCAM programs to CSP processes the systems still is too large for a direct approach using FDR2. Thus it is necessary to decompose the task and use other techniques for combining the results to obtain an overall result for the full system. Some of these techniques are tool supported, others currently are only performed unassisted.\r\n\r\nIn 2002, it became necessary to re-verify properties of these software modules after they were adapted for the reuse within the Automatic Transport Vehicle ATV developed by EADS Space Transportation. For this purpose the models were adapted and the required checks performed. A side e ect of this analysis is an evaluation which of the software changes a ect the abstract models and in which way.\r\n\r\nThe talk will discuss both the original work and the experiences of the re-verification.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Buth,sq,n.jpg');

INSERT INTO `seminar` VALUES (35,'2005-06-28','14:00','Robert Recorde Room','Martin Dyer','http://www.comp.leeds.ac.uk/dyer/','Leeds','http://www.comp.leeds.ac.uk/','Approximately Counting Knapsack Solutions','We will describe an algorithm for approximating the number of solutions to a zero-one knapsack inequality. The talk will be self-contained, since we will first review the relevant computational ideas of exact and approximate counting.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Dyer,sq,n.jpg');

INSERT INTO `seminar` VALUES (36,'2005-07-07','14:00','Robert Recorde Room','Marijn Heule','http://www.isa.ewi.tudelft.nl/~heule/','TU Delft','http://www.tudelft.nl/live/pagina.jsp?id=b226846d-f19f-4c34-97ed-165fecc5ad8f&lang=en','Observed Lower Bounds for Random 3-SAT Phase Transition Density Using Linear Programming','We introduce two incomplete polynomial time algorithms to solve satisfiability problems which both use Linear Programming (LP) techniques. First, the FlipFlop LP attempts to simulate a Quadratic Program which would solve the CNF at hand. Second, the Weighted Linear Autarky LP is an extended variant of the Linear Autarky LP as defined by Kullmann and iteratively updates its weights to find autarkies in a given formula. Besides solving satisfiability problems, this LP could also be used to study the existence of autark assignments in formulas. Results within the experimental domain (up to 1000 variables) show a considerably sharper lower bound for the uniform random 3-Sat phase transition density than the proved lower bound of the myopic algorithm (> 3.26) by Achlioptas and even than that of the greedy algorithm (> 3.52) proposed by Kaporis.',1,NULL);

INSERT INTO `seminar` VALUES (38,'2004-10-05','14:00','Robert Recorde Room','Ulrich Berger','http://www-compsci.swan.ac.uk/~csulrich/','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','A Semantic Strong Normalization Proof for Higher-Order Rewrite Systems','We consider the untyped lambda calculus with constructors and recursively defined constants. We define the n-th approximation of a term M as the term M_n obtained by replacing every constant c with a constant c_n which is defined like c except that it unfolds only n times. We show that if M does not denote bottom in a suitable strict domain-theoretic model and all M_n are strongly normalizing, then M is strongly normalizing. We transfer this result to typed lambda calculi extended by various forms of recursion in higher types for which strong normalization was hitherto unknown. The motivation for this work comes from computational problems arising in connection with program extraction from classical proofs.',1,'http://www.cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Berger,sq,n.jpg');

INSERT INTO `seminar` VALUES (39,'2004-10-12','14:00','Robert Recorde Room','Emanuele Trucco','http://www.ece.eps.hw.ac.uk/~mtc/mtc.html','Edinburgh','http://www.hw.ac.uk/',' Computer vision and videoconferencing: flirt or long-lasting love?','The last 10 years have seen a number of efforts towards the development of videoconferencing systems based on computer vision and image processing.\r\n\r\nRecent examples include the VIRTUE system, the Coliseum system of HP Research Palo Alto, and the US Tele Immersion Initiative. The algorithmic power of contemporary computer vision is certainly seductive for advanced, image-based communications; but can computer vision deliver in such a demanding, market-driven domain? We approach this question from the point of view of applied computer vision research. On the way to an answer we discuss some recent techniques and results, from our and other laboratories, especially in the area of image-based rendering and specifically view synthesis. Key issues here are the generation of very accurate disparity maps for the human body in a videoconferencing set-up, and the data-driven vs model-based dilemma.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Trucco,sq,n.jpg');

INSERT INTO `seminar` VALUES (40,'2004-10-19','14:00','Robert Recorde Room','Alexander Kurz','http://www.mcs.le.ac.uk/~akurz/','Leicester','http://www.mcs.le.ac.uk/','Stone Duality for Modal Logic','Since Goldblatt (1976) it is well-known how to account for Kripke''s semantic of modal logic on the basis of Stone''s duality of Boolean algebras and certain topological spaces. There is a general, simple principle underlying this phenomenon which is implicit in Abramsky''s Domain Theory in Logical Form (1991): A duality between two categories A and X and two functors L:A->A and T:X->X, gives rise to a duality between the algebras for the functor L and the coalgebras for the functor T.\r\n\r\nThe aim of the talk is to show that this principle of constructing new dualities from old ones (i) accounts for a number of well-known dualities and (ii) helps to understand what appropriate specification languages for coalgebras are. The second item is motivated by understanding the theory of coalgebras as a theory of systems (Rutten 2000).',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Kurz,sq,n.jpg');

INSERT INTO `seminar` VALUES (41,'2004-10-21','14:00','Robert Recorde Room','James Royer','http://www.cis.syr.edu/~royer/','New York','http://www.ecs.syr.edu/dept/eecs/','Adventures in Computational Complexity for Higher Types','A higher-type functional is a function that takes as input or produces as output another function. Programs for higher type functionals are a standard part of many branches of computing. For instance, the constructions in cryptography that transform a one-way function into a cryptographically strong hash function. Other examples come from learning theory, effective analysis, computational complexity theory, ... and functional programming. In fact, since modules and objects are essentially higher-type notions, higher-types pervade contemporary computing.\r\n\r\nBooks on algorithms are mostly silent on higher-types. In areas involving particular sorts of higher-type algorithms, their analysis is largely ad hoc, piecemeal, or non-existent. This is because reasoning about time and space complexity is of full of hard subtle conceptual issues --- which make for some very nice problems.\r\n\r\nThis talk will sketch one path of exploration into the computational complexity of higher-type functions. Our focus will be on higher-type analogues of the polynomial-time computable functions. I will examine the issue of type-level 2 notions of poly-time, where the situation is reasonably well understood, and the analogous issue for type-level 3, where we have only pieces of the picture. In particular, I will discuss work by Irwin, Kapron, and myself that confirms a conjecture by Seth that two seemingly similar notions of ``type-level 3 poly-time'''' in fact differ.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Royer,sq,n.jpg');

INSERT INTO `seminar` VALUES (42,'2004-10-28','14:00','Robert Recorde Room','Samson Abramsky','http://web.comlab.ox.ac.uk/oucl/people/samson.abramsky.html','Oxford','http://www.ox.ac.uk/','Information is Physical, but Physics is Logical','Quantum information and computation opens up fascinating new perspectives at the interface between Physics and Computer Science. It forces us to take seriously the idea that information and computational processes are physically embodied. Indeed, we can take advantage of this to exploit quantum phenomena such as entanglement.\r\n\r\nMy aim is to apply some of the distinctive methods of Computer Science, above all compositional semantics and logic, to develop high-level methods for quantum information and computation.\r\n\r\nIn joint work with Bob Coecke, we have developed a novel axiomatization of (finitary, non-relativistic) quantum mechanics, which is both more abstract and more expressive than that laid down by von Neumann in his classical work on Mathematical Foundations of Quantum Mechanics (1932), which is still the de facto standard presentation. This allows us to give complete descriptions and proofs of correctness of several leading quantum protocols. More importantly, it lays bare the logical structure of the information flow inherent in quantum entanglement. This leads in turn to a development of Categorical Quantum Logic, in progress jointly with my student Ross Duncan.',1,'http://www.cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Abramsky,sq,n.jpg');

INSERT INTO `seminar` VALUES (43,'2004-11-02','14:00','Robert Recorde Room','Philip Scott','http://www.csi.uottawa.ca/~phil/','Ottawa','http://www.uottawa.ca/','Geometry of Interaction and the Dynamics of Proofs','How do we mathematically model the dynamics of Gentzen''s cut-elimination (normalization) in proof theory? To answer this question, J-Y Girard introduced his Geometry of Interaction (GoI) program in a profound series of papers starting in 1988. Using techniques from functional analysis and operator algebras, Girard''s work (and following work by Danos, Regnier, et al) offers novel insights into the operational and denotational semantics of proofs. More recently, work by Hyland, Abramsky, and others has led to new insights into GoI. We shall survey some of the basic features of GoI, and give an introduction to some of my recent results with Esfan Haghverdi analyzing and axiomatizing the foundations of GoI.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Scott,sq,n.jpg');

INSERT INTO `seminar` VALUES (44,'2004-11-11','14:00','Robert Recorde Room','David Aspinall','http://homepages.inf.ed.ac.uk/da/','Edinburgh','http://homepages.inf.ed.ac.uk/','Logics for Certifying Resource Bounds','The Mobile Resource Guarantees (MRG) project is developing Proof-Carrying Code technology to endow mobile code with certificates of bounded resource consumption. These certificates are generated by a compiler which, in addition to translating high-level programs into byte code, derives formal proofs based on programmer annotations and program analysis.\r\n\r\nAs the basis for reasoning and certificate generation, we employ a program logic for a subset of the JVM, implemented in Isabelle/HOL. This logic has good properties, including mechanized formal proofs of soundness and (relative) completeness. However, it proved to be rather low level for direct automatic use. To address this we have defined a derived assertion format which relates directly to the compile time analysis, which has simple side conditions that make automatic verification feasible.\r\n\r\nIn this talk I will present the program logic of MRG and also explain the derived assertions. The presentation follows on from a Swansea Colloquium in November 2003 given by Don Sannella, but a perfectly accurate memory of that talk will not be assumed.',1,'http://www.cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Aspinall,sq,n.jpg');

INSERT INTO `seminar` VALUES (45,'2004-11-18','14:00','Robert Recorde Room','Mariangiola Dezani','http://www.di.unito.it/~dezani/','Turin','http://www.di.unito.it/','Boxed Ambients with Communication Interfaces','We define BACI (Boxed Ambients with Communication Interfaces), an ambient calculus allowing a liberal communication policy. Each ambient carries its local view of the topic of conversation (the type of the information being exchanged) with parents and children that will condition where it is allowed to stay or migrate to and which ambients may be allowed to enter it. The topic of conversation view of ambients can dynamically change during migration. BACI is flexible enough to allow different topics of conversation between an ambient and different parents, without compromising type-safety: it uses port names for communication and ambient names for mobility. Capabilities and co-capabilities exchange port names and run-time typing information to control mobility. We show the type-soundness of BACI proving that it satisfies the subject reduction property. Moreover we study its behavioural semantics by means of a labelled transition system.',1,NULL);

INSERT INTO `seminar` VALUES (46,'2004-11-25','14:00','Board Room','Deborah Silver','http://www.caip.rutgers.edu/~silver/','Rutgers','http://www.caip.rutgers.edu/','Tracking Features in 3D Time Varying Data','Large distributed time-varying simulations are common in many scientific domains to study the evolution of various phenomena. These simulations produce thousands of timesteps which must be analyzed and interpreted. For datasets with evolving features, feature analysis and visualization tools are crucial to help interpret all the information. For example, it is usually important to know how many regions there are, how are they evolving, how does their volume/mass change, etc. We have developed a methodology for analyzing time-varying datasets which tracks 3D amorphous features as they evolve in time. In this talk, I will present an overview of our methodology and demonstrate how it can provide a paradigm for further investigation of massive datasets.',1,NULL);

INSERT INTO `seminar` VALUES (47,'2004-12-02','14:00','Robert Recorde Room','Jose Fiadeiro','http://www.fiadeiro.org/jose/','Leicester','http://www.cs.le.ac.uk/','Software Services: Scientific Challenge or Industrial Hype?','Web-services keep making headlines, not only in technical journals but also in the wider media like The Economist. Is this just a sales plot of the fragile software industry targeted to the companies and organisations that want to operate in the new economy as enabled by the internet and wireless communication? Or is there a new paradigm as far as software development is concerned? Should we, scientists, regard this as a challenge? Or dismiss it as hype?\r\n\r\nWe take these questions as a cue for discussing the difference between two different (but often confused) notions of complexity that arise in software development and the mathematics behind them.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Fiadeiro,sq,n.jpg');

INSERT INTO `seminar` VALUES (48,'2004-12-07','14:00','Robert Recorde Room','Bill Roscoe','http://web.comlab.ox.ac.uk/oucl/people/bill.roscoe.html','Oxford','http://www.ox.ac.uk/','The pursuit of buffer tolerance','Process algebras such as CSP use handshaken communication on channels. Other models of interaction such as dataflow use buffered channels, and frequently real systems contain some quantity of buffering that may well be nondeterministic. CSP can model these things by the insertion of extra processes onto channels, but the resulting systems tend to have very large state spaces. A network is said to be buffer tolerant if the addition of buffering on one or more channels does not affect its satisfaction of some specification. This is a desirable property since it means that verifying a buffer-free implementation proves it for versions with buffers in.\r\n\r\nIn this talk I will give formal definitions of buffer tolerance and identify classes of network in which it is automatically true. An important sort of component of buffer tolerant networks are processes which act as monotonic functions on their input streams. I will identify a remarkable finitary test for this property.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Roscoe,sq,n.jpg');

INSERT INTO `seminar` VALUES (49,'2004-12-14','14:00','Robert Recorde Room','Mark Jones','http://www.cs.swan.ac.uk/~csmark/','Swansea','http://www.swan.ac.uk/compsci','Visual Supercomputing - Technologies, Applications and Challenges','If we were to have a Grid infrastructure for visualization, what technologies would be needed to build such an infrastructure, what kind of applications would benefit from it, and what challenges are we facing in order to accomplish this goal? In this talk, ''visual supercomputing'' encapsulates the subject domain concerning the infrastructural technology for visualization. This talk will examine the technologies, applications and infrastructure that will enable and benefit from such an approach.',1,NULL);

INSERT INTO `seminar` VALUES (50,'2004-02-03','14:00','Board Room','Barry Blundell','http://cs.swan.ac.uk/~csbarry','Swansea','http://www.swan.ac.uk/compsci','Working with innovative 3D systems','There is increasing recognition that in the case of certain applications, such as medicine, engineering, and the sciences, the conventional flat-screen display is limiting the human-computer interaction process. A spectrum of alternative display technologies has been the subject of research for many years. However, all too often researchers have focused solely upon the visual characteristics of the display without considering new interaction opportunities that a display technique may offer. The speaker will give a brief, personal overview of some aspects of research he has carried out in this area during the course of the last fifteen years. Issues relating to the almost universal adoption of the flat-screen display paradigm will be examined, and volumetric display systems will be introduced. The speaker will focus upon one particular volumetric technology that he has developed, and some of the strengths and weaknesses of volumetric (and other) approaches will be highlighted. The speaker warns all attendees that this colloquium comes with a government health warning - this subject is multidisciplinary: hardware will be discussed... ',1,NULL);

INSERT INTO `seminar` VALUES (51,'2004-02-10','14:00','Robert Recorde Room','Adrian Hilton','http://www.ee.surrey.ac.uk/Personal/A.Hilton/','Surrey','http://www.ee.surrey.ac.uk/','3D Studio Production ','This talk will introduce research on the use of computer vision techniques for 3D content production in broadcast and interactive entertainment. Computer vision enables reconstruction of real-world objects to create highly realistic animated models. Research at the University of Surrey has developed a studio production platform using multiple view video to reconstruct the shape, appearance of movement of actors in a muliple camera broadcast studio. Results will be demonstrated which illustrate the use of this technology for both automatic post-production of special effects and creation of animated 3D models.',1,NULL);

INSERT INTO `seminar` VALUES (52,'2004-02-17','14:00','Robert Recorde Room','Paul Lewis','http://www.ecs.soton.ac.uk/~phl/','Southampton','http://www.ecs.soton.ac.uk/','Retrieval and Navigation of Multimedia Information Using Content','This talk is concerned with multimedia information handling. It will explore some of the problems of navigating from, to and around large digital multimedia collections by following and the problems of retrieving particular multimedia objects in response to queries. Although it will be mainly concerned with image collections, the issues and ideas often apply to other multimedia formats such as videos, 3-D models and audio. Keywords or metadata have historically provided the most effective vehicle for retrieving multimedia information from digital multimedia collections. Content-based image and video retrieval are very active research area and some of its benefits and limitations will be discussed. Attempts to address the limitations of these approaches through the development of integrated content, metadata and semantic based retrieval and navigation facilities will be described. The work involves applications to both museum collections and medical images and the use of semantic web technology to enhance the facilities provided.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Lewis,sq,n.jpg');

INSERT INTO `seminar` VALUES (53,'2004-02-24','14:00','Robert Recorde Room','Anton Setzer','http://cs.swan.ac.uk/~csanton','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','The Pi_3-Reflecting Universe','The research is part of a programme with the goal of extending Martin-Loef Type Theory (MLTT) in order to reach as much proof theoretic strength as possible. From a computer science point of view the hope is to find new data structures which can be used in general programming. Some of the ideas developed as part of this project (the Mahlo universe, see below) have already been used in order to develop a closed formalisation of inductive-recursive definitions. The use of this in generic programming is currently been explored by P. Dybjers, Marcin Benke and Patrik Jansson. In this talk we will first review the main principles of MLTT (universes and the W-type) which already allow us to reach considerable strength (Kripke-Platek set theory extended by one recursively inaccessible -- the notion of a recursively inaccessible will be explained in this talk). We then give some idea why we reach this strength. Then we will look at the Mahlo universe as developed by the author, which reaches the strength of one recursively Mahlo ordinal (a notion which will again be explained in the talk). Finally we look at how to design a theory the author conjectures to reach the strength of on Pi_3-reflecting-ordinal.',1,NULL);

INSERT INTO `seminar` VALUES (54,'2004-03-02','14:00','Robert Recorde Room','Jiang-Lun Wu','http://www-maths.swan.ac.uk/staff/jlw/','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','Hyperfinite model and measurability problem via the continuum method','This is my second talk in nonstandard analysis. After setting up hyperfinite framework for probability and measure theory, we will outline the general approaches of nonstandard analysis in application. Then we will focusing on our recent work on Doob''s measurabilty problem. We will keep the talk at an explanatory level.',1,NULL);

INSERT INTO `seminar` VALUES (55,'2004-03-04','14:00','Robert Recorde Room','Vladimiro Sassone','http://www.cogs.susx.ac.uk/users/vs/','Sussex','http://www.cogs.susx.ac.uk/','Foundations of Global Computing','Global computing refers to computation over a global network of mobile, bounded resources shared among mobile, highly dynamic, untrusted entities. The main concerns are classical ones: protection and management of resources; privacy and confidentiality of data, ..., but have to be established under challenging conditions: extreme dynamic reconfigurability; lack of coordination and trust; limited capabilities; partial knowledge,... In the talk I will illustrate some recent results on the foundations of global computing, ranging from abstract semantic theories and models for concurrency to type theories for access control and programming languages.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Sassone,sq,n.jpg');

INSERT INTO `seminar` VALUES (56,'2004-03-09','14:00','Robert Recorde Room','Christoph LÃ¼th','http://www.informatik.uni-bremen.de/~cxl/','Bremen','http://www.informatik.uni-bremen.de/','Formal Development of a Safe Wheelchair Control Program','In the talk, I will report about ongoing work in the SafeRobotics project, which is concerned with the formal development of a safe control program for a wheelchair for severely handicapped patients. The talk will introduce the system architecture of our wheelchair, and discuss how safety can be ensured by the formal development of a small but critical safety module. The formal development itself is done with the higher-order prover theorem prover Isabelle/HOL. First we formalise the wheelchair''s kinematics in higher-order logic, and formulate a safety requirements specficiation. From this specification, we derive a design specification in the executable fragment of higher-order logic, from which we derive a second design specification using imperative features such as state and exceptions, arriving finally at an imperative program.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,LUUth,sq,n.jpg');

INSERT INTO `seminar` VALUES (57,'2004-03-16','14:00','Robert Recorde Room','Adam Schwarz',NULL,'Verona',NULL,'Proceedings from the heat-oppressed brain: Neuroimaging data processing and visualisation','\"If the brain were so simple we could understand it, we would be so simple we couldn''t.\" --Lyall Watson Medical imaging modalities such as Magnetic Resonance Imaging (MRI) routinely acquire multislice/3D data sets, sometimes as a time series to capture dynamic or functional changes. Consequently, strategies for both data reduction (to extract the functional parameter of interest, and/or in order that statistical tests and inference be tractable) and visualisation (to facilitate 3D localisation of functional parameters) are key issues. Although the need for effective visualisation of 3D medical data has been reflected in ongoing applications of computer graphics techniques to this end, the classical approach of 2D slices with overlays still provides a benchmark in terms of anatomical referencing and ease of interpretation. Nevertheless, the intrinsically volumetric nature of much medical imaging data lends itself naturally to emerging visualisation technologies such as volumetric or other autostereoscopic display technologies. Here I will provide an overview of MRI data acquisition and subsequent data processing, including functional and pharmacological MRI experiments. Standard and innovative approaches to the visualisation of (3+1)D MR data sets will be reviewed. Finally, opportunities for visualisation using advanced display technologies will be discussed.',1,NULL);

INSERT INTO `seminar` VALUES (58,'2004-03-23','14:00','Robert Recorde Room','Yoshinao Isobe','','<A href=\"http://www.aist.go.jp/index_en.html\">Information Technology Research Institute Japan</A>, visiting <A href=\"http://www.swan.ac.uk/compsci\">Swansea</A>',NULL,'Theorem proving support for CSP','The recently developed CSP-Prover is an interactive theorem prover dedicated to refinement proofs within the process algebra CSP. It aims specifically at proofs on infinite state systems, which may also involve infinite non-determinism. For this reason, the CSP-Prover uses the stable failures model F as denotational semantics of CSP. Semantically, the CSP-Prover is based on the theory of complete metric spaces. Here, Banach''s Fixed Point Theorem is used for two purposes: to prove the existence of fixed points, and to prove CSP refinement between two fixed points. An interesting detail in the context of the various CSP denotational semantics is that metric spaces are represented as so-called restriction spaces. Technically, the CSP-Prover is based on the generic theorem prover Isabelle, using the logic HOL-Complex. Within this logic, the syntax as well as the semantics of CSP is encoded, i.e., the CSP-Prover provides a deep encoding of CSP. This encoding follows a generic approach which makes it easy to re-use large parts of the encoding for other CSP models like the traces model T, or the failure-divergence model N, or even the various infinite traces models. At the end of the talk, the CSP-Prover will be demonstrated by a classical refinement example: the dining mathematicians.',1,NULL);

INSERT INTO `seminar` VALUES (59,'2004-04-20','14:00','Robert Recorde Room','Klaus Aehlig',NULL,'<A href=\"http://www.mathematik.uni-muenchen.de/\">M&uuml;nchen</A>, visiting <A href=\"http://web.comlab.ox.ac.uk/oucl/\">Oxford</A>',NULL,'On Fragments of Analysis with Strengths of Finitely Iterated Inductive Definitions','The polymorphic lambda-calculus (System F) is a very expressive functional programming language. All inductive types can be encoded directly in system F. A natural restriction of the polymorphic types consists in allowing quantification only for types with at most the quantified variable free. This fragment is still strong enough to host all inductive types, but on the other hand all number theoretic functions definable in this system are provably recursive in systems of finitely iterated inductive definition. So a simple fragment capturing precisely inductive data types has been identified. Similarly, a fragment of second order arithmetic can be defined with the same restriction on second order quantification. This fragment is proof theoretically equivalent to the system of finitely iterated inductive definitions.',1,NULL);

INSERT INTO `seminar` VALUES (60,'2004-04-27','14:00','Robert Recorde Room','Gareth Daniel','http://www-compsci.swan.ac.uk/~csgareth/','Swansea','http://www.swan.ac.uk/compsci/index.html','Video Visualisation','Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this talk, we present a novel methodology for \"summarizing\" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing \"relative\" and \"absolute\" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.',1,NULL);

INSERT INTO `seminar` VALUES (61,'2004-05-20','15:00','Robert Recorde Room','Claudia Eckert','http://www.sec.informatik.tu-darmstadt.de/de/mitarbeiter/eckert/','Darmstadt','http://www.informatik.tu-darmstadt.de/','Ubiquitous Computing: Both a blessing and a curse?','Ubiquitous computing is emerging rapidly as exciting new paradigm to provide computing and communication services all the time, everywhere. Its systems are now invading every aspect of life to the point that they are disappearing inside all sorts of appliances. This emergence is an outcome of research and technological advances in pervasive computing and communications, wireless networks, mobile computing and distributed computing. Ubiquitous computing offers a lot of new challenges and opportunities to enable new applications for instance in the area of ehealth. On the other hand, a lot of new problems arise. Especially, ubiquitous computing will aggravate our already existing security problems considerably. The talk aims at pointing at the gap between the blessings that might come with these new technologies and the security problems we should be aware of. The talk will then show by means of an example-scenario (e.g. identity management) that we are still far away from controlling today''s security problems. Lots of challenging R&D topics are still under investigation. The talk will finally sketch some problems my research group is currently working on.',1,NULL);

INSERT INTO `seminar` VALUES (62,'2004-05-27','14:00','Robert Recorde Room','Jan Peleska','http://www.informatik.uni-bremen.de/agbs/jp/','Bremen','http://www.informatik.uni-bremen.de/','Formal Methods for Hard-Real Time Testing','We outline several problems and possible solutions for automated test data generation, test execution and test evaluation in the field of embedded hard real-time systems with both discrete and time-continuous (i.e. analog) interfaces. Test scripts are written as formal specifications which are - in pre-compiled internal representations - executable in real-time. We discuss the suitability of process algebras (Timed CSP) versus Hybrid Automata formalisms for these tasks. Automated test generation is based on standard solutions well known from process algebras, graph theory, logic and model checking. However, the necessary distinctions between input to the System Under Test (these parameters may be manipulated by the testing environment) and outputs (these parameters are checked against the specification) and the incorporation of real-time constraints require considerable extensions of the known theories.',1,NULL);

INSERT INTO `seminar` VALUES (63,'2004-06-09','14:00','Robert Recorde Room','Peter Mosses','http://www.brics.dk/~pdm/','Aarhus','http://www.brics.dk/','Incremental Semantics','Formal semantic descriptions of programming languages are highly desirable. Unfortunately, the engineering aspects of most semantic description frameworks are far from ideal: little reuse of parts of descriptions, no repositories of validated descriptions, poor tool support, etc.\r\n\r\nSuppose, however, that we focus on describing the semantics of individual programming constructs, instead of trying to describe an entire language all at once. Many constructs have essentially the same intended interpretation in all the languages where they occur (sometimes with minor variants, e.g., conditionals might have boolean or numerical tests). If one could describe each construct (variant) independently, so that its description would never need reformulating -- regardless of which other kinds of constructs might be included with it in the same language -- it would allow semantic descriptions to be given incrementally, with radical improvements to their engineering aspects. For instance, there would be no need to reformulate the description of the constructs of Standard ML when giving a description of its extension to Concurrent ML.\r\n\r\nAfter briefly illustrating the problems of giving independent descriptions of individual constructs using conventional semantic frameworks, we take a closer look at MSOS, which is an incremental variant of the well-known Structural Operational Semantics. We also discuss the pros and cons of our incremental approach.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Mosses,sq,n.jpg');

INSERT INTO `seminar` VALUES (64,'2004-06-10','15:00','Robert Recorde Room','Thomas Forster','http://www.dpmms.cam.ac.uk/site2002/People/forster_te.html','Cambridge','http://www.dpmms.cam.ac.uk/','Better Quasi Orderings','These were invented by the late combinatorist Crispin Nash-Williams and most of the work on them has been done by combinatorist. However, much of BQO has an underlying logical/algebraic flavour which I will attempt to bring out. Specifically I shall sketch a proof that a quasiorder is a BQO iff its free countable completion is wellfounded.\r\n\r\nI shall try to aim this at a general logical audience, the presence of local BQO-istes notwithstanding.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Forster,sq,n.jpg');

INSERT INTO `seminar` VALUES (65,'2004-06-29','14:00','Robert Recorde Room','Anton Setzer','http://www.cs.swan.ac.uk/~csetzer/','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','Weakly Final Coalgebras in Dependent Type Theory','We reconsider the formulation of interactive programs in dependent type theory and note that interactive programs correspond to a special case of weakly final coalgebras. We then introduce rules for weakly final coalgebras of strictly positive functors in dependent type theory. We arrive at the notion of coiteration and investigate its relationship to guarded induction. Finally we explore the relationship between state dependent coalgebras and bisimulation.',1,NULL);

INSERT INTO `seminar` VALUES (66,'2004-07-01','14:00','Robert Recorde Room','Yoram Hirshfeld','http://www.math.uu.se/logik/logic-server/telaviv.html','Tel Aviv','http://www.tau.ac.il/','Continuous time temporal and predicate logic','We develop metric temporal logic within the framework of monadic logic, with the positive real line as its canonical model. This makes evolving programs a special case of systems evolving in time (not necessarily with finite variability). Decidability and complexity results are derived from the non metric case, without resorting to automata theory, and apply also to processes without finite variability. We hope that this work (joint with Alex Rabinovich) will put in order a chaotic domain where lots of talent was invested achieving advanced technical results within (arguable) unnatural frameworks.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Hirshfeld,sq,n.jpg');

INSERT INTO `seminar` VALUES (67,'2004-07-06','14:00','Robert Recorde Room','Joanna Gooch / David Clark',NULL,'Swansea','http://www.swan.ac.uk/compsci/index.html','Virtual Secretary / Automatic Program Translation','Joanna Gooch: Virtual Secretary. A Knowledge-based User Interface for File Management\r\n\r\nFile organisation and file sharing are essential activities for every computer user. We propose a knowledge-based user interface, called a Virtual Secretary (VS), for file management. The system is designed to emulate the basic behaviour of a human secretary, and it allows a user to instruct the VS to perform tasks for managing files, instead of manipulating files directly through windows as with a conventional operating system. The system is supported by a knowledge base and a collection of agents, which are programs that manage and process the knowledge collected, and work behind the scene aiding gradual proliferation of knowledge.\r\n\r\nIn this talk, I will present my experience in designing and implementing a VS user interface, its system architecture, its knowledge base and a collection of agents. I will demonstrate that it is desirable as well as feasible to deploy a knowledge base in supporting an intelligent user interface that acts like a human assistant who handles paperwork, looks after filing, security and so on. I will also show that such a user interface has the potential to be evolved into a highly intelligent assistant to a user over a period of service and through the introduction of more intelligent agents.\r\n\r\nDavid Clark: Automatic Program Translation\r\n\r\nTranslation between data formats, multimedia mark-up languages, modelling languages and programming languages are classic problems in computer science and software engineering. We will explore the two traditional approaches of direct translation and translation via an intermediate language along with a new approach, Independent Stylesheet Language Translation. ISLT employs a knowledge-based decision process and a mapping thesaurus to facilitate the transformation of data or program constructs from one language to another, based upon a single stylesheet for each language and a generic translator.',1,NULL);

INSERT INTO `seminar` VALUES (68,'2004-07-20','14:00','Robert Recorde Room','Till Mossakowski','http://www.informatik.uni-bremen.de/~till/','Bremen','http://www.informatik.uni-bremen.de/','Heterogeneous CASL and the heterogeneous tool set','For the specification of large software systems, heterogeneous multi-logic specifications are needed, since complex problems have different aspects that are best specified in different logics. True logic combinations (in the sense of fibring, or colimits of logical systems) work well for certain classes of logics. However, the true combination approach reaches its limits when logics involving very different features (like modalities, higher-order polymorphism, and calculi for concurrent systems) shall be combined. In such cases, a true combination of all the used logics will quickly become too complex. Hence, heterogeneous specification provide a weaker form of logic combination (corresponding to weighted colimits), where basically the logics are put side by side, but can interact via logic translations.\r\n\r\nUsing heterogeneous specifications, different approaches being developed at different sites can be related, i.e. there is a formal interoperability among languages and tools. In many cases, specialized languages and tools have their strengths in particular aspects. Using heterogeneous specification, these strengths can be combined with comparably small effort.\r\n\r\nWe provide a general semantic framework for heterogeneous specification in Heterogeneoous CASL, as well as a proof calculus and tool support. We show that Grothendieck institutions based on institution comorphisms can serve as the underlying mathematical framework. In particular, we show how to extend the verification semantics given for structured specifications in CASL Reference Manual to the heterogeneous case. This semantics translates a heterogeneous specification into a kernel formalism called development graphs.\r\n\r\nThe heterogeneous tool set provides tool support for heterogeneous specification. Based on an object-oriented interface for institutions (using type classes in Haskell), it implements the Grothendieck institution and provides a heterogeneous parser, static analysis and proof support for heterogeneous specification. This is based on parsers, static analysers and proof support for the individual institutions, on the above mentioned heterogeneous verification semantics, and on a proof calculus for development graphs over the Grothendieck institution.',1,NULL);

INSERT INTO `seminar` VALUES (17,'2006-05-09','14:00','Robert Recorde Room','Stephen Brewster','http://www.dcs.gla.ac.uk/~stephen/','University of Glasgow','http://www.dcs.gla.ac.uk/','Olfoto: Designing a Smell-Based Interaction','I will present a study into the use of smell for human-computer interaction, and in particular for searching digital photo collections. Many people now have large photo libraries on their computers and effective search tools are needed. Smell has a strong link to memory and emotion so may be a good way to cue recall when searching. Our study compared text and smell based tagging. For the first stage we generated a set of smell and tag names from user descriptions of photos, participants then used these to tag photos, returning two weeks later to answer questions on their photos. Results showed that participants could tag effectively with text labels, as this is a common and familiar task. Performance with smells was lower but participants performed significantly above chance, with some participants using smells well. This suggests that smell has potential. Results also showed that some smells were consistently identified and useful, but some were not and highlighted issues with smell delivery devices. I will also highlight some practical issues of using smell for interaction.\r\n\r\n\r\n\r\n<b>Bio</b>\r\n\r\nStephen brewster is an EPSRC Advanced Research Fellow and leads the Multimodal Interaction Group at Glasgow, investigating how we can use the different senses to improve interaction with computers.\r\n\r\n',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Brewster,sq,n.jpg');

INSERT INTO `seminar` VALUES (37,'2004-09-15','14:00','Robert Recorde Room','Stefano Berardi','http://www.di.unito.it/~stefano/','Turin','http://www.di.unito.it/','Programming With Non-Recursive Maps','',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Berardi,sq,n.jpg');

INSERT INTO `seminar` VALUES (70,'2003-09-18','14:00','Robert Recorde Room','Yannis Ivrissimtzis','http://www.mpi-sb.mpg.de/~ivrissim/contactdetails.html','Saarbr&uuml;cken','http://www.mpi-sb.mpg.de/','Statistical Learning in Surface Reconstruction','We present a new algorithm for surface reconstruction from unorganized point clouds. The algorithm is based on a special type of Neural Networks, the Growing Cell Structures, starting with an initial Neural Network and learning the geometry of target space in a \"competitive learning\" process. The network expands by splitting its most active vertices and its quality is constantly improved by removing the least active vertices. The topology changes with statistics based operations which create boundaries and merge them to create handles. ',1,NULL);

INSERT INTO `seminar` VALUES (71,'2003-09-19','14:00','Robert Recorde Room','Arne Lindow','http://www.informatik.uni-bremen.de/~lindow','Bremen','http://www.informatik.uni-bremen.de/','MMiSS - MultiMedia Instruction in Safe Systems','We present an educational system developed at five universities in Germany that focuses on creation and presentation of learning material. The system was intended to cover the whole subject of Safe Systems at all partner locations. Over the time, the number of contributors - organized in an international MMiSS forum - is growing, so that course material from diverse domains goes into the respository. In the talk we will show the possibilities of the approach combining hypermedia course materials and formal programming tools. More informations about the project can be found at http://www.mmiss.de',1,NULL);

INSERT INTO `seminar` VALUES (72,'2003-10-02','14:00','Robert Recorde Room','Sergei Tupailo','http://www.cs.ioc.ee/~sergei/','Leeds','http://www-compsci.swan.ac.uk/~csetzer/logic-server/leeds.html','On the intuitionistic strength of monotone inductive definitions','In his 2002 PhD thesis M. Moellerfeld has shown that the second-order mu-calculus, a theory axiomatizing least fixed points of positively defined monotone operators, when based on classical logic, has the strength of Pi1_2 comprehension axiom, which is the current limit of ordinal analysis. His methods are based on Generalized Recursion Theory, and as such are not amenable to intuitionistic reasoning. However, the $\\mu$-calculus presented very little problems for the Goedel-Gentzen-Kolmogorov double-negation translation, so we prove that the intuitionistic theory is proof-theoretically equally strong. Further interpretation of the intuitionistic mu-calculus in the system T_0^i+UMID of Explicit Mathematics provides a first breakthrough into intuitionistic strength of monotone inductive definitions in those theories, showing that one should expect that this strength is as big as the classical one. This question was posed by S. Feferman in 1982, but up to now virtually nothing was known in this area. On the classical side, it came as a surprise when M. Rathjen proved in a series of papers of 1996-2002 that the strength is essentially that of Pi1_2-CA. Our work determines the exact strength of the intuitionistic T_0^i(restr.)+UMID_N. The complete paper is available at http://www.cs.ioc.ee/~sergei/Mypapers/mumid.ps .',1,NULL);

INSERT INTO `seminar` VALUES (73,'2003-10-07','14:00','Robert Recorde Room','Magne Haveraaen','http://www.ii.uib.no/~magne/','Bergen','http://www.ii.uib.no/','High performance computing using Coordinate Free Numerics','Numerical software is important for expanding our understanding of the world around us and for solving many engineering tasks. Writing numerical software meets many challenges. These ranges from general software problems like the fact that cost increases more than linearly in program size, to a specific focus on efficiency due to the high computational loads of numerical software. As the demand for numerical software increases, making numerical software adapatable to new problems becomes very important. The talk discusses the choice of variation points in numerical software, and shows that the approach of coordinate free numerics fits well with these demands. Consequential efficiency problems and possible solutions are also presented.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Haveraaen,sq,n.jpg');

INSERT INTO `seminar` VALUES (74,'2003-10-30','14:00','Robert Recorde Room','Jiang-Lun Wu','http://www-maths.swan.ac.uk/staff/jlw/','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','Constructive aspects of nonstandard analysis and some of its application',NULL,1,NULL);

INSERT INTO `seminar` VALUES (75,'2003-11-04','14:00','Robert Recorde Room','Phil Grant','http://www.cs.swan.ac.uk/~csphil/','Swansea','http://www.swan.ac.uk/compsci/index.html','JACIE - A Language for Net-centric, Multimedia and Collaborative Applications','We will present details of a new scripting language, JACIE, designed to support rapid prototyping and implementation of net-centric, multimedia and collaborative applications. The support for the management of multimedia interaction and communication in collaborative applications is highlighted. JACIE facilitates such support through the concepts of channels and a collection of interaction protocols. A template-based programming style is adopted by JACIE, using a single program for both client and server, and platform-independence achieved by employing Java as the target language. Examples of applications developed in JACIE will be illustrated.',1,NULL);

INSERT INTO `seminar` VALUES (76,'2003-11-11','14:00','Robert Recorde Room','Jan Peleska','http://www.informatik.uni-bremen.de/agbs/jp/','Bremen','http://www.informatik.uni-bremen.de/','Formal Methods for Hard-Real Time Testing','We outline several problems and possible solutions for automated test data generation, test execution and test evaluation in the field of embedded hard real-time systems with both discrete and time-continuous (i.e. analog) interfaces. Test scripts are written as formal specifications which are - in pre-compiled internal representations - executable in real-time. We discuss the suitability of process algebras (Timed CSP) versus Hybrid Automata formalisms for these tasks. Automated test generation is based on standard solutions well known from process algebras, graph theory, logic and model checking. However, the necessary distinctions between input to the System Under Test (these parameters may be manipulated by the testing environment) and outputs (these parameters are checked against the specification) and the incorporation of real-time constraints require considerable extensions of the known theories.',1,NULL);

INSERT INTO `seminar` VALUES (77,'2003-11-18','14:00','Robert Recorde Room','Don Sannella','http://www.dcs.ed.ac.uk/home/dts/','Edinburgh','http://www-compsci.swan.ac.uk/~csetzer/logic-server/edinburgh.html','Mobile Resource Guarantees','The Mobile Resource Guarantees (MRG) project is building infrastructure for endowing mobile bytecode programs with independently verifiable certificates describing their resource consumption. These certificates will be condensed and formalised mathematical proofs of a resource-related property which are by their very nature self-evident and unforgeable. Arbitrarily complex methods may be used to construct such a certificate, but once constructed its verification will always be a simple computation. This makes it feasible for the recipient to check that the proof is valid, and so the claimed property holds, before running the code. This work falls within an area known as \"proof carrying code\". Our focus in MRG on quantitative resource guarantees is different from the traditional PCC focus which is security. Another novelty is the method to be used to generate proofs, which is to use a \"linear\" type system that classifies programs according to their resource usage as well as according to the kinds of values they consume and produce. The intention is to generate proofs of resource usage from typing derivations. The MRG project (IST-2001-33149), which is a collaboration between the University of Edinburgh and LMU Munich, is funded by the EC under the FET proactive initiative on Global Computing.',1,NULL);

INSERT INTO `seminar` VALUES (78,'2003-11-27','14:00','Robert Recorde Room','Holger Schlingloff','http://www.informatik.hu-berlin.de/~hs/','Berlin','http://www.informatik.hu-berlin.de/','Hybrid Modal Logic','Hybrid logics are an enrichment of modal logics with certain first-order features which are algorithmically well behaved. Therefore, they are well suited for the specification of certain properties of computational systems. We show that hybrid logics are more expressive than usual modal and temporal logics, and exhibit a hierarchy of hybrid languages. We determine the complexities of the satisfiability problem for these languages and define an existential fragment of hybrid logic for which satisfiability is still NP-complete. We then summarise results on the model checking problem for hybrid logics and give applications to the specification of industrial systems.',1,NULL);

INSERT INTO `seminar` VALUES (79,'2003-12-02','14:00','Robert Recorde Room','Achim Jung','http://www.cs.bham.ac.uk/~axj/','Birmingham','http://www.cs.bham.ac.uk/','The probabilistic powerdomain: Old problems and new results','Two approaches to the semantics of probabilistic processes arose around 1980; one by Kozen who employed Banach lattices (and tools from functional analysis) and another one by Saheb-Djahromi in the framework of Scott domains. My talk will follow the second line of investigation. Saheb-Djahromi''s definition was considerably simplified by Jones and Plotkin in 1989, and a substantial amount of results were developed in the PhD dissertation of Jones. However, from a domain theoretic point of view, the theory contained some pitfalls and some fundamental questions remained open for some time (and some remain open to this day). More recently, it has become clear that a topological, rather than order-theoretic approach is more fruitful, and indeed, it has been relatively easy to establish the core properties one needs when working with the probabilistic powerspace: integration; extension of valuations to measures; closure in a suitable category of spaces. In this talk I wish to emphasize the underlying mathematical machinery which turned out to be quite elegant.',1,NULL);

INSERT INTO `seminar` VALUES (80,'2003-12-04','14:00','Robert Recorde Room','Ranko Lazic','http://www.dcs.warwick.ac.uk/people/staff/Ranko.Lazic/','Warwick','http://www.dcs.warwick.ac.uk/','Model checking polymorphic systems with arrays','Polymorphic systems with arrays (PSAs) is a general class of nondeterministic reactive systems. A PSA is polymorphic in the sense that it depends on a signature, which consists of a number of type variables, and a number of symbols whose types can be built from the type variables. Some of the state variables of a PSA can be arrays, which are functions from one type to another. We present several new decidability and undecidability results for the parameterised control-state reachability problem on subclasses of PSAs.',1,NULL);

INSERT INTO `seminar` VALUES (81,'2003-12-09','14:00','Robert Recorde Room','Johan Glimming','http://www.nada.kth.se/~glimming/','<A href=\"http://www.nada.kth.se/index.html.en\">Stockholm University</A> visiting <A href=\"http://www.cs.nott.ac.uk/\">University of Nottingham</A>',NULL,'Recursion parameterised by Monads: Examples and characterisation','Fokkinga (1994) constructed an adjunction between the category of F-algebras and the category of lifted F-algebras for monads M given a certain natural transformation dist_F, and regular F. The left adjoint in the construction (with its preservation of colimits) allow translation of recursion schemas to schemas parameterised by monads. In this talk I will explain Fokkinga''s construction and give concrete examples of its use in functional programming, e.g. the relationship between recursion and stateful objects represented by state monads. I further discuss shortcomings with Fokkinga''s monadic lifting, and describe my current work on generalising the lifting construction.',1,NULL);

INSERT INTO `seminar` VALUES (82,'2003-01-31','14:00','Robert Recorde Room','Felix Joachimski','http://www.mathematik.uni-muenchen.de/~joachski/','<A href=\"http://www-compsci.swan.ac.uk/~csetzer/logic-server/muenchen.html\">Munich</A>, visiting Bristol',NULL,'Continuous Normalization','Continuous normalization has been introduced to proof theory by Mints and since then studied (amongst others) by Buchholz and Schwichtenberg. The talk will try to illustrate the underlying ideas by applying them to a much simpler setting - the untyped lambda-calculus. This is quite interesting, because the process of continuous normalization can even be applied to non-normalizing terms. It uses so-called repetition rules to coinductively construct the normal form of its input. The algorithm is very intuitive and ensures that the function it models is primitive recursive; being defined on non-wellfounded terms, it has the identity as modulus of continuity. We will explore some further fascinating properties and in particular relate the continuous normal forms of typed to derivations of strong normalizability, which leads to new bounds on the height of these terms'' reduction trees. The talk is based on two recent articles by Klaus Aehlig and Felix Joachimski, available on http://www.mathematik.uni-muenchen.de/~joachski.\r\n\r\n[1] On continuous normalization. CSL 2002.\r\n[2] Continuous normalization in the untyped lambda-calculus and Godel''s T.',1,NULL);

INSERT INTO `seminar` VALUES (83,'2003-02-04','14:00','Robert Recorde Room','Martin Campbell-Kelly','http://www.dcs.warwick.ac.uk/~mck/','Warwick','http://www.dcs.warwick.ac.uk/pub/index.html','The Rise and Rise of the Spreadsheet','Every year, about 50 million spreadsheet programs are sold worldwide. Since the appearance of VisiCalc in 1979, the personal computer spreadsheet program has evolved into a software artifact of such bewildering complexity that few users can be sure that their spreadsheets are error free, and still fewer understand all their capabilities.\r\n\r\nSpreadsheet programs have eliminated much end-user programming, but unlike programming languages, there is no \"theory\" of spreadsheets and no processes of standardization. As a result, the modern spreadsheet is not a coherent design but an accretion of features \"selected\" by millions of users in a Darwinian-like process.\r\n\r\nThe seminar will trace the technical and social evolution of the spreadsheet from the time-sharing systems of the 1960s up to the present day.',1,NULL);

INSERT INTO `seminar` VALUES (84,'2003-02-11','14:00','Robert Recorde Room','Markus Roggenbach','http://www.informatik.uni-bremen.de/~roba','Bremen','http://www-compsci.swan.ac.uk/~csetzer/logic-server/bremen.html','CSP-CASL - A new Integration of Process Algebra and Algebraic Specification','CSP-CASL is a combination of the process algebra CSP and the algebraic specification language CASL following the paradigm `integrating a formalism for the concurrent aspects with algebraic specification of the static datatypes''. Its novel aspects are:\r\n\r\n   1. A process algebra is combined with the concept of loose specifications on the algebraic side. Thus, CSP-CASL is able to deal with data refinement/abstraction by restricting/extending the model class. Furthermore, CSP-CASL can express communication patterns depending on abstract data requirements.\r\n   2. CSP-CASL has a two-step semantics. This gives rise to a notion of refinement which can be decomposed in terms of the respective refinements in CASL and CSP.\r\n   3. Choosing a denotational semantics for CSP enables theorem proving for CSP. \r\n\r\nThe last two points aim for the reuse of HOL-CSP and HOL-CASL as components for theorem proving support of CSP-CASL refinement.\r\n\r\nA CSP-CASL specification consists of a data part, which is essentially a structured CASL specification, and a process part, which consists of a (recursive) CSP process, where CASL terms are used to describe communications. As usual, the concept of communication via channels is added as `syntactic sugar'': an optional channel part allows declaring (typed) channels. These declarations are translated into CASL datatypes, which provide the extra syntax needed for the CSP operations like sending or receiving data on a channel.\r\n\r\nThe above described structure of a CSP-CASL specification is reflected by its two-step semantics: The first step determines a class of models for the data part by the standard CASL semantics. The second fixes one of the obtained models, additionally fixes one of the denotational semantics of CSP and gives a meaning to the process part. Here, all CASL terms, sorts, ... occuring in the process part are interpreted according to the fixed model of the data part. The second step is generic in the various denotational CSP semantics. The semantics of a whole CSP-CASL specification is the family of all these interpretations.\r\n\r\nA crucial point of the CSP-CASL semantics is how to define the communication alphabet for the CSP semantics relative to a given CASL model. While a CASL model provides a carrier set for each sort, the CSP semantics expects all communications to be collected in one set. As a first approximation CSP-CASL takes the disjoint sum of all carrier sets as communication alphabet. Preserving the typing leads to identical process behavior for isomorphic CASL models. To model CASL subsorting, an equivalence relation is defined on this disjoint sum. The technical problem here is that CASL equations fail to be transitive at the syntactical level. Finally, to deal with partiality a (typed) communication `undefined'' is added: thus, definedness of communications is not treated as an external `well-formedness'' condition but can be proven within CSP-CASL.\r\n\r\nThe integration of CSP and CASL also provides interesting insights into both languages. Following the guideline that all kind of data arising in a CSP-CASL specification should be describable within CASL, CSP''s replicated operators like\r\n||_{i=1}^n P(i)\r\n\r\nare out of scope: CASL does not provide dependent types. In order to obtain `full CSP'' in CSP-CASL, a CASL extension would be necessary. Another point is that loose CASL specifications naturally lead to infinite carrier sets. Thus, CSP hiding might give rise to a non-wellformed CSP-CASL specification as the choosen underlying CSP semantics such as the failures/divergences model deals only with finitely nondeterministic CSP.',1,NULL);

INSERT INTO `seminar` VALUES (85,'2003-03-04','14:00','Robert Recorde Room','Anton Setzer','http://www-compsci.swan.ac.uk/~roba/index.html','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','An implementation of algebraic data types in Java using the visitor pattern',NULL,1,NULL);

INSERT INTO `seminar` VALUES (86,'2003-03-11','14:00','Robert Recorde Room','Steve Schneider','http://www.cs.rhbnc.ac.uk/research/formal/steve.html','Royal Holloway','http://www-compsci.swan.ac.uk/~csetzer/logic-server/london.html','CSP-B - A New Composition of Process Algebra and State-based Specification','This talk describes a way of using the process algebra CSP to control B machines and to enable interaction between them. This approach supports compositional verification: each of the controlled machines, and the combination of controller processes, can be analysed and verified separately in such a way as to guarantee correctness of the combined communicating system. Reasoning about controlled machines separately is possible due to the introduction of guards and assertions into the description of the controller processes in order to capture assumptions about other controlled machines and provide guarantees to the rest of the system. The verification process can be completely supported by different tools. The use of separate controller processes facilitates the iterative development and analysis of complex control flows within the system.',1,NULL);

INSERT INTO `seminar` VALUES (87,'2003-03-13','14:00','Robert Recorde Room','Oliver Kullmann','http://www.cs.swan.ac.uk/~csoliver/','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','Conflicts, propositional logic and linear algebra',NULL,1,NULL);

INSERT INTO `seminar` VALUES (88,'2003-03-17','14:00','Robert Recorde Room','Ulrich Berger','http://www-compsci.swan.ac.uk/~csulrich/','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','Teaching functional programming through Multimedia',NULL,1,NULL);

INSERT INTO `seminar` VALUES (89,'2003-03-20','14:00','Robert Recorde Room','Marco Mazzucco','mailto:marco@dmg.org','Swansea','http://www-compsci.swan.ac.uk/~csetzer/logic-server/swansea.html','Validating streaming XML documents.',NULL,1,NULL);

INSERT INTO `seminar` VALUES (19,'2006-05-02','14:00','Robert Recorde Room','Lihua You','','National Centre for Computer Animation, Bournemouth University','http://ncca.bournemouth.ac.uk/newhome/index.htm','Differential Equation Based Geometric Modelling and Computer Animation','Geometric modelling and computer animation based on solutions to differential equations have some advantages such as exact satisfaction of boundary constraints and unified description of geometric and physical attributes. In order to develop this modelling approach, we introduce physical properties into deformations and motion of objects, present mathematical models based on ordinary and partial differential equations, propose various resolution methods, discuss how geometric constraints, material properties and external forces affect deformations of objects, and investigate the applications of the proposed approach in wire modelling, surface generation, surface blending, surface manipulation, solid modelling and computer animation. \r\n\r\nDr. L. H. You is a senior research fellow of National Centre for Computer Animation, Bournemouth University.  His research interest is physics based computer graphics which includes elastic muscle deformation, ordinary differential equation based wire modelling, partial differential equation based surface modelling, solid modelling and dynamic modelling. ',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Lihua_You,sq,n.jpg');

INSERT INTO `seminar` VALUES (69,'2006-05-23','14:00','Robert Recorde Room','Pius ten Hacken','http://www.swan.ac.uk/french/home_pages/ten-hacken_home_page.html','Swansea','http://www.swan.ac.uk/french/','Formal Grammar and Semantics in Natural Language','In the study of the syntax and semantics of formal languages, repeated reference is made to concepts and techniques developed first of all for the analysis of natural language. In this talk I will sketch the original background of some of these concepts and show how the discussion of them in the field of linguistics has led to at least two different approaches to the study of grammar. Although Chomsky made some major contributions to the theory of formal grammars, the goals of his theory are incompatible with a purely formal approach to natural language. By contrast, the approach advocated by the followers of Richard Montague and Gerald Gazdar starts from the assumption that formal and natural languages share essential properties.',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Pius_ten_Hacken,sq,n.jpg');

INSERT INTO `seminar` VALUES (108,'2006-09-19','14:00','Board Room','Klaus Aehlig','','Swansea','','A Finite Semantics of Simply Typed Lambda Terms for Infinite Runs of Automata','Model checking properties are often described by means of finite automata. Any particular such automaton divides the set of infinite trees into finitely many classes, according to which state has an infinite run. Building the full type hierarchy upon this interpretation of the base type gives a finite semantics for simply-typed lambda-trees.\r\n\r\nA calculus based on this semantics is proven sound and complete. In particular, for regular infinite lambda-trees it is decidable whether a given automaton has a run or not. As regular lambda-trees are precisely recursion schemes, this decidability result holds for arbitrary recursion schemes of arbitrary level, without any syntactical restriction. This partially solves an open problem of Knapik, Niwinski and Urzyczyn.\r\n',2,'');

INSERT INTO `seminar` VALUES (109,'2006-11-28','14:00','Robert Recorde Room','Paul Cairns','http://www.uclic.ucl.ac.uk/','UCLIC UCL','http://www.uclic.ucl.ac.uk/','','',1,'');

INSERT INTO `seminar` VALUES (95,'2006-06-01','14:00','Robert Recorde Room','Steven Wall','http://www.dcs.gla.ac.uk/%7Esteven/','Glasgow University','http://www.dcs.gla.ac.uk/','Feeling What You Hear: Tactile Feedback for Navigation of Audio Graphs','Access to digitally stored numerical data is currently very limited for \r\nsight impaired people. Graphs and visualizations are often used to\r\nanalyze relationships between numerical data, but the current methods of\r\naccessing them are highly visually mediated. Representing data using\r\nsynthesised speech is a common method of making data more accessible,\r\nbut methods of navigating and accessing the data are often serial in\r\nnature and laborious. Tactile or haptic displays could be used to\r\nprovide additional feedback to support a point-and-click type \r\ninteraction for the visually impaired. In this talk I will discuss a\r\nrequirements capture conducted with sight impaired computer users at the\r\nRoyal National College for the Blind in Hereford, and discuss key\r\nfindings for using tactile feedback to aid navigation. These findings\r\nled to the design of a prototype accessible interface which has been\r\niteratively developed with input from the college over the last 12\r\nmonths. Providing an absolute position input device and tactile feedback \r\nallowed the users to explore graphs using tactile and proprioceptive\r\ncues in a manner analogous to point-and-click techniques.\r\n\r\nDr Steven Wall is a postdoctoral research fellow in the multimodal\r\ninteraction group at Glasgow University. He obtained a PhD from the\r\nDepartment of Cybernetics, University of Reading, for research on\r\nvirtual haptic display of material properties. He currently works on the \r\n\"Tactons\" project, investigating multimodal applications of tactile\r\ndisplay for accessibility. ',1,'');

INSERT INTO `seminar` VALUES (92,'2006-10-10','14:00','Robert Recorde Room','Robert S. Laramee','http://www.cs.swan.ac.uk/~csbob','Swansea','http://www.cs.swan.ac.uk/','Visualizing the Flow of Engine Simulation Data','This talk is divided into two parts.  In part one,\r\nwe investigate two important, common fluid flow patterns from computational \r\nfluid dynamics (CFD) simulations, namely, swirl and tumble motion typical of \r\nautomotive engines. We study and visualize swirl and tumble flow using three \r\ndifferent flow visualization techniques: direct, geometric, and \r\ntexture-based. When illustrating these methods side-by-side, we describe the \r\nrelative strengths and weaknesses of each approach within a specific spatial \r\ndimension and across multiple spatial dimensions typical of an engineer''s \r\nanalysis. Based on this investigation we offer perspectives on where and when \r\nthese techniques are best applied in order to visualize the behavior of swirl \r\nand tumble motion.\r\n\r\nIn part two, we present a visual analysis and exploration of fluid flow \r\nthrough a cooling jacket. Engineers invest a large amount of time and serious \r\neffort to optimize the flow through this engine component because of its \r\nimportant role in transferring heat away from the engine block. In this study \r\nwe examine the design goals engineers apply in order to construct, as closely \r\nas possible, the ideal cooling jacket geometry and apply a broad range of \r\nvisualization tools in order to analyze, explore, and present the results. We \r\nsystematically employ direct, geometric, texture-based flow visualization \r\ntechniques as well as automatic feature extraction and interactive \r\nfeature-based methodology and discuss the relative advantages and \r\ndisadvantages of these approaches as well as the challenges, both technical \r\nand perceptual involved with this application. The result is a feature rich \r\nstate-of-the-art flow visualization analysis applied to an important and \r\ncomplex data set from real-world computational fluid dynamics simulations.\r\n\r\nPlease come to the talk if you want to get some impression of what\r\nBob does.\r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (93,'2006-10-17','14:00','Robert Recorde Room','David A Watt','http://www.dcs.gla.ac.uk/~daw/','Glasgow','http://www.dcs.gla.ac.uk/~daw/','Flexible Typing in Object-Oriented Languages','In this talk I will introduce the concept of flexible typing, and explore its application in the context of a single-inheritance object-oriented language. Flexible typing enables a program to be partly statically typed and partly dynamically typed. This has important pragmatic benefits, for example it enables a single language to be suitable for both programming and scripting. I will show that flexible typing can be implemented in such a way that programs that make no use of dynamic typing pay no penalty in terms of run-time inefficiency or insecurity.',1,'');

INSERT INTO `seminar` VALUES (94,'2006-05-25','14:00','Robert Recorde Room','Uwe Wolter','','Bergen','http://www.ii.uib.no/','A Journey from Total to Partial Algebras ','Partial Algebras have the reputation of being difficult in theory and\r\npractice. Their bad reputation arises from the fact that many concepts\r\nknown from Total Algebras split up into at least three different\r\nconcepts in the context of Partial Algebras.\r\n\r\nIn our talk we argue that partiality is not too complicated at all.\r\nEspecially if seen from Algebraic Specification, Partial Algebras turn\r\nout to be only slighty more difficult to understand and to use than\r\nTotal Algebras.\r\n\r\nWe revise basic concepts and constructions such as algebra,\r\nhomomorphism, subalgebra, congruence, quotient algebra, initial\r\nalgebra, (conditional) equations,..., and discuss the changes emerging\r\nby moving from Total Algebras to Partial Algebras. ',1,NULL);

INSERT INTO `seminar` VALUES (1,'2005-09-20','14:00','Robert Recorde Room','Arnold Beckmann','http://www-compsci.swan.ac.uk/~csarnold/','Swansea','http://www.swan.ac.uk/compsci','Proofs, programs and abstract complexity','A meanwhile classical theme in mathematical logic is, that proving forall-exists-statements and defining recursive functions are related concepts. For \"classical\" theories of arithmetic and corresponding classes of sub-recursive functions, such connections can be obtained, for example, by proof theoretic means.\r\n\r\nIn my talk, I will speak about similar connections between weak theories of arithmetic (called bounded arithmetic [1]) and low level complexity functions (like the polynomial time hierarchy of functions). I will point out how these connections are related to certain abstract measures (called dynamic ordinals [2]) of the provability strength of such theories. In particular, I will mention connections to an enterprise called \"Cook''s NP versus coNP programme\" of proving lower bounds to propositional proof systems.\r\n\r\n[1] S. Buss: Bounded Arithmetic. Studies in Proof Theory. Lecture Notes, 3. Bibliopolis, Naples, 1986.\r\n\r\n[2] A. Beckmann: Dynamic ordinal analysis. Arch. Math. Logic 2003, 42: 303-334. ',1,'http://www.cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Beckmann,sq,n.jpg');

INSERT INTO `seminar` VALUES (28,'2005-03-15','14:00','Robert Recorde Room','Ali Abdallah','http://myweb.lsbu.ac.uk/~abdallae/','London South Bank','http://myweb.lsbu.ac.uk/','Refining Functions to Processes: models, methods, applications and challenges','The world of functions is usually based on abstract mapping between input and output values. The world of processes is usually based on concrete events and patterns of behaviour. The former is well suited for capturing specifications and expressing designs. The latter, on the other hand, is much more suited for describing implementations in conventional as well as in parallel and hardware forms. There is a need to have a better understanding of the relationship between these two worlds and, in particular, to establish a foundation for correctly refining functions to processes.\r\n\r\nIn this talk, we explore possibilities for modelling functions as processes and for defining the mathematical notion of refinement from functions to processes. We investigate algebraic laws and transformational methods which allow refinement to be compositional. The application of these methods are illustrated in the derivation of parallel algorithms and the synthesis of provably correct hardware circuits in FPGAs.',1,'http://www.cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Abdallah,sq,n.jpg');

INSERT INTO `seminar` VALUES (21,'2005-12-15','14:00','Robert Recorde Room','Ralf Botchen','http://wwwvis.informatik.uni-stuttgart.de/~botchen/','Stuttgart','http://wwwvis.informatik.uni-stuttgart.de/','Uncertainty Visualization','',1,'http://cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Botchen,sq,n.jpg');

INSERT INTO `seminar` VALUES (34,'2005-06-21','14:00','Robert Recorde Room','Jason Brotherton','http://www.cs.bsu.edu/homepages/brothert/','','','Your Life On Disk','The mantra of successful ubiquitous computing research has always included, \"Build, Deploy, and Evaluate.\" The key to building these ubicomp applications is to know as soon as possible if your idea or design is flawed (fail fast), and if so, how best to fix it. This is achieved through rapid prototyping and evaluating the impact of adding the technology in real world settings.\r\n\r\nThis is all fine and good, but the truth is that there are few examples of good ubicomp research (based on this mantra) in the literature. I claim that the reason for this is the applications built need to provide the services of many different applications, which are often complex programs in their own right. Then, additional code has to be written to ''glue'' these smaller applications together. In other words, the applications needed in ubicomp research are hard to build. (They are also hard to deploy and evaluate!)\r\n\r\nIn this talk, I will highlight two very different approaches to doing successful ubicomp research. One, the approach just described, is done in ivory towers with researchers. Another, more daring approach is to involve end users in the entire ''build, deploy, and evaluate'' process.\r\n\r\nSurprisingly, we believe this approach shortens the life cycle time and creates more usable ubicomp applications designed, conceived, and tested by users, but built by researchers. As an example, we will demonstrate this approach applied to the design of accessing your life on disk.',1,'http://www.cs.swan.ac.uk/~cswill/Pictures/VisitingSpeakers/testsite/Portrait,Brotherton,sq,n.jpg');

INSERT INTO `seminar` VALUES (7,'2005-11-08','14:00','Robert Recorde Room','Jolie de Miranda','http://web.comlab.ox.ac.uk/oucl/people/jolie.de.miranda.html','Oxford','http://web.comlab.ox.ac.uk/oucl/','The ''Safety'' Restriction',' Higher-order grammars were first introduced in the 1980s by Goerdt as a means of generating languages. A higher-order grammar consists of a set of typed rewrite rules and is classified as being of level n if the highest type level occurring in it is n. Level-0 grammars correspond to the regular languages and level-1 grammars correspond to the context-free. The infinite hierarchy of languages generated by higher-order grammars is often considered to be a more natural alternative to the Chomsky hierarchy of languages.\r\n\r\nRecently (Knapik, Niwinski, Urzyczyn 2001), the definition of higher-order grammars has been adjusted to generate more general structures: potentially infinite term trees, and this has generated much interest from communities in infinite-state verification.\r\n\r\nIn this talk we consider higher-order grammars in both settings (language-theoretic and verification-oriented) and consider the \"safety problem\". In both settings it has been shown that many good algorithmic and behavioural properties hold provided that the \"safety\" restriction is satisifed; here safety is a syntactic restriction on the rewrite rules of the higher-order grammar. However, very little is (was) known about the state of unsafe grammars. My thesis has made an attempt to rectify this situation.',1,'');

INSERT INTO `seminar` VALUES (96,'2006-06-05','12:00','407, SmallTalk Room','Professor Chandra Bajaj','http://www.cs.utexas.edu/~bajaj/','University of Texas, Austin','http://ccvweb.csres.utexas.edu/cvc/','Geometry, Signal Processing, Visualization for Modeling Bio-Molecular Interactions','The rapid proliferation of structural molecular data of the living cell in recent decades accelerates the need for adequate computational analytics to represent, manipulate and analyze these in ways that maximize their scientific utility.\r\nBiologically active molecules (proteins, nucleic acids, and their combination in macromolecular complexes) have distinct three-dimensional structures that  match and fit, and thereby determine their behavior and interactions with other molecules within their native cellular environment.\r\nMoreover, in order to successfully apply molecular structural information in areas such as drug discovery, and disease therapy, one must also be able to take into account energetic factors such as molecular electrostatic potentials and hydrophobicity in their native solvated environments, for more comprehensive biomolecular interactions.\r\n\r\nIn this talk I shall cover several geometric, signal processing and computational analysis algorithms that are required to support both the structural elucidation of atomic and quasi-atomic models of macromolecules from electron microscopy, and the verification, validation and visualization of flexible and dynamic models of bio-molecular and macromolecular interactions.',1,'');

INSERT INTO `seminar` VALUES (97,'2006-11-14','14:00','Robert Recorde Room','Joel Ouaknine','http://web.comlab.ox.ac.uk/oucl/people/joel.ouaknine.html','Oxford','http://web.comlab.ox.ac.uk/oucl/','The Cost of Punctuality ','In an influential paper titled \"The Benefits of Relaxing Punctuality\" (JACM 1996), Alur, Feder, & Henzinger introduced the logic Metric Interval Temporal Logic (MITL), which is a fragment of the real-time logic Metric Temporal Logic (MTL) in which the time constraints on operators are not allowed to be punctual, i.e., singleton sets. They produced an intricate proof (11 pages) that MITL model checking and satisfiability are decidable -- in fact EXPSPACE-COMPLETE. This has led to considerable further work; in the last year alone, both Hirshfeld & Rabinovich, and Maler, Nickovic, & Pnueli, published new and simpler decision procedures for MITL.\r\n\r\nAn obvious question to ask is, what happens if punctuality is allowed? Until recently, it was widely believed that the faintest presence of punctuality in any linear-time timed temporal logic would automatically lead to undecidability. Although this was recently disproved, until now no decidable punctual fragment of MTL was known to have even primitive recursive complexity (with certain fragments having provably non-primitive recursive complexity!).\r\n\r\nVery recently, in joint work with Patricia Bouyer, Nicolas Markey, and James Worrell, we have been able to precisely pinpoint the complexity of the main decidable punctual fragments of MTL. Our complexity bounds involve a connection between MTL formulas and reversal-bounded Turing machines. We will present an overview of these results and how they relate to standard (untimed) verification. ',1,'');

INSERT INTO `seminar` VALUES (98,'2006-07-07','14:00','Board Room','Marek Zaionc','http://www.ii.uj.edu.pl/~zaionc/','Jagiellonien University, Krakow','','Asymptotic densities in logic, examples and techniques','This talk presents numerous results from the area of\r\nquantitative investigations in logic and type theory. Â For the given\r\nlogical calculus (or type theory) we investigate the proportion of the\r\nnumber of distinguished formulas (or types) $A$ of a certain length $n$\r\nto the number of all formulas of such length. We are especially\r\ninterested in asymptotic behavior of this fraction when $n$ tends to\r\ninfinity. The limit $\\mu(A)$ if exists, is an asymptotic probability of\r\nfinding formula from the class $A$ among all formulas or the asymptotic\r\ndensity of the set $A$. Often the set $A$ stands for all tautologies of\r\nthe given logical calculus (or all inhabited types in type theory). In\r\nthis case we call the asymptotic of $\\mu(A)$ the \\emph{density of\r\ntruth}. Most of this research is concern with classical logic and\r\nsometimes with its intuitionistic fragments but there are also some\r\nattempts to examine modal logics. To do that we use methods based on\r\ncombinatorics, generating functions and analytic functions of complex\r\nvariable with the special attention given to singularities regarded as\r\na key determinant to asymptotic behavior. We are going to analyze\r\nexamples of results obtained by extensive use of generating functions\r\n(singularities) analysis for certain logics.',2,'');

INSERT INTO `seminar` VALUES (100,'2006-10-24','14:00','Robert Recorde Room','Alan Dix','http://www.comp.lancs.ac.uk/computing/users/dixa/','Lancaster','http://www.comp.lancs.ac.uk/','Intelligent context-sensitive interactions on desktop and the web','Intelligent context-sensitive interactions on desktop and the web\r\n\r\nI will describe briefly three systems: onCue a desktop\r\ninternet-access toolbar, Snip!t a web-based bookmarking application\r\nand ontoPIM an ontology-based personal task-management system.  These\r\nembody context issues to differing degrees, and we use them to\r\nexemplify more general issues concerning the use of contextual\r\ninformation in ''intelligent'' interfaces. We look at issues relating\r\nto interaction and ''appropriate intelligence'', at different types of\r\ncontext that arise and at architectural lessons we have learnt. I\r\nwill also highlight outstanding problems, in particular the need to\r\ncomputationally describe and communicate context where reasoning and\r\ninference is distributed.\r\n\r\nDepending on how much I digress during the former (!) I will also\r\nmention some ongoing work on mining semantics from folksonomies.\r\n',1,'');

INSERT INTO `seminar` VALUES (101,'2006-09-12','14:00','Robert Recorde Room','Yoshinao Isobe','http://staff.aist.go.jp/y-isobe/','AIST, Japan','http://www.aist.go.jp/index_en.html','A complete axiomatic semantics for the CSP stable-failures model','Traditionally, the various semantics of the process algebra CSP are\r\nformulated in denotational style. For many CSP models, e.g., the\r\ntraces model, equivalent semantics have been given in operational\r\nstyle. A CSP semantics in axiomatic style, however, has been\r\nconsidered problematic in the literature.\r\n\r\nIn this paper we present a sound and complete axiomatic semantics for\r\nCSP with unbounded nondeterminism over an alphabet of arbitrary\r\nsize.\r\n\r\nThis result is connected in various ways with our tool CSPProver: (1)\r\nthe CSP dialect under discussion is the input language of CSPProver;\r\n(2) all theorems presented have been verified with CSPProver; (3)\r\nCSPProver implements the given axiom system.\r\n',3,'');

INSERT INTO `seminar` VALUES (102,'2006-09-28','14:00','Robert Recorde Room','Markus Roggenbach','http://www.cs.swan.ac.uk/~csmarkus/','Swanses','http://www.swan.ac.uk/compsci/','CSP-CASL: Semantics, Application, Tools','TBA',3,'');

INSERT INTO `seminar` VALUES (103,'2006-10-12','14:00','Robert Recorde Room','Pius ten Hacken','http://www.swan.ac.uk/french/home_pages/ten-hacken_home_page.html','Swansea','http://www.swan.ac.uk/french/','Computational Linguistics as an Applied Science','An applied science is opposed on the one hand to an empirical science and on the other to technology. It shares with the former its concern for explanation and with the latter its concern for solving practical, real-life problems. A prototypical example is medicine, where the purpose of research activity is both to find cures and to explain how they work. Whereas computational linguistics (CL) can also be pursued as an empirical science or used as mere technology, it is most interesting as an applied science.\r\n\r\nAn area in CL in which the development towards an applied science is particularly obvious is machine translation (MT). By considering the main stages of the history of MT I will show how they can be analysed in this perspective.',3,'');

INSERT INTO `seminar` VALUES (104,'2006-12-12','14:00','Robert Recorde Room','Oliver Kullmann','http://www.cs.swan.ac.uk/~csoliver/','Swansea','http://www.swan.ac.uk/compsci/','Between constraints and satisfaction','I want to give an overview on the more practical aspects of my current work: Developing\r\n  new algorithms and frameworks for hard constraint satisfaction and satisfiability problems,\r\n  and implementing a generative (C++) library (the OKlibrary) based on these ideas.\r\n  The algorithmic ideas will be explained using easy examples, for example Sudoku\r\n  problems (which are interesting when they are bigger).\r\n\r\n  The title should be more accurately ``Between constraints and satisfiability'''', where\r\n  ``constraints'''' refers to the world of constraint satisfaction, with its emphasise on modularity\r\n  and a (certain degree of) abstraction, while ``satisfiability'''' refers to be world of (boolean)\r\n  satisfiability problems, with its emphasise on algorithms, complexity and implementations.\r\n  One of the main goals of the new algorithmic framework is to unify these two worlds, based\r\n  on new concepts of ``generalised satisfiability problems''''.\r\n\r\n  These ideas are developed in strong interaction with the development of the OKlibrary, which\r\n  is a generic library (strongly based on abstract data types) and also a generative library (the\r\n  library is not static, but has a lot of computational power to be flexible and adaptive). One\r\n  of the main novelties here (purely on the software engineering side) is a framework for\r\n  ``higher order unit testing'''', which fully integrates unit testing into a generic library.',1,'');

INSERT INTO `seminar` VALUES (105,'2006-10-31','14:00','Robert Recorde Room','Les Carr','http://www.ecs.soton.ac.uk/~lac/','Southampton','http://www.ecs.soton.ac.uk/','Open Access: past, present, future','Open Access is the attempt to improve usage of the scholarly and scientific literature by making it free at the point of delivery (either by pay-to-publish economic models for journals or by author-self archiving in institutional repositories). Although the Open Access initiative was born in Budapest in 2001, attempts to adapt technology to improve access to the literature go back many decades before that.\r\n\r\nThis talk attempts to set Open Access in a context of earlier activities and shows the relationship between the current Open Access landscape (institutional repositories) and e-Science, the Semantic Web and Memories for Life.\r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (106,'2006-12-05','14:00','Robert Recorde Room','Alun Preece','http://www.csd.abdn.ac.uk/~apreece/','Aberdeen','http://www.csd.abdn.ac.uk/','Policing Commitments in Virtual Organisations ','Commitment management and policing are key issues in the management of\r\nagent-mediated virtual organisations (VOs). A service-provider - which\r\nmay be a single agent acting within an organisation, or the VO acting as\r\na collective whole - manages particular resources, and commits these\r\nresources to meet specific goals. Commitments can be modelled as\r\nconstraints on resources. Such constraints are often soft: they can be\r\nbroken if necessary. When an agent breaks a commitment, it will be in\r\nbreach of contract. Service-provisioning domains are often not fully\r\nobservable, featuring incomplete logging of events, or unreliable\r\nsensors. In such domains, the process of identifying which agent is to\r\nblame for breach of contract is essentially one of argumentation: agents\r\nare able to advance arguments on their views of the state of the\r\nenvironment. When a disagreement occurs, they may be able to probe the\r\nenvironment state. By associating utility with both probing actions and\r\nwinning the argument, a strategy for argumentation can be defined.\r\n\r\nIn this talk, I will present an integrated framework for representing\r\nand reasoning about commitments, and monitoring contracts in\r\npartially-observable domains using argumentation and subjective logic.\r\nThis framework has been applied in various \"e-domains\": e-business,\r\ne-science, and e-response. ',1,'');

INSERT INTO `seminar` VALUES (107,'2006-05-19','14:00','Board Room','Uwe Wolter','','Bergen','','From Universal Algebra to Lawvere Theories','\"Lawvere Theories\" introduced by by F.William Lawvere in his PhD thesis in 1963 are an outcome of three crucial observations concerning Universal Algebra: An algebra is an interpretation of syntactical entities in the semantical domain of sets. The syntactical entities \"signature\", \"variable\", and \"term\" reflect the formation of cartesian products of sets. And substitution of variables by terms reflects the composition of term functions.\r\n\r\nIn the talk we show how a many-sorted algebraic signature SIG gives rise to a Lawvere Theory C(SIG) with products where the objects are lists of sort names, the morphisms are (tuples of) terms, and composition is given by substitution. This categorical reformulation turns SIG-algebras into product preserving functors from Ã‚ C(SIG) into the category SET and SIG-homomorphisms into natural transformations between those functors. Moreover, term algebras are reconstructed as hom-functors and the \"recursion theorem\" (uniqueness of term evaluation) turns out to be an instance of Yoneda''s Lemma. This construction can be extended to equational specifications (SIG,EQ) if we consider equivalence classes of (tuples of) terms as morphisms.\r\n\r\nWe will discuss some benefits (and drawbacks) of this categorical reformulation of Universal Algebra. And, if there is time left, we will sketch some more topics as Tensor Products of Theories, 2-categorical Lawvere Theories (the categorical counterpart of term rewriting) and Sketches (the categorical counterpart of equational specifications). ',2,'');

INSERT INTO `seminar` VALUES (110,'2006-04-04','11:00','Board Room','Jan Johannsen','','LMU Munich','','An infinite hierarchy in the linear time mu-calculus','The notion of the next-rank of a formula in the linear time mu-calculus muTL is introduced, and the fragments muTL(r) of formulas of next-rank at most r are studied. It is shown that muTL(1) is equivalent to LTL, and that the hierarchy of fragments muTL(r) is infinite. The proof utilizes a translation of muTL into certain restricted alternating Buechi automata. As a corollary to the construction, it follows that every formula in muTL is equivalent to a formula without nested fixpoints, and thus muTL collapses to its one-variable fragment.',2,'');

INSERT INTO `seminar` VALUES (111,'2006-03-28','14:00','Board Room','Paul Taylor','','Manchester','','Abstract Stone Duality and Real Analysis','We argue that Dedekind completeness and the Heine--Borel property should be seen as part of the ``algebraic'''' structure of the real line, along with the usual arithmetic operations and relations. Dedekind cuts provide a uniform and natural way of formulating differentiation, integration and limits. They and these examples also generalise to intervals. Together with the arithmetic order, cuts enjoy proof-theoretic introduction and elimination rules similar to those for lambda abstraction and application. This system completely axiomatises computably continuous functions on the real line.\r\n\r\nWe show how this calculus (of ``single'''' points) can be translated formally into Interval Analysis, interpreting the arithmetic operations a la Moore, and compactness as optimisation under constraints. Notice that interval computation is the conclusion and not the starting point.\r\n\r\nThis calculus for the real line is part of a more general recursive axiomatisation of general topology called Abstract Stone Duality.',2,'');

INSERT INTO `seminar` VALUES (112,'2006-03-30','14:00','Board Room','Peter Fritzson and Adrian Pop','','LinkÃ¶ping','','PELAB - the Programming Environment Lab','The RML environment\r\n\r\n    Tools for generating efficient language implementations from Structured Operational Semantics, including tools for debugging and teaching specifications. \r\n\r\nRML is a meta language for Structured Operational Semantics including Natural Semantics. It is strongly typed, polymorphic, deterministic, efficient, and is being used for writing language specifications ranging from small specifications of a few lines to large specifications of around 85 000 lines. It is being used successfully for a range of languages like Java, Modelica (equation-based), C subset with pointer arithmetic, MiniML, lambda calculus, etc. The language originates from research at PELAB in generating efficient compilers from specifications, see also LNCS #1549.\r\n\r\nExtensive experience of writing large executable specifications using RML has shown that an efficient meta-language is not enough for practical usage. There is also a need to debug large specifications, to browse specifications for understanding, to teach specifications using teaching material that allows explanatory text combined with specifications that can be evaluated interactively. During the talk we will present the RML language and demonstrate tools for compiler/interpreter generation, an RML debugger, and ongoing work on an Eclipse plugin for specification writing in RML, as well as a WYSIWYG teaching tool for literate programming of specifications in active documents. (See also www.ida.liu.se/labs/pelab/rml) ',2,'');

INSERT INTO `seminar` VALUES (113,'2006-03-23','14:00','Board Room','Anton Setzer','','Swansea','','Inductive-Recursive Definitions (Part II)','Inductive-recursive definitions were developed by P. Dybjer as a concepts which formalises the principle for introducing sets in Martin-Loef Type Theory. Indexed inductive-recursive definitions extend this principle by the possibility, to introduce simultaneously several sets inductive-recursively.\r\n\r\nAll sets definable in the core of Martin-Loef type theory, which is accepted by most researchers in this area, are instances of indexed inductive-recursive definitions. It contains as well many extensions, for instance Erik Palmgren''s superuniverses and higher universes. Many data types which are used in programming and theorem proving are instances of indexed inductive-recursive definitions, e.g. the accessible part of an ordering, Martin-Loef''s computability predicate, which was used in his normalisation proof for one version of Martin-Loef type theory, and Bove and Carpretta''s formalisation of partial functions in type theory.\r\n\r\nIn this lecture we will introduce the notions of inductive-recursive definitions and indexed inductive-recursive definitions. We will show how to introduce inductive-recursive defintions using finitely many rules. ',2,'');

INSERT INTO `seminar` VALUES (114,'2006-03-16','14:00','Board Room','Anton Setzer','','Swansea','','Inductive-Recursive Definitions (joint work with Peter Dybjer, Gothenburg)','Inductive-recursive definitions were developed by P. Dybjer as a concepts which formalises the principle for introducing sets in Martin-Loef Type Theory. Indexed inductive-recursive definitions extend this principle by the possibility, to introduce simultaneously several sets inductive-recursively.\r\n\r\nAll sets definable in the core of Martin-Loef type theory, which is accepted by most researchers in this area, are instances of indexed inductive-recursive definitions. It contains as well many extensions, for instance Erik Palmgren''s superuniverses and higher universes. Many data types which are used in programming and theorem proving are instances of indexed inductive-recursive definitions, e.g. the accessible part of an ordering, Martin-Loef''s computability predicate, which was used in his normalisation proof for one version of Martin-Loef type theory, and Bove and Carpretta''s formalisation of partial functions in type theory.\r\n\r\nIn this lecture we will introduce the notions of inductive-recursive definitions and indexed inductive-recursive definitions. We will show how to introduce inductive-recursive defintions using finitely many rules. ',2,'');

INSERT INTO `seminar` VALUES (115,'2006-02-23','14:00','Board Room','Peter Mosses','','Swansea','','Programming Language Description Languages: From Scott and Strachey to Semantics Online','Since the middle of the last century, hundreds of programming languages have been designed and implemented - and new ones are continually emerging. The syntax of a programming language can usually be described quite precisely and efficiently using formal grammars. However, the formal description of its semantics is much more challenging. Language designers, implementers, and programmers commonly regard precise semantic descriptions as impractical and too costly. Research in semantics has allowed us to reason about software and has provided valuable insight into the design of programming languages, but few semantic descriptions of full languages have been published, and hardly any of these are currently available online.\r\n\r\nOne of the major approaches to formal semantics is denotational semantics, developed by Scott and Strachey in the late 1960s. Why has such a theoretically attractive approach been found impractical for describing full-scale programming languages? Does it help much to use monads in denotational descriptions, or is a more radical change needed? How might efficient online access to a repository of semantic descriptions be provided? Could it ever become as easy to generate efficient compilers and interpreters from semantic descriptions as it already is to generate parsers from grammars? This talk addresses such questions, and gives some grounds for optimism about the development of highly practical, online semantic descriptions.\r\n\r\n(This is a preliminary version of a talk to be given as a BCS-FACS Evening Seminar in London next month.) ',2,'');

INSERT INTO `seminar` VALUES (116,'2006-02-16','14:00','Board Room','Oliver Kullmann and Matthew Henderson','','UWS','','A generative library for generalised SAT solving: Software engineering, algorithms and mathematics','We give a short introduction what the OKlibrary can do (for the world and for you; in the future), and where we are now. ',2,'');

INSERT INTO `seminar` VALUES (118,'2006-10-12','14:00','Robert Recorde Room - Talk in the Algebraic Specification Seminar','Pius ten Hacken','','Dept of French, Swansea','','','',2,'');

INSERT INTO `seminar` VALUES (120,'2006-09-28','14:00','Robert Recorde Room - Talk in the Algebraic Specification Seminar','Markus Roggenbach','','Swansea','','','',2,'');

INSERT INTO `seminar` VALUES (122,'2006-02-06','14:00','Board Room','Will Harwood','','Swansea','','Ordinal Bounds for Dickson''s Lemma','In a previous seminar it was claimed -- with handwaving but little actual mathematics -- that the ordinal bound on non-dominating sequences of n-tuples is $\\omega^n$ (a tighter version of Dickson\\''s Lemma, which simply states that any such sequence is finite). This Thursday\\''s seminar will furnish a proof.',2,'');

INSERT INTO `seminar` VALUES (117,'2006-10-19','14:00','Board Room','Jens Blanck','','Swansea','','Centred dyadic approximations','Approximations based on dyadic centred intervals are investigated as a means\r\nfor implementing exact real arithmetic. It is shown that the field operations\r\ncan be implemented on these approximations with optimal or near optimal\r\nresults. Bounds for the loss in quality of approximations for each of the\r\nfield operations are also given. These approximations can be used as a more\r\nefficient alternative to endpoint based implementations of interval analysis.',2,'');

INSERT INTO `seminar` VALUES (123,'2006-10-19','14:00','Board Room - - in cooperation with the PCV Seminar','Jens Blanck','http://www.swan.ac.uk/compsci/people/homepage.php?staff=J.Blanck','Swansea','http://www.swan.ac.uk/compsci/','Centred dyadic approximations','Approximations based on dyadic centred intervals are investigated as a means\r\nfor implementing exact real arithmetic. It is shown that the field operations\r\ncan be implemented on these approximations with optimal or near optimal\r\nresults. Bounds for the loss in quality of approximations for each of the\r\nfield operations are also given. These approximations can be used as a more\r\nefficient alternative to endpoint based implementations of interval analysis.',3,'');

INSERT INTO `seminar` VALUES (99,'2007-04-24','14:00','Robert Recorde Room','Cliff Jones','http://www.cs.ncl.ac.uk/people/home.php?name=cliff.jones','Newcastle','http://www.cs.ncl.ac.uk','A structural proof of the soundness of rely/guarantee rules ','The challenge of finding compositional ways of (formally) developing concurrent programs is considerable. Various forms of rely and guarantee conditions have been used to record and reason about interference in ways which do indeed provide compositional development methods for such programs. This paper presents a new approach to justifying the soundness of rely/guarantee inference rules. The underlying concurrent language is defined by an operational semantics which allows fine-grained interleaving and nested concurrency; the proof that the rely/guarantee rules are consistent with that semantics (including termination) is by a structural induction.\r\n\r\nA lemma which relates the states which can arise from the extra interference that results from taking a portion of the program out of context is key to our ability to do the proof without having to perform induction over the computation history. This lemma also offers a way to understand some elusive expressibility issues around rely guarantee conditions. ',1,'');

INSERT INTO `seminar` VALUES (126,'2006-11-30','14:00','Robert Recorde Room - Talk in the Algebraic Specification Seminar','Temesghen Kahsai','','Swansea','','','',2,'');

INSERT INTO `seminar` VALUES (128,'2006-11-30','14:00','Robert Recorde Room','Temesghen Kahsai','http://www.cs.swan.ac.uk/~csteme/','Swansea','http://www.swan.ac.uk/compsci/','Towards semi automated equivalence checking of spi calculus processes','We model the notion of Framed Bisimulation in the interactive theorem\r\nprover Isabelle using the logic HOL-Nominal. Framed Bisimulation was\r\nintroduced in 1998 by Abadi and Gordon, who used it in order to reason\r\nabout cryptographic protocols formulated in Spi-Calculus. The logic\r\nHOL-Nominal is a novel way of reasoning for calculi with binding\r\noperators, such as Lambda calculus, Pi-calculus, and\r\nSpi-calculus. Based on HOL-Nominal, we have developed a proof\r\nenvironment which automates part of the decision procedure if two\r\nprocesses are equivalent w.r.t. Framed Bisimulation. In our work we\r\nuse some of the ideas of Huttel''s algorithm for deciding the\r\nbisimilarity between processes. In particular, we decrease the search\r\nspace during the proof. Our proof environment makes it possible to\r\nwrite proofs in Isabelle which closely correspond to the (traditional)\r\nmanual proofs presented in the literature.\r\n\r\n\r\n',3,'');

INSERT INTO `seminar` VALUES (129,'2006-10-26','14:00','Robert Recorde Room','Jens Blank','','Swansea','','Centred dyadic approximations, part II','The talk given on October 19, 2006 will be continued.',2,'');

INSERT INTO `seminar` VALUES (121,'2006-11-02','14:00','Board Room','Christiano Braga','http://maude.sip.ucm.es/~cbraga/','Universidad Complutense de Madrid ','','Implementing Modular SOS ***TALK CANCELLED***','Modular SOS (MSOS) is a formalism that allows Structural Operational Semantics specifications to be written in a modular way. In the context of the specification of programming language semantics, a modular specification intuitively means that the transition rules for a given programming language construct can be given \"once and for all\". An extension to a semantics specification that adds new constructs and requires new semantic entities does not imply a reformulation of the existing rules. For instance, a specification of constructs that reflects functional aspects of a programming language, such as declarations and applications, can be extended in with imperative constructs, such as assignment, without any change to the transition rules that give semantics to the functional constructs.\r\n\r\nIn this talk we report on the development of the Maude MSOS Tool (MMT), an execution environment for MSOS specifications using the Maude system, a high performance implementation of Meseguer''s Rewriting Logic. MMT is implemented in Maude as a (semantics preserving) meta-function that transforms Modular SOS specifications into Maude modules thus allowing the execution and analysis of MSOS specifications using Maude''s built-in tools (rewriting modulo theories, state search, and LTL model-checking) and user-defined tools, such as the strategy language interpreter.\r\n\r\nAs a non-trivial case study, we will report on an implementation of Mosses''s Constructive approach to programming language semantics in MSOS, or Constructive MSOS, using MMT. The Constructive approach defines basic language constructs that capture common programming language features. Within this approach, the semantics of a programming language is defined by semantic functions that relate constructs in a given programming language to the basic constructs. MMT provides tool support for constructive programming language design using Modular MSOS as underlying semantic framework.\r\n\r\nThe MMT home page is at http://maude-msos-tool.sourceforge.net/\r\n',2,'');

INSERT INTO `seminar` VALUES (124,'2006-11-02','14:00','Board Room - in cooperation with the PCV Seminar','Christiano Braga','http://maude.sip.ucm.es/~cbraga/','Universidad Complutense de Madrid','','Implementing Modular SOS ***TALK CANCELLED***','---see announcement in the PCV seminar series---',3,'');

INSERT INTO `seminar` VALUES (119,'2006-11-16','14:00','Board Room ','Diana Ratiu','http://www.mathematik.uni-muenchen.de/~ratiu/','LMU Munich','','A-Translation - From Theory to Practice and Back','We overview the refined A-Translation method for uncovering the\r\ncomputational content in the classical proofs, thus enabling the extraction of\r\nalgorithms from them. We will briefly present the successful application of\r\nA-Translation on the base case proof for Dickson''s Lemma and then suggest a\r\ngeneralisation of the lemma. This later part refers to work in progress, since\r\nwe aim at extensions of the conditions which the refined A-Translation imposes,\r\nsuch that the method becomes applicable to a larger scale of proofs. ',2,'');

INSERT INTO `seminar` VALUES (130,'2006-11-28','14:00','Board Room','Paul Taylor','','Manchester','','The definitive axiomatisation for ASD (maybe)','ASD has provided the complete axiomatisation of the category\r\nof computably based locally compact locales and (with the \"underlying set\"\r\naxiom) that of locally compact locales over an elementary topos.  Key\r\nto this (and also to the Heine--Borel theorem in recursive topology)\r\nis the requirement that the adjunction $\\Sigma^{-}\\dashv\\Sigma^{-}$ be\r\nmonadic.\r\n\r\nThe generalisation of this theory beyong local compactness has been \r\nproblematic.  Somehow, this monadic condition, which ensures that\r\n(certain) subobjects carry the subspace topology, needs to be generalised.\r\nOver a number of years, I experimented with several possible axioms,\r\nwhich looked very pretty but had neither models nor consistency proofs.\r\nNow I believe I have the solution - the original monadicity property,\r\nexcept now with all finite limits in the category.  The test of this\r\nwill be the characterisation of the free model, which appears to be\r\nthe monadic completion of Scott''s category of equilogical spaces.\r\n\r\n\r\n(See also www.cs.man.ac.uk/~pt/ASD/extension.html)\r\n',2,'');

INSERT INTO `seminar` VALUES (127,'2006-12-14','14:00','Board Room','Jan Juerjens','','The Open University, Milton Keynes','','Verifying Cryptoprotocol Implementations in First-Order Logic','Understanding the security goals provided by cryptographic protocol\r\nimplementations is known to be difficult, since security requirements\r\nsuch as secrecy, integrity and authenticity of data are notoriously\r\nhard to establish, especially in the context of cryptographic\r\ninteractions. A lot of research has been devoted to develop formal\r\ntechniques to analyze abstract specifications of cryptographic\r\nprotocols. Less attention has been paid to the analysis of\r\ncryptoprotocol implementations, for which a formal link to\r\nspecifications is often not available. We present work towards\r\nverifying crypto protocol implementation against security\r\nrequirements using automated theorem provers for first-order\r\nlogic, and discuss some interesting aspects of its underlying\r\nmodel-theoretic foundations.',2,'');

INSERT INTO `seminar` VALUES (131,'2007-02-27','14:00','Robert Recorde Room','Roderick Murray-Smith','http://www.dcs.gla.ac.uk/~rod','Glasgow University','','Negotiated, mobile interaction: model-based approaches which allow','I will present an approach to the design of interaction which uses\r\ndynamic systems theory to design and calibrate the closed-loop behaviour\r\nof instrumented hand-held systems with which the user interacts in a\r\ncontinuous fashion. I will look at multimodal feedback loops, which also\r\nsupport feedback of uncertain information, making this approach useful\r\nfor incorporation of machine learned models, or Bayesian networks.\r\nExamples will be given which run on PocketPCs instrumented with\r\naccelerometers and GPS, and which use both audio (granular synthesis)\r\nand vibrotactile feedback. Further examples will look at synchronization\r\neffects in walking behaviour during mobile phone conversations,\r\ntext-entry in Brain-Computer interfaces and continuous, uncertain\r\ninteraction with information at spatial locations in our gpsTunes\r\nsystem.',1,'');

INSERT INTO `seminar` VALUES (133,'2007-02-06','14:00','Robert Recorde Room','Jens Blanck','http://www.swan.ac.uk/compsci/people/homepage.php?staff=J.Blanck','Swansea','http://www.swan.ac.uk/compsci/','Computability, domains, topology','Domains are partially ordered structures that have a natural computability \r\ntheory. From another perspective, domain theory is a theory of approximations \r\nand domains are therefore useful as representations of uncountable spaces. \r\nThus, there is an obvious connection from computability to topology via \r\ndomains.\r\n\r\nTotal domain elements may be seen as representations (or realisers) of points \r\nin the topological space while the finite (compact) objects of a domain often \r\nretain countability allowing computations to be performed on the domains.\r\n\r\nWe will look at the basic framework, with basic examples including metric \r\nspaces, and discuss how to recognise good domain representations.',1,'');

INSERT INTO `seminar` VALUES (134,'2007-02-22','14:00','Robert Recorde Room','Tobias Nipkow','http://www4.in.tum.de/~nipkow/','TU Muenchen','http://www4.in.tum.de/index_en.shtml','Verifying a Hotel Key Card System ','Two models of an electronic hotel key card system are contrasted: a state based and a trace based one. Both are defined, verified, and proved equivalent in the theorem prover Isabelle/HOL. It is shown that if a guest follows a certain safety policy regarding her key cards, she can be sure that nobody but her can enter her room.',1,'');

INSERT INTO `seminar` VALUES (135,'2007-03-06','14:00','Robert Recorde Room','Martin Campbell-Kelly','http://www.dcs.warwick.ac.uk/~mck/','Warwick','http://www.dcs.warwick.ac.uk/','The History of Software Patents','This seminar is intended to place the current debates about software patents in the historical context of patenting in the information technology industries. \r\nThe first computer-program products were sold in the mid 1960s when software patents were not generally allowed, and as a result trade secrecy became endemic to the software industry. Software products were also protected by copyright, but in practice this offered little protection against most forms of appropriation by reverse engineering or cloning. By the early 1980s a series of landmark cases led to the acceptance of software patents. It is argued that this development was consistent with the patenting of algorithmic inventions that long predated the invention of the computer. In the 1990s, business method patents were accepted. Again, this development was consistent with the \"virtualization\" of inventions that long predated the Internet. Although patents offer similar benefits to the software industry as for other technological industries, there are some old and new disadvantages. ',1,'');

INSERT INTO `seminar` VALUES (137,'2007-02-20','14:00','Robert Recorde Room','Roger Hindley','','Swansea','','Introduction to the Lambda Calculus','',3,'');

INSERT INTO `seminar` VALUES (138,'2007-03-08','14:00','Robert Recorde Room','Roger Hindley','','Swansea','','Lambda Calculus II ','',3,'');

INSERT INTO `seminar` VALUES (139,'2007-03-08','14:00','Robert Recorde Room','Roger Hindley','','Swansea','','Lambda Calculus II ','',2,'');

INSERT INTO `seminar` VALUES (140,'2007-05-01','14:00','Robert Recorde Room','Rynson Lau','','University of Durham','','A Streaming-based Distributed Virtual Environment to support collaboration','\r\nExisting DVE applications, such as online games, typically require the complete content to be installed in a client machine before the user may participate in the application. However, as the database of the DVE application grows larger and larger, it is either taking a long time to download the whole database or requiring the users to obtain a CDROM/DVDROM of the database through some means.\r\n\r\nIn this seminar, I will first summarize our earlier work to develop a streaming-based DVE. Based on the location of the user in the virtual environment, the system streams the local geometry to the user''s client machine in an on-demand fashion. This streaming-based architecture allows quick browsing of 3D worlds in a way similar to browsing web pages. I will then discuss our recent work to improve the performance of the DVE system and to extend it to support collaboration over the Internet.',1,'');

INSERT INTO `seminar` VALUES (142,'2007-03-15','14:00','Board Room','Heribert Vollmer','http://www.thi.uni-hannover.de/mitarbeiter/vollmer/','Universit&auml;t Hannover','http://www.thi.uni-hannover.de/','The Complexity of Deciding if a Boolean Function Can Be Computed by Circuits over a Restricted Basis','We study the complexity of the following algorithmic problem: Given a Boolean function $f$ and a finite set of Boolean functions $B$, decide if there is a circuit with basis $B$ that computes $f$. We show that if both $f$ and all functions in $B$ are given by their truth-table, the problem is in quasipolynomial-size AC$^0$, and thus cannot be hard for AC$^0(2)$ or any superclass like NC$^1$, L, or NL. This answers an open question by Bergman and Slutzki (SIAM J.~Comput., 2000). Furthermore we show that, if the input functions are not given by their truth-table but in a succinct way, i.e., by circuits (over any complete basis), the above problem becomes complete for the class coNP.',2,'');

INSERT INTO `seminar` VALUES (150,'2007-05-15','14:00','Robert Recorde Room','Parisa Eslambolchilar','http://www.swan.ac.uk/compsci/people/homepage.php?staff=P.Eslambolchilar','Swansea University','http://www.swan.ac.uk/compsci/','Engineering of Human-Computer Interaction','As the technology grows the gap between what the human user wants and what\r\nthe designer develops and delivers to the user grows more. What\r\ndistinguishes interactive systems from the other classes of systems is the\r\nuser and usability of the system. However, many successful computer\r\ninterfaces that have been developed based on many experimental tests over\r\na considerable amount of time their results cannot be generalised even to\r\nsimilar interfaces.\r\n\r\nThis talk highlights the fact that we need a solid theoretical foundation\r\nthat combines an understanding of the content of use with particular\r\nattention to the details of interaction and human behaviour, supported by\r\nrobust interaction architecture. This talk argues that engineering of\r\ninteraction based on control theory, which have been overlooked in\r\nHuman-Computer Interaction research, is one possible solution.',1,'');

INSERT INTO `seminar` VALUES (144,'2007-07-03','14:00','Robert Recorde Room','Mike Twidale','','University of Illinois','http://people.lis.uiuc.edu/~twidale/','xTreme Research','What happens when we take some of the ideas from eXtreme Programming\r\nand apply them in related contexts, like interface design,\r\nevaluation, user studies, ethnography, analysis, theory-building and\r\nother aspects of the research process? How is the way we currently\r\nconduct research like a classic 20th century Fordist optimized\r\nproduction line? When is that a Good Thing and when is that a Bad\r\nThing? How might we take 21st century, post-Fordist industrial and\r\nservice production models and apply them to research?\r\n\r\nHow might we use mashups, YouTube, blogging, wikis, Second Life,\r\nother web 2.0 apps,  minimalist user studies, single examples,\r\nmetaphors and reframing to undertake a different kind of rapid\r\nprototyping and evaluation? How might that help us in doing better\r\ncomputer science and apply insights from informatics research to the\r\ndevelopment of better products, infrastructures and socio-technical systems?\r\n\r\nBy looking at some examples of rapid, minimalist lightweight\r\napproaches to addressing or uncovering research questions, this talk\r\nwill try to explore some ideas of different ways we might go about\r\ndoing research.',1,'');

INSERT INTO `seminar` VALUES (125,'2007-02-15','14:00','Board Room ','Ulrich Berger','http://www.cs.swan.ac.uk/~csulrich/','Swansea','','Truth in Higher Types','In recent years a new brach of proof theory, dubbed\r\n\"proof mining\", has gained considerable popularity.\r\nIn proof mining one extracts computational content from proofs\r\nin order to obtain formally verified, more efficient, or new\r\nalgorithms. Very often the proofs are formulated in\r\nsystems based on higher types and, most curiously,\r\n\"false\" axioms. That the extracted programs are\r\nnevertheless correct hinges on the fact that there\r\nare models of higher types where these \"false\" axioms\r\nare actually true.\r\n\r\nIn this talk we investigate systematically how the\r\ntruth of a statement involving higher type functionals\r\ndepends on the underlying model.\r\n\r\nMore precisely, given models X and Y of Goedel''s system\r\nT of primitive recursive functionals in higher types, it is our aim to\r\ncharacterise those higher-type quantifier prefixes such that\r\nfor all prenex formulas A with that quantifier prefix the truth of\r\nA in X implies the truth of A in Y.\r\n\r\nWe will concentrate on the following four models of system T: The\r\nfull set-theoretic model, the model of continuous\r\nfunctionals of Kleene and Kreisel, the model of hereditarily\r\neffective operations and the closed term model.\r\nThese models are of particular interest for proof mining, but\r\nthey are also significant form a foundational point of view,\r\nsince they correspond (roughly) to the classical, intuitionistic,\r\nconstructivistic and formalistic perception of higher types,\r\nrespectively.\r\n',2,'');

INSERT INTO `seminar` VALUES (145,'2007-04-26','14:00','Robert Recorde Room','Jens Blanck','http://www.cs.swan.ac.uk/~csjens/','Swansea','http://www.cs.swan.ac.uk','Domains, the nearly final story by JB','TBA',3,'');

INSERT INTO `seminar` VALUES (136,'2007-03-01','14:00','Robert Recorde Room','Chuck Hansen','http://www.cs.utah.edu/~hansen/','Utah','http://www.cs.utah.edu/','Suppose the World was Piecewise Plastic? ','\r\nIs it ridiculous to think of the world has nothing but plastic?  That\r\nis precisely an assumption most volume renders make by using the Phong\r\nillumination model.\r\n\r\nDirect volume rendering has proven to be an effective and flexible\r\nvisualization method for interactive exploration and analysis of 3D\r\nscalar fields.  While widely used, most if not all applications render\r\n(semi-transparent) surfaces lit by an approximation to the Phong local\r\nsurface shading model. This model renders surfaces simplistically (as\r\nplastic objects) and does not provide sufficient lighting information\r\nfor good spatial acuity. In fact, the constant ambient term leads to\r\nmisperception of information that limits the effectiveness of\r\nvisualizations. Furthermore, the Phong shading model was developed for\r\nsurfaces, not volumes. The model does not work well for volumetric\r\nmedia where sub-surface scattering dominates the visual appearance\r\n(e.g. tissue, bone, marble, and atmospheric phenomena).  As a result,\r\nit is easy to miss interesting phenomena during data exploration and\r\nanalysis.  Worse, these types of materials occur often in modeling and\r\nsimulation of the physical world.  Physically correct lighting has\r\nbeen studied in the context of computer graphics where it has been\r\nshown that the transport of light is computationally expensive for\r\neven simple scenes.  Yet for visualization, interactivity is necessary\r\nfor effective understanding of the underlying data. We seek increased\r\ninsight into volumetric data through the use of more faithful\r\nrendering methods that take into consideration the interaction of\r\nlight with the volume itself.',1,'');

INSERT INTO `seminar` VALUES (146,'2007-05-10','14:00','Robert Recorde Room','Harold Thimbleby','','Swansea','','Medical Systems and HCI','',3,'');

INSERT INTO `seminar` VALUES (147,'2007-05-17','14:00','Robert Recorde Room','Markus Roggenbach','','Swansea','','Modelling Medical Systems in CSP','',3,'');

INSERT INTO `seminar` VALUES (148,'2007-05-25','14:00','Robert Recorde Room','Jose Fiadeiro','','Leicester','','TBA','',3,'');

INSERT INTO `seminar` VALUES (149,'2007-03-20','14:00','Robert Recorde Room','David Bainbridge','','University of Waikato','http://www.waikato.ac.nz/','Content analysis driven digital music libraries','\r\n\r\nEver had a tune buzzing around your head, but can''t remember its name?\r\nOr been looking for some new music to listen to, but aren''t sure what to\r\ntry? Enter digital music libraries!\r\n\r\nThis talk will focus on the digital music library work conducted as part\r\nof the research activities at the University of Waikato, home of the\r\nopen-source Greenstone digital library software. The work encompasses\r\nhandling different forms of music such as sheet music, symbolic\r\nrepresentation, and audio performances; novel ways to access the\r\ninformation such as locating a musical score through a user singing a\r\nfragment of remembered  melody as their query (in addition to supporting\r\nsearching by bibliographic information). Alternatively, browsing through\r\nan ever-changing collage of images associated with music works can\r\nsupport a serendipitous form of access, akin to spotting an interesting\r\nbook on a library shelf. Combining heterogeneous forms of music also\r\npresents challenges that need to be overcome. During the course of the\r\ntalk, a variety working examples will be demonstrated and the underlying\r\nalgorithmic techniques explained.\r\n\r\n\r\nBio:\r\n\r\nDavid Bainbridge is a senior lecturer in computer science at the\r\nUniversity of Waikato, New Zealand. He holds a PhD in computer science\r\nfrom the University of Canterbury, New Zealand where he studied the\r\nproblem of optical music recognition as a Commonwealth Scholar. Since\r\nmoving to Waikato, he has continued to broadened his interest in digital\r\nmedia, while retaining a particular emphasis on music. He is an active\r\nmember of the Greenstone Digital Library project (www.greenstone.org),\r\nand through this work has collaborated with several United Nations\r\nAgencies, the BBC and various public and national libraries. He has\r\npublished in the areas of image processing, music information retrieval,\r\ndigital libraries, data compression, and text mining. He is co-author of\r\nthe book, How to build a digital library, and twice has been the\r\nrecipient of the best paper award at the premier US conference on\r\ndigital libraries.',1,'');

INSERT INTO `seminar` VALUES (151,'2007-05-08','14:00','Robert Recorde Room','Martin Kraus','','TU Munich','http://wwwcg.in.tum.de/people/Kraus/','GPU-Based Pyramidal Image Processing: Theory and Applications','The talk will cover particularly efficient image filters for GPU-based image processing; basic pyramidal image processing techniques (such as zooming, blurring, and interpolating scattered pixel data); and more complex techniques that take advantage of GPU-based image processing (such as zooming with edge enhancement, blurring for depth-of-field effects, and adaptive sampling for direct volume rendering).',1,'');

INSERT INTO `seminar` VALUES (152,'2007-06-19','14:00','Robert Recorde Room','Olov Wilander','http://www.math.uu.se/staff/pages/?uname=wilander','University of Uppsala','http://www.math.uu.se/','Universal algebras with lazy and partial functions ','It is well known that equational logic is not sound for structures\r\nwith partial functions.  A sound system for Horn logic with partial\r\nfunctions, called PHL (investigated by E. Palmgren and S. Vickers), is\r\none of many alternative systems.  In this talk, we simplify and extend\r\nPHL to handle, not only partial, but also lazy functions.\r\n\r\nThe system is given semantics in a way that stays very close to the\r\ntraditional universal algebra semantics for equational logic, and both\r\nsoundness and completeness is shown.  Further, some proof theoretic\r\nproperties of the new system, particularly regarding the substitution and\r\ncut rules, are investigated.  Finally its precise relation to PHL is\r\nclarified by means of intertranslatability results.\r\n',2,'');

INSERT INTO `seminar` VALUES (154,'2007-05-17','14:00','Robert Recorde Room - Talk in the Algebraic Specification Seminar ','Markus Roggenbach','','Swansea','','Modelling Medical Systems in CSP','',2,'');

INSERT INTO `seminar` VALUES (155,'2007-04-26','14:00','Robert Recorde Room - Talk in the Algebraic Specification Seminar','Jens Blank','','Swansea','','Domains, the nearly final story by JB','',2,'');

INSERT INTO `seminar` VALUES (156,'2007-09-27','14:00','Robert Recorde Room','Peter Johnson','http://www.cs.bath.ac.uk/dept/people/p.johnson.html','University of Bath','http://www.cs.bath.ac.uk/department/','Designing Complex Interactions: a People Centred Perspective','Complex Systems are deemed to be complex because of the nature of the interactions between the components rather than merely because of the number of the components. Focusing upon complex interactions that are difficult to predict and design is the very territory that researchers and practitioners in Human Computer Interaction are used to. The nature of human behaviour, the varied domains of activity, and the interactions that take place are indeed complex. Designing systems that support, enhance and enable human, social activity is a difficult challenge facing these researchers and practitioners.  To meet these challenges theories, methods, technologies and models are developed, applied and evaluated in demanding contexts and where found wanting give rise to further research and development. Taking two examples of designing interaction in the cockpit and in creative music composition the approaches used are illustrated. The relevance of these findings to approaching the design of systems on a larger scale is considered.      ',1,'');

INSERT INTO `seminar` VALUES (158,'2007-10-11','14:00','Robert Recorde Room','Ross D. King','http://www.aber.ac.uk/~dcswww/Admin/staff/HTML/rdk.html','University of Wales, Aberystwyth','http://www.aber.ac.uk/~dcswww/public/','The Robot Scientist Project','We are interested in the automation of science for both philosophical and technological reasons. To this end we have built the first automated system that is capable of automatically: originating hypotheses to explain data, devising experiments to test these hypotheses, physically running these experiments using a laboratory robot, interpreting the results, and then repeat the cycle.  We call such automated systems \"Robot Scientists\". We applied our first Robot Scientist to predicting the function of genes in a well-understood part of the metabolism of the yeast S. cerevisiae.  For background knowledge, we built a logical model of metabolism in Prolog. The experiments consisted of growing mutant yeast strains with known genes knocked out on specified growth media. The results of these experiments allowed the Robot Scientist to test hypotheses it had abductively inferred from the logical model. In empirical tests, the Robot Scientist experiment selection methodology outperformed  both randomly selecting experiments, and a greedy strategy of always choosing the experiment of lowest cost; it was also as good as the best humans tested at the task. To extend this proof of principle result to the discovery of novel knowledge we have: built a fully automated robot called ''Adam'', formed a model of most of the known metabolism of yeast, and developed an efficient way of inferring probable hypotheses based on bioinformatics.  Adam has been successful in experimentally confirming several novel hypotheses.  We are currently in the process of manually checking these hypotheses.',1,'');

INSERT INTO `seminar` VALUES (159,'2007-10-16','14:00','Robert Recorde Room','Georg Gottlob','http://web.comlab.ox.ac.uk/oucl/people/georg.gottlob.html','Oxford University','http://web.comlab.ox.ac.uk/oucl/','Hypertree Decompositions:  Detecting Tractable Instances of NP-hard Problems','One of the best-known methods for decomposing graphs is the method of\r\ntree-decompositions introduced by Robertson and Seymour. Many NP-hard\r\nproblems become polynomially soblvable if restricted to instances\r\nwhose underlying graph structure has bounded treewidth. The notion of\r\ntreewidth can be straightforwardly extended to hypergraphs by simply\r\nconsidering the treewidth of their primal graphs or, alteratively, of\r\ntheir incidence graphs. However, doing so comes along with a loss of\r\ninformation on the structure of a hypergraph with the effect that many\r\npolynomially solvable problems cannot be recognized as such because\r\nthe treewidth of the underlying hypergraphs is unbounded. In\r\nparticular, the treewidth of the class of acyclic hypergraphs is\r\nunbounded. In this talk, I will describe more appropriate measures for\r\nhypergraph acyclicity, and, in particular, the method of hypertree\r\ndecompositions and the associated concept of hypertree width. After\r\ngiving general results on hypertree decompositions, I will report on\r\ngame-theoretic characterizations of hypergraph decomposition methods,\r\nand give a survey on recent results.',1,'');

INSERT INTO `seminar` VALUES (162,'2002-10-10','14:00','Robert Recorde Room','René Vestergaard','http://www.jaist.ac.jp/~vester/','JAIST - Japan Advanced Institute of Science and Technology, Ishikawa','http://www-compsci.swan.ac.uk/~csetzer/logic-server/ishikawa.html','Structural Induction and the lambda-Calculus  ','Addressing the role of variable binding in higher-order languages presented with simple syntax (in this case, the lambda-calculus), we (i) show that pen-and-paper proofs by structural induction and related proof principles typically, but not always, are formally incomplete rather than incorrect, as would be expected and (ii) account comprehensively for a general proof methodology that serves to bridge the gap between pen-and-paper and formalised proofs by structural proof principles. As well as summarising earlier, formally verified proofs (in Isabelle/HOL) of beta-confluence and the strong weakly-finite beta-development property, we also present formal proofs of eta-confluence, beta,eta-confluence, eta-over-beta-postponement, and notably beta-standardisation. In the latter case, the known proofs fail in rather interesting ways.',1,NULL);

INSERT INTO `seminar` VALUES (163,'2002-10-15','14:00','Robert Recorde Room','David Pym','http://www.bath.ac.uk/~cssdjp/','Bath','http://www-compsci.swan.ac.uk/~csetzer/logic-server/bath.html','A Semantics for Reductive Logic and Proof-search','Since its earliest conception, (proof theory in) mathematical logic has been formulated as a formalization of deductive reasoning: given a collection of hypotheses, a conclusion is derived. The advent of computational logic, however, has emphasized the significance of reductive reasoning: given a putative conclusion, sufficient hypotheses are determined. We provide, for intuitionistic logic and classical logic, a model-theoretic semantics of reductions of comparable value to those available for proofs. Within this general theory, which combines BHK and Kripke semantics, we formulate a model-theoretic semantics for proof-search, giving a specific games model interpretation of the key control mechanism known as backtracking.',1,NULL);

INSERT INTO `seminar` VALUES (164,'2002-10-29','14:00','Robert Recorde Room','Conor McBride','http://www.dur.ac.uk/c.t.mcbride/','Durham','http://www-compsci.swan.ac.uk/~csetzer/logic-server/durham.html','Generic Programming within Dependently Typed Programming.','This is joint work with Thorsten Altenkirch\r\n\r\nWe show how higher kinded generic programming can be represented faithfully within a dependently typed programming system. The development has been implemented using the OLEG system.\r\n\r\nThe present work can be seen as evidence for our thesis that extensions of type systems can be done by programming within a dependently typed language, using data as codes for types.\r\n\r\nMore details can be found under http://www.dur.ac.uk/c.t.mcbride/generic/.',1,NULL);

INSERT INTO `seminar` VALUES (165,'2002-10-31','14:00','Robert Recorde Room','Andy Hopper','http://www-lce.eng.cam.ac.uk/~hopper/','Cambridge','http://www.eng.cam.ac.uk/','Sentient Computing','Sentient Computing is the proposition that applications can be made more responsive and useful by observing and reacting to the physical world. It is particularly attractive in a world of mobile users and computers.\r\n\r\nThe solution requires a classification and quantification of sensor information together with methods of altering the behavior of arbitrary terminal devices. It also requires a framework for \"programming with space\" which can associate space-related events with actions in a computationally bounded way.\r\n\r\nThe talk will describe an operational system that uses a variety of sensors; allows space representations to change quickly; provides an appropriate governing event logic; uses caches and proxies to handle large volumes of data quickly; and executes in real time to satisfy a human in the loop.',1,NULL);

INSERT INTO `seminar` VALUES (166,'2002-11-05','14:00','Robert Recorde Room','Bakhadyr Khoussainov','http://www.cs.auckland.ac.nz/~bmk/','University of Auckland, New Zealand','http://www-compsci.swan.ac.uk/~csetzer/logic-server/auckland.html','On the power of algebraic specifications','In this talk we address long standing open problems of Bergstra and Tucker about specifications of abstract data types by means of equations and conditional equations. We provide several examples, discuss known results in the area, and provide basic ideas and concepts from logic and computability developed towards the study of the problems.',1,NULL);

INSERT INTO `seminar` VALUES (167,'2002-11-12','14:00','Robert Recorde Room','Perdita Stevens','http://www.dcs.ed.ac.uk/home/pxs/','Edinburgh','http://www-compsci.swan.ac.uk/~csetzer/logic-server/edinburgh.html','Playing games with UML tools','Modern software development processes openly acknowledge what software designers have always whispered: software design is not done as a monolithic phase between analysis and implementation. Rather, the process of designing software is incremental, experimental, often concurrent, and interleaved with other activities. It is a game, in the sense that it involves strategising, exploring options, balancing objectives - and in the sense that it can be fun to do in groups!\r\n\r\nAt the same time the market for object-oriented software design tools has expanded and become more competitive, largely because of the emergence of the Unified Modelling Language as dominant design notation. Yet, I will claim, these two thematic changes in the community''s view of software design, embodied in methodologies and tools respectively, do not yet seem to be harmonious. I will discuss the implications for future tools, and will explain how I think formal techniques can contribute to improving them.',1,NULL);

INSERT INTO `seminar` VALUES (168,'2002-11-28','14:00','Robert Recorde Room','Graham Finlayson','http://www.sys.uea.ac.uk/people/graham/','University of East Anglia, Norwich','http://www.sys.uea.ac.uk/','All wavelengths are equal but some are more equal than others.','The famous Newton Prism experiment appears to indicate that the colour we see depends on the (dominant) wavelength of light. This is in fact not true. The same physical stimulus may appear blue, green or red depending on the context in which it is seen. Yet, the idea of wavelength surely matters in colour vision and it appears that some wavelengths are more crucial than others. Specifically, the prime wavelengths of light around 450, 540 and 610 Nanometres (the visible spectrum runs from about 400 to 700 Nanometres) appear most important.\r\n\r\nIn the talk I show the following results. First, that a monitor that has its red, green and blue primaries anchored at the prime wavelengths is optimally energy efficient. Second, that such a monitor induces the largest gamut of colours. Third, that a camera designed to drive a prime light monitor has attractive colour balance properties (specifically it easy to model and remove the effect of viewing illuminant). Finally, by applying the same reasoning to our own visual systems we come up with a physical basis for perceptual response (this idea might be seen as controversial).\r\n\r\nSo, why is this interesting to a computer science audience? Well, these ideas are now well established in computer vision (see papers on color constancy and photometric invariants). Moreover, the prime wavelength concept is being incorporated in camera standards. In recent work we have generalised the prime light idea to multispectral data in computer graphics . Indeed, the prime light idea is the key to fast multispectral rendering (which in turn is the key to photo realism). Other possible applications for prime lights will also be discussed.',1,NULL);

INSERT INTO `seminar` VALUES (169,'2002-12-03','14:00','Robert Recorde Room','Reyer Zwiggelaar','http://www.sys.uea.ac.uk/people/rz/','University of East Anglia, Norwich','http://www.sys.uea.ac.uk/','Scale-Orientation Space','Scale-orientation signatures were initially developed for the detection of mass-like structures in mammographic images. Subsequently it has been shown that this rich local image feature is capable of the enhancement of image structures in general and can even classify sub-groups. More recently, a general description of scale-orientation space was used to do basic image processing. During the presentation the whole historic range of the process will be covered and a number of medical imaging applications will be used to demonstrate the potential of the described approach. Current and future developments will be discussed.',1,NULL);

INSERT INTO `seminar` VALUES (170,'2002-12-05','14:00','Robert Recorde Room','John Brooke','http://www.csar.cfs.ac.uk/staff/brooke/','Manchester','http://www.mcc.ac.uk/','RealityGrid: A Distributed Reality Centre on the Grid.','I describe a project aimed at providing computational scientists for doing remote steering and visualization of massively parallel computations over a Computational Grid. Grids are large collaborations of multiple resources, computers, sensors, visualization facilities, databases etc..which can be accessed by the end-user as a single virtual resource with a simple sign-in to the whole range of resources. I describe work in an EPSRC Pilot Project called RealityGrid that is applying Grid technology to the investigation of soft condensed matter physics and chemistry. The applications are in the oil extraction industry and in biological modelling of large and complex molecules. As well as describing the project plans, I will give a detailed account of a working steering application which is the first large scale application to utilise the proposed Open Grid Services Architecture. For more details see the Web references below. I will also include an introductory section on Grid computing and why this is a topic of such interest in Computer Science at the present time, for the benefit of those who are unfamiliar with Grid technology and concepts.',1,NULL);

INSERT INTO `seminar` VALUES (171,'2002-12-10','14:00','Robert Recorde Room','Tom Troscianko','http://psychology.psy.bris.ac.uk/TomTroscianko.html','Bristol','http://psychology.psy.bris.ac.uk/','Psychophysics of Natural Images','The paradox of vision science is that it appears easy to learn much about very simple image viewing situations, or else little about the perception of more complex scenes. Since we are interested in the perception of natural images, we are adapting normal psychophysical methods to study such scenes. We show that there is an optimisation to the properties of natural scene statistics - in particular, such optimisation applies iw we consider a task which needs a particular visual subsystem. To this end, we have been studying the properties of fruit and leaves eaten by primates in an African rainforest and finding clear evidence for optimality of coding of such stimuli. We have also used a simple approach to deal with more complex, dynamic, stimulus sequences in which the task is to predict whether violent human behaviour will occur. It may be that the primitives for such tasks can also be defined as simple, low-level operators. There may therefore be a \"middle way\" through the paradox: make the images complex, but keep the models simple.',1,NULL);

INSERT INTO `seminar` VALUES (172,'2002-01-29','14:00','Robert Recorde Room','Jan Bergstra',NULL,'Amsterdam','http://www-compsci.swan.ac.uk/~csetzer/logic-server/amsterdam.html','Molecular programming: from program algebra to Java','Molecular programming is a simplistic program notation able to deal with the core features of object orientation. It will be used to explain the behavior of a notorious 10 line Java program.\r\n\r\nIn addition some time will be spent on the program algebra perspective on structured programming: goto''s are more epressive than while loops!',1,NULL);

INSERT INTO `seminar` VALUES (173,'2002-02-05','14:00','Robert Recorde Room','Wilfrid Hodges','http://www.maths.qmw.ac.uk/~wilfrid/','Queen-Mary, University of London','http://www-compsci.swan.ac.uk/~csetzer/logic-server/london.html','Imperfect information and clashes between syntactic and semantic scope','An old problem about the semantics of natural languages is that some expressions seem to have a semantic scope that disagrees with their syntactic scope. Since Frege, one deals with this by attaching the semantics to a rearranged ''deep structure'' whose semantic and syntactic scopes match up. In the 1950s Leon Henkin asked (by implication) whether there is a workable semantics that keeps the original surface structure of the sentence. A number of people have said in print that the answer is no. This is false; under very general circumstances the answer is yes. But to find the answer one should tackle two questions: (a) Exactly what information is a semantics supposed to convey? and (b) Scope discrepancies usually show up as a failure to pass information from one part of a sentence to another; are we looking at a semantics of imperfect information, in the sense of game theory?',1,NULL);

INSERT INTO `seminar` VALUES (174,'2002-02-19','14:00','Robert Recorde Room','Julian Bradfield','http://www.dcs.ed.ac.uk/home/jcb/','Edinburgh','http://www-compsci.swan.ac.uk/~csetzer/logic-server/edinburgh.html','Model-checking: from real life to mathematics','\"Model-checking\" is a popular and highly successful technique for performing formal verification of both hardware and software systems. It relies on a range of theories and techniques from theoretical computer science and logic: temporal logics are used to express the properties to be checked, process algebras may be used to express the systems under examination, automata theory is used to produce algorithms for model-checking, and so on. Moreover, the study of techniques inspired by the very practical demands of model-checking, can lead into mathematical questions that most people would consider very theoretical -- even by mathematicians'' standards, let alone computer scientists''. In this talk, I will give a high-level overview of model-checking and related areas: what the problem is (verification), how we can formalize it (logic and automata), how we can then solve it (model-checking itself), and a glimpse at some of the related mathematical topics (game theory, descriptive set theory).',1,NULL);

INSERT INTO `seminar` VALUES (175,'2002-02-20','14:00','Board Room','Julian Bradfield','http://www.dcs.ed.ac.uk/home/jcb/','Edinburgh','http://www-compsci.swan.ac.uk/~csetzer/logic-server/edinburgh.html','Enriching OCL using observational mu-calculus','The Object Constraint Language is a textual specification language which forms part of the Unified Modelling Language. Its principal uses are specifying constraints such as well-formedness conditions (e.g. in the definition of UML itself) and specifying contracts between parts of a system being modelled in UML. Focussing on the latter, we propose a systematic way to extend OCL with temporal constructs in order to express richer contracts. Our approach is based on observational mu-calculus, a two-level temporal logic in which temporal features at the higher level interact cleanly with a domain specific logic at the lower level. Using OCL as the lower level logic, we achieve much improved expressiveness in a modular way. We present a unified view of invariants and pre/post conditions, and we show how the framework can be used to permit the specification of liveness properties. ',1,NULL);

INSERT INTO `seminar` VALUES (176,'2002-02-26','14:00','Robert Recorde Room','David Walker','http://www.cs.cf.ac.uk/department/staff/david.w.walker.shtml','Cardiff','http://www.cs.cf.ac.uk/','PSEs and The Grid: More Than Just a Pretty (Inter)Face','This talk will give an overview of research at Cardiff University into distributed problem-solving environments for science and engineering, and place it in the broader context of the emerging field of Grid computing. Our work has focused on three closely related areas. The first is the development of a visual collaborative code composition environment based on software components. The second area is the specification of a component model in XML. The XML description of a component must represent the hierarchical structure of the component, and the component interface, as well as other information that might be useful in scheduling and running the component. The third area is the wrapping of legacy code for use as components in CORBA and Java environments, and a system for automatically wrapping complete C libraries as Java components will be described. The interaction of the XML component specification with Grid infrastructure for discovering and scheduling resources will also be considered.',1,NULL);

INSERT INTO `seminar` VALUES (177,'2002-03-14','15:00','Robert Recorde Room','Boris Mirkin','http://www.dcs.bbk.ac.uk/~mirkin','Birbeck College, London','http://www.dcs.bbk.ac.uk/','Two models for single cluster clustering','Single cluster clustering is a discipline devoted to the problem of separating a homogeneous cluster (a pattern) from a data set. This type of clustering can both complement and supplement more traditional clustering problems such as partitioning or building a hierarchy.\r\n\r\nTwo models for single cluster clustering will be presented; one based on the traditional data format, entity-to-feature table, and the other on a more flexible format of image and signal data, the entity-to-subset linkage function.\r\n\r\nThe first model leads to a clustering method, which is akin to k-means clustering and gives the user more advice with regard to data pre-processing, initial setting, and interpretation.\r\n\r\nThe second model leads to a method for structuring data in a nested manner by separating the dense core, its less dense shell, then more shells, each sparser than the previous one. Mathematically, the problem emerging is that of maximization of a specific set function, which admits a polynomial-time greedy like solution.',1,NULL);

INSERT INTO `seminar` VALUES (178,'2002-05-14','14:00','Robert Recorde Room','Stephan Reiff-Marganiec','http://www.cs.stir.ac.uk/~srm/','Stirling','http://www-compsci.swan.ac.uk/~csetzer/logic-server/stirling.html','Telecommunication Services -- What''s the big Deal?','Telecommunications service engineering is a quite challenging area. Telecommunication systems are large, distributed systems that have evolved over a period of time and additionally are safety critical. As long as the development of the systems was in the hand of few companies, most problems could be dealt with (though not optimally). However, the recent move towards an open market introduces many new challenges.\r\n\r\nIn this talk I will give a background on telecommunications systems, and in particular discuss what features are and concentrate on the feature interaction problem. I will then present different approaches to resolving the FI problem and explore the solution proposed in my PhD thesis. The last part of the talk will look at the future developments in the area and link my previous results to this.',1,NULL);

INSERT INTO `seminar` VALUES (179,'2002-06-11','14:00','Robert Recorde Room','Andy Gordon','http://research.microsoft.com/~adg','Microsoft Research, Cambridge','http://www-compsci.swan.ac.uk/~csetzer/logic-server/microsoft.html','Types and effects for asymmetric cryptographic protocols','Joint work with Alan Jeffrey, DePaul University.\r\n\r\nWe present the first type and effect system for proving authenticity properties of security protocols based on asymmetric cryptography. The most significant new features of our type system are: (1) a separation of public types (for data possibly sent to the opponent) from tainted types (for data possibly received from the opponent) via a subtype relation; (2) trust effects, to guarantee that tainted data does not, in fact, originate from the opponent; and (3) challenge/response types to support a variety of idioms used to guarantee message freshness. We illustrate the applicability of our system via protocol examples.',1,NULL);

INSERT INTO `seminar` VALUES (180,'2002-06-20','14:00','Robert Recorde Room','Luca Cardelli','http://www.luca.demon.co.uk/','Microsoft Research, Cambridge','http://www-compsci.swan.ac.uk/~csetzer/logic-server/microsoft.html','A Spatial Logic for Concurrency (joint work with Luis Caires)','We present the semantics and proof theory of a modal logic for describing the spatial organization and the behavior of distributed systems. In addition to standard logical and temporal operators, our logic includes spatial operations corresponding to process composition and name hiding, and a fresh name quantifier. Properties of concurrent systems can also be defined by second-order quantification and hence (through an encoding) by recursion. A central aim of our logic is the combination of a logical notion of freshness with inductive and coinductive definitions of properties.',1,NULL);

INSERT INTO `seminar` VALUES (181,'2001-10-16','14:00','Robert Recorde Room','Peter G. Hinman','http://www.math.lsa.umich.edu/~pgh/','University of Michigan','http://www-compsci.swan.ac.uk/~csetzer/logic-server/michigan.html','Relative computability for sets of sets','There are many notions of relative computability for sets of natural numbers: $A\\leq_{\\cal C}B$ iff there is a $\\cal C$-algorithm $\\Phi$ which computes $A$ using oracle $B$: $A=\\Phi(B)$. Here $\\cal C$ may be Turing (recursive), poly-time, etc. Intuitively, $A$ is a problem (is $m\\in A$?) which we can solve using $B$.\r\n\r\nFor each $\\cal C$ there is a corresponding notion for classes of sets: $P\\;\\dot\\leq_{\\cal C}\\;Q$ iff for some $\\Phi\\in{\\cal C}$, for all $B\\in Q$, $\\Phi(B)\\in P$. Here the intuition is that solving {\\it some} $A\\in P$ is the goal which can be accomplished given a solution for {\\it some} $B\\in Q$.\r\n\r\nIn each case most attention has been paid to restricted versions --- for example, to relative Turing computability on the recursively enumerable sets. We describe an analogous restriction of Turing computability to $\\Pi^0_1$ classes of sets --- membership of a set $A$ in a $\\Pi^0_1$ class is determined by an effective condition on all initial segments of $A$. Many familiar problems, such as finding graph colorings and consistent extensions of theories can be naturally viewed as $\\Pi^0_1$ classes. We discuss properties of relative Turing computability on $\\Pi^0_1$ classes and and suggest some directions for further research. ',1,NULL);

INSERT INTO `seminar` VALUES (182,'2001-10-25','14:00','Robert Recorde Room','Christopher Jones','http://www.cs.cf.ac.uk/user/C.B.Jones/','Cardiff','http://www.cs.cf.ac.uk/','Geographical Information Retrieval with Ontologies of Place','There are many geographical information retrieval tasks in which the target of the search may be documents, images or records which are referenced to geographical space only by means of place names. Often there may be an imprecise match between the query name and the names associated with candidate sources of information. There is a need therefore for geographical information retrieval facilities that can rank the relevance of candidate information with respect to geographical closeness as well as semantic closeness with respect to the topic of interest. Here we present a geographical place ontology that combines limited coordinate data with qualitative spatial relationships between places. This parsimonious model of place is intended to support information retrieval tasks that may be global in scope. The ontology has been implemented with a semantic modelling system linking non-spatial conceptual hierarchies with the place ontology. An hierarchical distance measure is combined with Euclidean distance between place centroids to create a hybrid spatial distance measure. This can be combined with thematic distance, based on classification semantics, to create an integrated semantic closeness measure that can be used for relevance ranking of retrieved objects.',1,NULL);

INSERT INTO `seminar` VALUES (183,'2001-11-01','14:00','Robert Recorde Room','Dave Marshall','http://www.cs.cf.ac.uk/user/Dave.Marshall/','Cardiff','http://www.cs.cf.ac.uk/','Reverse Engineering of CAD Models from 3D range data','Reverse engineering a physical object part is the extraction of information from a particular part which is sufficient to reproduce it. In most cases only an approximation of some aspect of the original part is required. The research highlighted in this talk focuses on reverse engineering the shape of mechanical parts. Our goal is to create a system that can automatically generate a complete and consistent solid (CAD) model from a given, simple mechanical part which has all the important geometric properties of its real instance.\r\n\r\nIt is expected that a system like this has various practical applications by dramatically reducing the amount of human interaction required for generating CAD models. Often CAD models of existing parts do not exist or are not available in a usable form or a CAD model of a non-computer generated model like a clay model is required. Applications for those models range from design and re-design to manufacturing to analysis. An important aspect for many of these applications is that an accurate model with the intended shape properties is generated.\r\n\r\nThe talk will overview the major areas of Reverse Engineering ranging from how capturing 3D point data from a vision system, through various levels of data processing to producing a valid solid model of shape.\r\n\r\nThe talk will then detail some of the major research advances made by Cardiff in this area in recent years. An initial EU funded research project produce ''raw'' models but made some significant advances in registering 3D data and surface fitting as well as model building.\r\n\r\nThis research work is continuing in an EPSRC grant into the beautification of reverse engineered models - taking the ''raw'' models produced in earlier work, and imposing symmetry and regularity to produce objects which meet engineering requirements.',1,NULL);

INSERT INTO `seminar` VALUES (184,'2001-11-06','14:00','Robert Recorde Room','Anuj Dawar','http://www.cl.cam.ac.uk/users/ad260/','Cambridge','http://www-compsci.swan.ac.uk/~csetzer/logic-server/cambridge.html','An Introduction to Quantum Computing','Research in quantum computing is aimed at exploiting quantum mechanical effects that have no counterpart in classical physics for more efficient computation. Two important strands of this research are (1) the development of devices that exhibit quantum behaviour which can be exploited for computation; and (2) the development of algorithms that rely on such behaviour. (1) has been pursued mainly by physicists, and (2) mainly by computer scientists. At the interface of the two sits an abstract model of computation. This talk will be a gentle introduction to this model of computation, aimed at computer scientists and assuming (and requiring) no knowledge of quantum mechanics. I will explore topics such as qubits, entanglement, quantum parallelism and universal machines. ',1,NULL);

INSERT INTO `seminar` VALUES (185,'2001-11-15','14:00','Robert Recorde Room','Iain Stewart','http://www.mcs.le.ac.uk/~istewart/','Leicester','http://www-compsci.swan.ac.uk/~csetzer/logic-server/leicester.html','Computation on finite structures and Lindstroem logics, zero-one laws and dynamic logics','Finite model theory is all about what one can say about classes of finite structures (such as graphs, strings and so on) using logic; and computational complexity is all about what one can compute on finite inputs within given resources. There is a very strong link between finite model theory and computational complexity theory (exemplified by Fagin''s Theorem that a problem is in NP if and only if it can be defined in existential second-order logic). Often, this link is strongest when the finite structures are ordered, i.e., we are essentially dealing with strings. On arbitrary finite structures, the link between resource-bounded computation and logical definability is nowhere near as clear-cut. In this introductory talk, I will introduce this subject, known as descriptive complexity, and I will also introduce models of computation, program schemes, for computing on arbitrary finite structures, and show how a consideration of these models can lead to new results in finite model theory and descriptive complexity. The talk will be introductory in nature and suitable for a general audience. It will last approximately 45 minutes.\r\n\r\nI am also Co-ordinator of MathFIT. The broad aim of the Mathematics for Information Technology (MathFIT) initiative is to support, through research grants, visiting fellowships, networks, workshops and summer schools, high-quality interdisciplinary research in areas at the interface between mathematics and computer science. In the final 15 minutes of my seminar I shall explain the MathFIT initiative and the opportunities for funding.',1,NULL);

INSERT INTO `seminar` VALUES (186,'2001-11-23','14:00','Robert Recorde Room','Bhavani Thuraisingham','http://www.interact.nsf.gov/cise/contact.nsf/53f032aef5157cbf852565db006fc19f/e74e3542ea4a2a0685256ae900445ab0?OpenDocument','NSF, Arlington, VA, USA','http://www.nsf.gov/','Data Mining: Developments and Directions','Data Mining is the process of posing queries and extracting information previously unknown from large quantities of data using statistical reasoning and machine learning techniques. This presentation will review the recent developments in data mining and discuss data mining techniques and technologies. Then some of the challenges will be presented. In particular, mining text and image data, web mining, and security and privacy issues will be discussed. ',1,NULL);

INSERT INTO `seminar` VALUES (187,'2001-11-27','14:00','Robert Recorde Room','Stan Wainer','http://www.amsta.leeds.ac.uk/Pure/staff/wainer/wainer.html','Leeds','http://www-compsci.swan.ac.uk/~csetzer/logic-server/leeds.html','$\\Pi^0_2$ Induction and Exponential Time','This is an extension of work with G. Ostrin which I''ve spoken about before. If the induction variables are separated from the quantified variables in arithmetic, then the provably recursive functions become much more feasible. The $\\Sigma_1$ inductive fragment corresponds to polynomial time (but of course in \"unary\" notation) and the next level of induction corresponds to exponential time. The whole theory only proves totality of elementary functions. Exponential time is particularly interesting because it includes good, informative examples (from the proof theoretic viewpoint). Factorial, suggested by H. Jervell, is a specially good one, and I''ll use it to illustrate how our theory (closely related to earlier work of Leivant) ticks.',1,NULL);

INSERT INTO `seminar` VALUES (188,'2001-12-04','14:00','Robert Recorde Room','Eike Ritter','http://www.cs.bham.ac.uk/~exr/','Birmingham','http://www-compsci.swan.ac.uk/~csetzer/logic-server/birmingham.html','Strong normalisation for explicit substitutions',NULL,1,NULL);

INSERT INTO `seminar` VALUES (189,'2001-12-13','13:00','Robert Recorde Room','Thorsten Altenkirch','http://www.cs.nott.ac.uk/~txa/','Nottingham','http://www-compsci.swan.ac.uk/~csetzer/logic-server/nottingham.html','Functions for free. Representations of first order function types as terminal coalgebras','We show that function types which have only initial algebras for regular functors in the domains, i.e. first order function types, can be represented by terminal coalgebras for certain nested functors. The representation exploits properties of $\\omega^\\op$-limits and local $\\omega$-colimits.',1,NULL);

INSERT INTO `seminar` VALUES (190,'2001-01-30','14:00','Robert Recorde Room','Michel Schellekens',NULL,'University of Cork',NULL,' Quantitative Domain Theory','Domain Theory, an important tool to develop models for programming languages, was developed by Dana Scott in the mid-1960''s. This, by now classical, theory has recently motivated active research on special purpose languages and led to interesting new applications. New models for real number computation, probabilistic computation, dataflow networks and efficiency analysis have been developed. Applications include better frameworks for exact real number computation, fractals and new techniques for integration. The main novel idea involved is the extension of Domain Theory with the concept of ``real number measures''''; a field currently referred to as Quantitative Domain Theory. The use of the terminology ``quantitative'''' reflects a shift from a purely order theoretic (``qualitative'''' approach) to a quantified approach based on such real number measures. We present an overview of the current state of the field as well as some recent results on the development of quantitative domains.',1,NULL);

INSERT INTO `seminar` VALUES (191,'2001-02-13','14:00','Robert Recorde Room','Bernhard Reus',NULL,'University of Sussex',NULL,' A Hoare-Calculus for an Object-Oriented Language','A new Hoare-calculus for a simple (Java-like) object-oriented language is presented that includes methods and object creation. In the assertions no explicit representation of state has to be used since the calculus is inspired by America and de Boer''s approach without global store and uses the components-as-array-trick to handle aliasing. The calculus can be adapted to OCL (Object Constraint Language which is part of UML). This is joint work with Martin Wirsing',1,NULL);

INSERT INTO `seminar` VALUES (192,'2001-02-22','14:00','Robert Recorde Room','Thorsten Altenkirch',NULL,'University of Nottingham',NULL,' Use semantics to show properties of syntax','To illustrate the idea of using semantics to show syntactical properties I will derive normalisation for minimal propositional logic from completeness of Kripke models. This simple construction motivates the work on categorical normalisation proofs and also shows how to use Type Theory and Categories in Theoretical Computer Science.\r\nThe talk is self contained - no previous knowledge of Kripke models or any other of the buzzwords used above is required.',1,NULL);

INSERT INTO `seminar` VALUES (193,'2001-02-27','14:00','Board Room','Ian Hodkinson',NULL,'Imperial College',NULL,' Varieties of algebras of relations','I will attempt to survey some theoretical work done in London over the last five years on resolving problems on representability of algebras of relations, a topic in algebraic logic. Those interested in a foretaste may browse http://www.cs.ucl.ac.uk/staff/R.Hirsch/ http://www.doc.ic.ac.uk/~imh/frames_website/AL.html http://www.doc.ic.ac.uk/~kuag/ http://www.dcs.bbk.ac.uk/~szabolcs/ ',1,NULL);

INSERT INTO `seminar` VALUES (194,'2001-03-06','14:00','Robert Recorde Room','Antonin Kucera',NULL,'Masaryk University Brno, Czech Republic',NULL,' Model-Checking LTL with Pushdown Systems','Pushdown systems can be seen as a very natural model for systems with recursive procedures. Intuitively, the stack carries information about the history of activation records, and the top stack symbol corresponds to the instruction currently being executed. The finite control can, eg, keep auxiliary information about global variables, allocated memory, etc. When abstracting a real program to a pushdown automaton, the if-then-else command is usually replaced by a non-deterministic choice between the two possible branches. Hence, the abstracted model is non-deterministic even if the original program was completely deterministic. As the underlying dynamics of pushdown automata is defined in terms of transition systems, temporal logics can be used to express properties of such systems formally. Linear-time logics (like LTL) are suitable for describing properties of `runs'', ie, possible computations. Their advantage over branching-time logics (like CTL) is that one can design rather efficient model-checking algorithms by adapting the automata-theoretic approach of Vardi and Wolper. We present such an algorithm, discussing some issues in detail. In particular, we consider the problem how to interpret atomic LTL propositions on pushdown automata without losing efficiency. We design so-called `regular'' interpretations which assign to each atomic proposition of LTL an infinite set of pushdown configurations which is symbolically encodable by a finite-state automaton. We also show how to model-check LTL formulae wrt regular interpretations, presenting the associated complexity bounds. Finally, we also present several examples of practical applicability of our results to problems of data-flow analysis and security problems of JAVA programs.',1,NULL);

INSERT INTO `seminar` VALUES (195,'2001-03-13','14:00','Robert Recorde Room','David Pym',NULL,'Queen Mary and Westfield College',NULL,NULL,NULL,1,NULL);

INSERT INTO `seminar` VALUES (196,'2001-03-20','14:00','Robert Recorde Room','Jiang Lun Wu',NULL,'University of Wales Swansea',NULL,'Hyperfinite nonstandard model and its application',NULL,1,NULL);

INSERT INTO `seminar` VALUES (197,'2001-04-03','14:00','Robert Recorde Room','Petr Jancar',NULL,'University of Ostrava, Czech Republic',NULL,' Some techniques used to solve decidability and complexity questions for bisimulation-like equivalences','A method of converting a computational problem to a two-player game and its use in showing P-hardness of behavioural equivalences for finite-state systems and their undecidability for Petri nets will be shown.\r\n\r\nThen the \"semilinear witness\" method will be demonstrated in the case of a \"regular\" plane colouring technique which was used to show decidability of simulation and bisimulation equivalences for (weak) one-counter machines.',1,NULL);

INSERT INTO `seminar` VALUES (198,'2001-06-09','14:00','Board Room','Tony Davies',NULL,'BT Electronical Commerce Innovation Centre, University of Wales Cardiff',NULL,' eCommerce Progress in Wales','',1,NULL);

INSERT INTO `seminar` VALUES (200,'2000-09-21','14:00','Robert Recorde Room','Peter Hertling',NULL,'University of Hagen, Germany',NULL,' Computability and Continuity of Real Number Functions','In contrast to computations over discrete structures, for computations over the real numbers topological notions play an important role. While some approaches for defining computable real functions incorporate continuity in an obvious way, others imply continuity rather surprisingly. We present several results about the relationship between computability and continuity, starting with the continuity of Banach--Mazur computable functions. The main result presented will be a strengthening of results by Kreisel, Lacombe, Shoenfield, by Tseitin, by Moschovakis, and by Berger. We will characterize the effectively continuous functions on the computable elements of certain topological spaces as those functions which are effective with respect to a Goedel numbering of the computable elements and which have a sufficiently nice domain of definition.',1,NULL);

INSERT INTO `seminar` VALUES (201,'2000-09-26','14:00','Robert Recorde Room','Achim Jung',NULL,'University of Birmingham',NULL,' On Harold Simmons''s Theory of Lax Limits','In 1993 Harold Simmons wrote a beautiful paper on the structure and properties of lax limits in ordered categories (\"The Glueing Construction and Lax Limits\"). As a consequence of this theory, a new explanation of the celebrated \"limit-colimit coincidence\" in categories of semantic domains can be given. Together with my student Paola Maneggia we recently found that the lax limit construction can also give more insight into models of second-order lambda calculi.\r\n\r\nIn the talk I will present a brief introduction to the theory of domain equations and how they are solved in categories of semantic domains. I will explain the significance of the limit-colimit construction and then show how it follows from the theory of lax limits. Finally, I will apply the lax limit construction to models of System F (the second-order lambda calculus).\r\n\r\nAlthough this abstract contains many \"big words\" I intend to present the ideas in a self-contained fashion so that they may be appreciated by graduate students working in any field of Theoretical Computer Science. ',1,NULL);

INSERT INTO `seminar` VALUES (202,'2000-10-10','14:00','Robert Recorde Room','Monika Seisenberger',NULL,'University of Munich',NULL,' Constructive Proofs of Kruskal''s Theorem','Kruskal''s tree theorem is a famous theorem in infinitary combinatorics, saying that for every infinite sequence t_1, t_2,... of trees there exist indices i t'' &lt; j such that t_i is embeddable in t_j. Here a tree t is embeddable in t'' if there exists a one-to-one map f:t--&gt; t'' respecting infima of nodes. The theorem became famous since it is a simple statement neither provable in Peano arithmetic nor in ATR_0, two systems where large parts of mathematics can be developed. The main field of application of Kruskal''s theorem is term rewriting theory where it is used prove termination of simplification orderings. Kruskal''s theorem has a very elegant proof due to Nash-Williams using the minimal-bad-sequence argument. However, this proof is highly non-constructive and does not lead to an algorithm. We discuss the ideas behind several constructive proofs of Kruskal''s theorem, including the question whether the non-constructive Nash-Williams'' proof can be constructivized.',1,NULL);

INSERT INTO `seminar` VALUES (203,'2000-10-17','14:00','Robert Recorde Room','Alexander Rabinovich',NULL,'University of Edinburgh',NULL,' An Infinite Hierarchy of Temporal Logics over Branching Time','Many temporal logics were suggested as branching time specification formalisms during the last 20 years. These logics were compared against each other for their expressive power, model checking complexity and succinctness. Yet, unlike the case for linear time logics, no canonical temporal logic of branching time was agreed upon. We offer an explanation for the multiplicity of temporal logics over branching time and provide and objective quantified `yardstick'' to measure these logics.\r\n\r\nWe show that CTL^* has no finite base. We define an infinite hierarchy BTL_k of temporal logics and prove its strictness. We examine the expressive power of commonly used branching time temporal logics; almost all these logics are inside the second level of our hierarchy.\r\n\r\nWe design new Ehrenfeucht-Fraisse games on trees, and use them as our main tool to prove inexpressibility.\r\n\r\n(Based on joint work with Shahar Maoz) ',1,NULL);

INSERT INTO `seminar` VALUES (204,'2000-11-28','14:00','Robert Recorde Room','Martin Escardo',NULL,'University of Birmingham',NULL,' Higher-order exact real number computation with Real PCF','Real PCF is an extension of PCF with a ground type for (total and partial) real numbers. Thus, its types include R (real numbers), [R->R] (real valued functions of a real variable), [N->R] (sequences of real numbers), [[N->R]->R] (functionals taking sequences to numbers, such as limit operators), [[R->R]->R] (functionals taking functions to numbers, such as integration and global maxima operators), and so on.\r\n\r\nThe operational semantics of Real PCF is computationally adequate with respect to its standard model. Roughly, this means that every finite piece of information about the value of a program of ground type is computed in finitely many steps. Moreover, Real PCF extended with a certain search operator is universal with respect to its standard model, in the sense that every computable element and every computable function (of any order) of the model is denotable by at least one Real PCF term.\r\n\r\nIn this talk I''ll present these and other results on Real PCF, and I''ll formulate some open problems and conjectures.',1,NULL);

INSERT INTO `seminar` VALUES (205,'2000-12-05','14:00','Robert Recorde Room','David Duke',NULL,'University of Bath',NULL,' Visualisation: Linking Computation with Cognition','Visualisation applications, like interactive systems in general, rely fundamentally on human cognitive abilities to interpret and respond to the information presented. At the level of perception, there is a signficant body of theory available to help in designing graphical representations. However, visualisation tasks and interfaces increasingly require a deeper understanding of the role played by higher levels of cognitive processing, for example how we navigate through representations of abstract spaces. Building links between the practical development of visualisation tools or methods, and theoretical models of human-information processing, is a challenge, not in the least because of the different disciplines involved. In this talk I will describe some of the problems that arise in \"information visualisation\", and set out an approach that may provide the insight needed to address some of these issues.',1,NULL);

INSERT INTO `seminar` VALUES (206,'1999-11-02','15:00','Seminar Room 322','Masako Takahashi',NULL,'Tokyo Institute of Technology',NULL,'Lambda-Representable Functions over Term Algebras','In this paper, we study lambda-representability (by simply typed lambda-calculus) of functions over open/closed term algebras. By extending the standard notion of lambda-representation of closed terms to open terms, and extending the notion of lambda-represen- table functions accordingly, we first give a recursion-theoretic characterization of the class of lambda-representable functions over open term algebras. Then, based on this result, we obtain two characterizations of the class of lambda-representable functions over closed term algebras. As a related topic, in the Appendix we give a simple recursion-theoretic characterization of the set of computable functions on words.',1,NULL);

INSERT INTO `seminar` VALUES (207,'1999-11-09','15:00','Seminar Room 322','Ulrich Berger',NULL,'University of Wales Swansea',NULL,'Computability on Abstract Objects','Three different notions of computability for functions on abstract objects like e.g. the real numbers are discussed: 1. effective operations, i.e. functions which can be traced by a recursive mapping on the codes of their inputs and outputs, 2. effectively continuous functions, i.e. functions induced by a recursive mapping on finite approximations of their inputs, 3. functions definable from certain basic functions by certain operations like composition, recursion etc. It turns out that in many interesting cases these three notions coincide, i.e. characterise the same class of functions. We also consider situations where coincidence does not hold or is still open.',1,NULL);

INSERT INTO `seminar` VALUES (208,'1999-11-30','15:00','Seminar Room 322','Martin Otto',NULL,'University of Wales Swansea',NULL,'Issues in Algorithmic Model Theory for Specific Domains','Finite model theory provides a framework for the application of model theoretic methods to issues of logic in computer science. As such, it greatly emphasizes the importance of the underlying class of structures to be used in the modelling of application relevant entities. Thinking of typical applications of logic in computer science, however, there is another important issue of the underlying modelling task. This concerns the `grain'' or level of abstraction at which the modelling is carried out, or the question up to which notion of equivalence do structures represent the entities which are to be modelled.\r\n\r\nA typical example is provided by modal logics and their model theory. The modal domain is characterized not so much by the restriction to special kinds of structures (transition systems, Kripke structures) as by the built-in focus according to which these structures matter only up to bisimulation. At least two other related domains have emerged as important frameworks for the study of algorithmic issues by model theoretic means: the k-variable domains and the guarded domain.\r\n\r\nIn this talk I shall review old and more recent results in the light of this idea: that the underlying invariance postulates are characteristic of typical domains of applications and call for specific model theoretic tools.',1,NULL);

INSERT INTO `seminar` VALUES (209,'1999-12-07','15:00','Seminar Room 322','Colin Hirsch',NULL,'University of Aachen, Germany',NULL,'The Guarded Fragment of First-Order Logic','An introduction to the guarded fragment (GF), some extensions and (un)decidability results are given. The GF is especially interesting as extension and generalization to various modal logics. It has been suggested that the embeddability of modal logics into the GF is the key to understanding the well-behavedness of modal logics (rather than e.g. the usual two-variable translation).',1,NULL);

INSERT INTO `seminar` VALUES (210,'1999-12-17','10:30','Seminar Room 322','T.E.R. Jones',NULL,'University of Plymouth',NULL,'n-container mixing and two-fluid mixing',NULL,1,NULL);

INSERT INTO `seminar` VALUES (211,'2000-02-02','15:00','Board Room','Reinhard Kahle',NULL,'University of Tuebingen, Germany',NULL,'The proof theory of Frege structures','Aczel introduced Frege structures as a semantical concept to define sets by use of a partial truth predicate. Beeson discovered that they can be syntactically defined as a theory of truth over applicative theories.\r\n\r\nApplicative theories - the first-order part of Feferman''s theories of explicit mathematics - essentially comprise combinatory logic and axiomatically defined natural numbers. They provide a very useful account to theoretical computer science, particularly, they are well-suited for the study of functional programming.\r\n\r\nWe will discuss Frege structures as an alternative to explicit mathematics to introduce types. We show the expressive power of Frege structures and discuss their position in the landscape of proof theory.',1,NULL);

INSERT INTO `seminar` VALUES (212,'2000-03-03','10:00','Robert Recorde Room','Toshihiko Kurata',NULL,'Tokyo Metropolitan University, Japan',NULL,'Combinatory representations of lambda-calculus','We introduce a combinatory representation which models the theory of beta-equality in lambda-calculus, and obtain an embedding functor from the category of our combinatory structures (and homomorphisms among them) to the one of general lambda-models introduced by Berry. Through this consideration, we further study the correspondence of Berry''s lambda-models to lambda-algebras.',1,NULL);

INSERT INTO `seminar` VALUES (213,'2000-03-07','14:00','Robert Recorde Room','Jan Bergstra',NULL,'University of Amsterdam, The Netherlands',NULL,'Program algebra',NULL,1,NULL);

INSERT INTO `seminar` VALUES (214,'2000-06-02','14:00','Robert Recorde Room','David Lester',NULL,'University of Manchester',NULL,'What is Exact Arithmetic?','In this talk I shall explain what I think exact arithmetic is; methods by which it might be efficiently implemented on a machine; and problems for which it might profitably be used. An exact arithmetic is one in which any answers generated may be relied upon to be correct. One way to view this is that any intermediate calculations will be performed to whatever accuracy is needed to ensure the accuracy of the answer. There is a connection here to the use of laziness in languages such as Haskell. Another way to view an exact arithmetic is that it is a realization of the Computable Reals. The methods that can be used to implement Exact Arithmetic on a machine can be broardly classified as those that behave incrementally and those that require the complete re-computation of the problem if the accuracy required of the answers increases. As someone who has experimented with a number of methods from both classes I shall describe my experiences (or more accurately prejudices!). Finally, I shall describe one of the problems set for the CCA2000 arithmetic competition (gaussian elimination), along with other problems from Computable Analysis (Non-Newtonian Orbital Mechanics, and Korteweg de-Vriess) and show why the use of Exact Arithmetic can become vital.',1,NULL);

INSERT INTO `seminar` VALUES (215,'1998-10-27','15:00','Seminar Room 322','Harold Simmons',NULL,'University of Manchester',NULL,'Type Theoretic Constructions for Naming and Classifying Numeric Gadgets','There is a standard hierarchy of sets numeric functions\r\nE0, E2, E3,...Ealpha...\r\nindexed by the ordinals. Ordinal 2 corresponds (roughly) to the polynomially bounded functions (sometimes called the feasible functions), 3 to the Kalmar elementary functions, omega to the primitive recursive functions, and epsilon0 to the functions that are handled by Peano arithmetic. Larger ordinals correspond to more sophisticated descriptions of arithmetic. I will show how all of these fit into a common framework of descriptions (specifications) of functions.\r\n\r\nGödel''s T(erm calculus) lambdaG is an applied lambda-calculus for naming those numeric gadgets which occur before epsilon0. It includes many interesting subsystems. For instance, Primitive Recursive Arithmetic sits at the bottom of lambdaG. It can be seen how the complexity of a numeric gadget is directly related to the syntactic description in this system. We do not need any reference to a model of computation.\r\n\r\nIn recent years a technique known as tiering (or ramifying) has been applied to lambda-calculi. When this is done to lambdaG the overall strength drops from epsilon0 to 3, and thus we get a much finer classification of the Kalmar elementary functions. This tiering collapses Primitive Recursive Arithmetic down to level 2, and thus we get a much finer classification of the feasible functions. It is this result that has prompted the interest of some computer scientists.\r\n\r\nI will describe some of the historical background to this topic, some of the more recent views of what is going on, and I will try to indicate what tiering is doing.',1,NULL);

INSERT INTO `seminar` VALUES (216,'1998-11-03','15:00','Seminar Room 322','Rajeev Raman',NULL,'King''s College, London',NULL,'Exploiting Architectural Factors in Sorting Algorithms','We describe some preliminary steps we have taken towards a systematic (re-)evaluation of the practical performance of sorting algorithms for integers and floating-point numbers. This (re-)evaluation is necessitated by the growing importance of architectural factors as a determinant of the real-life run-times of algorithms. We consider two such architectural factors:\r\n\r\n    * The availability of word-level parallelism (WLP)\r\n\r\n      WLP refers to the ability of a CPU with word size w to process w-bit data in a SIMD manner in unit time, either indirectly through a standard repertoire of instructions, or directly by means of instructions such as those provided by the Intel MMX processor.\r\n\r\n    * Cache effects\r\n\r\n      We describe how to improve upon the performance of a recently-published algorithm for sorting random floating-point numbers.',1,NULL);

INSERT INTO `seminar` VALUES (217,'1998-11-10','15:00','Seminar Room 322','Peter Wapperom',NULL,'Université de Louvain-la-neuve',NULL,'Nonisothermal Flow of Polymeric Fluids','Polymeric fluids may demonstrate both elastic and viscous behaviour, depending on the rate of deformation. Most theoretical and numerical work is restricted to isothermal flow. However, almost all industrial flows of polymeric fluids are nonisothermal, and, because of the strong dependence on temperature of the material properties, a good description of nonisothermal behaviour is needed.\r\n\r\nWith the aid of thermodynamics of irreversible processes, the various nonisothermal effects that have been observed in experiments can be derived for polymeric fluids. Due to the elastic behaviour of these fluids the nonisothermal effects will differ from that of the well-known inelastic fluids. These additional effects will be discussed in the thermodynamical framework and clarified with the help of simple examples and experimental observations.\r\n\r\nThe magnitude of the various nonisothermal effects will be discussed with the aid of numerical simulations. To clearly clarify and distinguish these effects both a simple and a complex flow will be considered.',1,NULL);

INSERT INTO `seminar` VALUES (218,'1998-11-24','15:00','Seminar Room 322','Matthew Hubbard',NULL,'University of Reading',NULL,'Multidimensional Upwind Schemes for Conservation Laws','In this talk the current state of multidimensional upwind fluctuation distribution schemes will be discussed. These are relatively new finite volume techniques for unstructured and, less often, structured grids which have been designed to incorporate more genuinely multidimensional aspects than existing schemes.\r\n\r\nParticular attention will be paid to recent advances in the construction of accurate fluctuation distribution schemes for time-dependent applications, earlier schemes having only attained a high order of accuracy at the steady state. The methods will be applied initially to the scalar advection equation and then extended to nonlinear systems of equations, using the Euler equations as an example. A variety of results will be shown to illustrate the success of these methods.',1,NULL);

INSERT INTO `seminar` VALUES (219,'1998-12-01','15:00','Seminar Room 322','Jeffery Zucker',NULL,'McMaster University',NULL,'Abstract and Concrete Models of Computation on Metric Partial Algebras','A model of computation is abstract if, when applied to any algebra, the resulting programs for computable functions and sets on that algebra are invariant under isomorphisms, and hence do not depend on a representation for the algebra. Otherwise it is concrete. Intuitively, concrete models depend on the implementation of the algebra. The difference is particularly striking in the case of topological partial algebras, and notably in algebras over the reals. We investigate the relationship between abstract and concrete models of partial metric algebras. In the course of this investigation, interesting aspects of continuity, extensionality and non-determinism are uncovered.\r\n\r\nThis is joint work with J.V. Tucker.',1,NULL);

INSERT INTO `seminar` VALUES (220,'1998-12-08','15:00','Seminar Room 322','Xiaoming Zhang',NULL,'IBM UK',NULL,'A Parallel Choleski Solver with Improved Scalabilities','Direct system solvers are sometimes quite useful for the solution of linear systems arising from finite element problems. However, it is well known that they are difficult to parallelise on distributed memory platforms to achieve high scalabilities.\r\n\r\nThis talk will first investigate the isoefficiency scalabilities of a parallel Choleski method (factorization and forward/backward substitutions) based on a conventional substructuring approach and then demonstrate that these scalabilities can be improved upon by further adoption of substructuring for both two- and three-dimensional finite element and finite difference analysis problems. For 2D problems, the isoefficiency scalabilities can be optimized from N=p4 to N=p3 for factorization and from N=p5 to N=p3.67 for forward/backward substitutions, where N is the number of mesh nodes and p the number of parallel processors. For 3D problems, the isoefficiency scalabilities can be improved from N=p5.5 to N=p4.375. for factorization and from N=p7 to N=p5.5 for forward/backward substitutions.',1,NULL);

INSERT INTO `seminar` VALUES (221,'1999-01-19','15:00','Seminar Room 322','Graham Birtwistle',NULL,'University of Leeds',NULL,'Specifying and Verifying TK','The talk will present work nigh completed on designing, specifying and verifying the major subsystems of an AMULET-like micro in CCS. Like AMULET1 our micro is 2-phase, but like StrongARM, we have separate instruction memories, and like AMULET3, a wide arithmetic pipeline for greater parallelism. By following an obvious design discipline, and making use of some old theorems on the register bank (from previous work on AMULET1) and some obvious recent ones on pipelines, we have reduced the state minimisation problem by a handsome factor and the whole model now fits comfortably on the Edinburgh CWB. The pipeline theorems hold for 4-phase too.\r\n\r\nThe talk will cover the basic architecture, enough on CCS to get you by, and then detail the 3 major system blocks (fetch unit, arithmetic pipeline, and writeback unit) at the RT level, and how instruction colouring was fettled.\r\n\r\nThe work is being carried out with Matt Morley and Chris Tofts at Leeds University with plenty of help from young Jim Garside at Manchester.',1,NULL);

INSERT INTO `seminar` VALUES (222,'1999-01-26','15:00','Seminar Room 322','Philip Scowcroft',NULL,'Wesleyan University',NULL,'Decidability and Undecidability in the Theory of the Constructive Reals','From the constructivist point of view of L. E. J. Brouwer or Errett Bishop, the real numbers do not have the same properties as they do in ordinary nonconstructive mathematics. I will discuss the extent to which there is an analogue, for the theory of the constructive reals, of Tarski''s theorem that the ring of real numbers has a decidable first-order theory.',1,NULL);

INSERT INTO `seminar` VALUES (223,'1999-02-18','15:00','Seminar Room 322','Stan Wainer',NULL,'University of Leeds',NULL,'Proof Theory and Complexity','This talk will describe some joint work with my students G. Ostrin and N. Cagman, on the proof theory of low subrecursive classes. The basis is \"A new recursion theoretic characterization of the polytime functions\" by Bellantoni and Cook 1992, in which it is shown that a natural two-sorted re-interpretation of the usual primitive recursion schemes characterizes polynomially bounded computation. We show that if Peano Arithmetic is instead formulated in this two-sorted fashion, with quantification allowed only over one sort (\"safe\" variables) and induction allowed only over the other sort (\"normal\" variables), then the provably terminating computable functions are exactly the Kalmar elementary functions E(3). The provably terminating functions of the Sigma_1 Inductive fragment turn out to be exactly the Grzegorczyk E(2) functions, which are the same as the ones computable in Linear Space (on a Turing Machine working in binary). This work is related to other results of Buss, Bellantoni, Beckmann and Leivant, but in addition it clearly illustrates the use of classical ordinal analysis techniques at this low level. The difference is that the bounding functions are now the Slow Growing ones rather than the Fast Growing functions which bound computations in the usual single-sorted versions of Peano Arithmetic.',1,NULL);

INSERT INTO `seminar` VALUES (224,'1999-02-26','15:00','Seminar Room 322','Neal Harman',NULL,'University of Wales Swansea',NULL,'Models of Superscalar Microprocessors','Superscalar microprocessors - which include all current PowerPCs, Alphas, Intel processors, and SPARCs - attempt to issue multiple instructions within a single clock cycle, and may internally reorder instruction execution. The talk will consider how we can model the behaviour of superscalar microprocessors, and formalise and prove their correctness with respect to an architectural description. Superscalar processors are more complex to model than non-superscalar examples, and require a different correctness model because the temporal ordering of events can change between levels of abstraction. The talk will introduce techniques for algebraically modelling microprocessors; discuss informally the operation of pipelined and superscalar; show how our models must be changed to accomodate superscalar processors; and consider the problems still to be solved.',1,NULL);

INSERT INTO `seminar` VALUES (225,'1999-03-02','15:00','Seminar Room 322','John Tucker',NULL,'University of Wales Swansea',NULL,'New Problems and Results on Equational Specification of Systems',NULL,1,NULL);

INSERT INTO `seminar` VALUES (226,'1999-03-03','13:00','Seminar Room 322','Neal Harman',NULL,'University of Wales Swansea',NULL,'Models of Superscalar Microprocessors II','Superscalar microprocessors - which include all current PowerPCs, Alphas, Intel processors, and SPARCs - attempt to issue multiple instructions within a single clock cycle, and may internally reorder instruction execution. The talk will consider how we can model the behaviour of superscalar microprocessors, and formalise and prove their correctness with respect to an architectural description. Superscalar processors are more complex to model than non-superscalar examples, and require a different correctness model because the temporal ordering of events can change between levels of abstraction. The talk will introduce techniques for algebraically modelling microprocessors; discuss informally the operation of pipelined and superscalar; show how our models must be changed to accomodate superscalar processors; and consider the problems still to be solved.',1,NULL);

INSERT INTO `seminar` VALUES (227,'1999-03-09','15:00','Seminar Room 322','Wan Fokkink',NULL,'University of Wales Swansea',NULL,'Within ARM''s Reach: Compilation of Rewrite Systems','A new compilation technique for left-linear term rewriting systems is presented. It assumes the rightmost innermost rewriting strategy, and adopts a rule order in which a rewrite rule has higher priority if it has more syntactic structure. First, the rewrite rules are transformed into so-called minimal rewrite rules, using the pattern-match automaton of Hoffmann and O''Donnell. These minimal rules have such a simple form that they can be viewed as instructions for an abstract rewriting machine (ARM). The equational programming language Epic has been implemented using ARM. This is joint work with Jasper Kamperman and Pum Walters.',1,NULL);

INSERT INTO `seminar` VALUES (228,'1999-03-16','15:00','Seminar Room 322','Karen Stephenson',NULL,'University of Wales Swansea',NULL,'An Algebraic Specification of an Interface Definition Language','We construct a simple language for defining software interfaces. We then produce an algebraic specification of this Interface Definition Language, focusing on how we can filter the strings of the language so that we only allow syntactically valid interfaces to be defined. One aspect that determines the validity of an interface is whether its architecture is well-formed or not, for example: \"Is an interface constructed from another that is absent from the system?\" \"Are there any cyclic dependencies between interfaces?\" We frame such questions algebraically, and specify how we can extract the architecture of a system from its interfaces: the architecture of a well-formed system is a term that represents the tree of dependencies between interfaces. Finally, we describe the transformation of an interface into a signature, as the first step in providing a semantics for an interface.',1,NULL);

INSERT INTO `seminar` VALUES (229,'1999-04-22','15:00','Seminar Room 322','Dafydd Rees',NULL,'University of Wales Swansea',NULL,'Formalising Object-Oriented Analysis','Many existing object oriented methods utilise informal graphical notations to document analysis artifacts. We will present a technique for developing models of those entities and services that are documented during the process of object oriented analysis. In particular, our techniques allow the construction of well-defined mathematical models. Since our techniques are based on the specification of concrete algebras, our models require only the following basic mathematical concepts: sets, constants and functions. We believe that the well-defined, uniform nature of our models leads to better dependency management and easier refactoring. Although no tools exist at present to support these techniques, we will discuss proposals for dependency analysis and model simulation tools.',1,NULL);

INSERT INTO `seminar` VALUES (230,'1999-04-28','14:00','Seminar Room 322','Phil Grant',NULL,'University of Wales Swansea',NULL,'Evolving Rules for Finite Element Mesh Generation','This talk is based on a paper with Elise Langham to be presented at the 1999 Congress on Evolutionary Computation. Social insects, such as termites and wasps, build highly complex structures using only stimuli from the local environment for coordination. This is known as stigmergy. This idea is employed for meshing finite element domains. A triangular mesh is a discretization of a domain into a set of approximately equilateral triangles whose sizes are dependent on a density function. The agents are programmed using rule-base techniques. A Genetic Algorithm is used to evolve a suitable set of rules which can be used by a colony of termite-like agents to mesh a given domain. The stigmergic approach generalizes well and can produce good quality meshes. No knowledge of the FEM is required to understand the seminar.',1,NULL);

INSERT INTO `seminar` VALUES (231,'1997-10-07','14:30','Seminar Room 322','Magne Haveraaen',NULL,'University of Bergen and University of Wales Swansea',NULL,'Some Underlying Ideas for Guarded Algebras','Much work has been done in the last 20 years on the use of universal algebra to specify data types and programs. A recurring problem in this work has been that there are many cases where one may not want to specify precisely what will happen, either because one does not care or it is too early to make the final decision. One solution is to use partial algebras in these cases. In this paper we suggest an alternative solution using the concept of guarded algebras and sketch its connection to the work on partial algebras.\r\n\r\nThis is collaborative work Eric G. Wagner ',1,NULL);

INSERT INTO `seminar` VALUES (232,'1997-10-14','14:30','Seminar Room 322','Judi Romijn',NULL,'CWI, Amsterdam',NULL,'A Three-Level Verification of a Tree Identify Protocol\r\nAnalysing a fragment of the IEEE 1394 Serial Bus','The IEEE 1394 Serial Bus Protocol has been developed for interconnecting computer and consumer end-equipment, providing quick, reliable and inexpensive high-bandwidth transfer of digitized video and audio.\r\n\r\nThe 1394 protocol is divided over several layers. In the physical layer, the initialization work is partly done by the tree identify phase, which has to span a tree in the bus topology in order to elect a leader among the components connected to the bus.\r\n\r\nWe have been working at the verification of the tree identify protocol at three levels of abstraction. The idea behind our approach is that some properties of this protocol involve much more detail than others. Our aim is to verify each desired property at the appropriate level of abstraction, and reuse the results of more abstract levels by means of refinement proofs.\r\n\r\nJoint work with: Marco Devillers, David Griffioen, and Frits Vaandrager (University of Nijmegen) ',1,NULL);

INSERT INTO `seminar` VALUES (233,'1997-10-21','14:30','Seminar Room 322','Argimiro A Arratia Quesada',NULL,'Universidad Simon Bolivar, Caracas and University of Leicester',NULL,'Capturing Complexity Classes Using Generalized Quantifiers','I will describe a technique, first developed by Immerman (1980''s) and later exploited by Stewart, and Stewart and myself, for syntactically interpret the computational complexity classes log-space, nondeterministic log-space, P, NP and Polynomial Space, via extensions of first order logic (FO) by generalized quantifiers (or Lindstrom''s quantifiers) corresponding to complete problems in the respective complexity classes listed above. I will explain a collapsing property for the logics thus formed, which occurs with respect to ordered finite structures, and then explain in the case of PSPACE, what happen if the order is not present. This is all Finite Model Theory. Loads of hand-waving, loads of fun.',1,NULL);

INSERT INTO `seminar` VALUES (234,'1997-10-28','14:30','Seminar Room 322','Martin Campbell-Kelly',NULL,'University of Warwick',NULL,'From Airline Reservations to Sonic the Hedgehog: A History of the Software Industry','This seminar presents a model of the international software industry based on historical principles. The shaping of the industry is described in terms of the interplay of technological, economic, and cultural forces.\r\n\r\nThe business history of the software industry sheds lights on such issues as: the reasons for the U.S. dominance of the industry; the failure of the pre-existing software firms to compete with Microsoft; and the role played by formal methods and software engineering.',1,NULL);

INSERT INTO `seminar` VALUES (235,'1997-11-04','14:30','Seminar Room 322','Magne Haveraaen',NULL,'University of Bergen and University of Wales Swansea',NULL,'Software Engineering for Computational Modelling','Computational modelling of real world phenomena is becoming an important research tool in the sciences. Currently this is hampered by the time and effort needed to develop good computational models, and the time and cost needed to port such models onto a high performance computer (HPC). A typical solver for a partial differential equation (PDE) totals 15-20 000 lines of code, embodying the discretisation technique as well as the actual solver itself. The code handles a limited set of problems, and can not easily be adapted to related phenomena or account for changes in numerical discretisation techniques. In many ways such a solver becomes legacy code for the group that developed it: both being their main tool for success, but also limiting what problems they may tackle.\r\n\r\nIn the course of the ESPRIT supported project SAGA (Scientific computing and algebraic abstractions) we have studied algebraic techniques for bulding comptutational models. They were vital for the identification of the abstractions used in the mathematics of PDEs and in program structuring, making us able to build a software library of high level, interchangeable parts. A new numerical discretisation technique to be added to the library may typically take about 4000 lines of code. Writing a solver for a new problem will be on the order of 2000 lines of code. Programs written this way also parallelises immediately for a range of HPC architectures.\r\n\r\nTo achieve these remarkable improvements, the traditional technique for developing computational models has to be replaced by a development technique more centered on the mathematical level of the problem.',1,NULL);

INSERT INTO `seminar` VALUES (236,'1997-11-14','14:30','Seminar Room 322','Alban Ponse',NULL,'University of Amsterdam',NULL,'Process Algebra with Four-Valued Logic','Three and four-valued logic arise naturally in descriptions of data types with error/exceptions and divergencies. We take this observation as a point of departure, and propose a combination of a fragment of four-valued logic and process algebra. This fragment can easily be extended to a truth-functionally complete logic (for instance by adding a definedness predicate), and is geared to a simple relation with process algebra via the guarded command. We present an operational semantics in SOS-style, and a completeness result for ACP with conditionals and four-valued logic.\r\n\r\nJoint work with Jan A. Bergstra (University of Amsterdam and Utrecht University).',1,NULL);

INSERT INTO `seminar` VALUES (237,'1997-11-18','14:30','Seminar Room 322','Julian Bradfield',NULL,'University of Edinburgh',NULL,'Modal mu-Calculus and its Alternation Hierarchy','The modal mu-calculus is a widely studied and widely used temporal logic for describing properties of systems, such as communications protocols and railway signalling systems. It''s a simple but powerful logic, with its power coming from fixpoint operators, which allow the expression of looping properties. When different least and greatest fixpoints depend upon one another, more complex properties appear. For a long time, however, it was not known whether this so-called \"alternation\" of fixpoints need be taken to arbitrary depths, or whether one or two alternations might always suffice.\r\n\r\nIn this talk I aim to describe the \"alternation hierarchy\" problem and its solution for a general audience. Accordingly, the first part of the talk will be an introduction to the modal mu-calculus, concentrating on its intuitive operational meaning rather than its formal semantics, and with a quick look at its major properties and applications. Then I''ll explain the notion of alternation and the alternation hierarchy, and why it is interesting to establish its strictness. I''ll then describe the techniques used in the solution of the problem, which are conceptually quite simple. If time permits, I can then fill in a few details.',1,NULL);

INSERT INTO `seminar` VALUES (238,'1997-12-02','14:30','Seminar Room 322','Chris Hankin',NULL,'Imperial College, London',NULL,'Program Analysis Games','By \"Program Analysis\" we refer to a collection of techniques that have been developed for statically analysing programs. Program analysis has applications in optimising compilers, program verification and debugging. We will start by reviewing the area and providing a simple example.\r\n\r\nFor object-oriented languages and functional languages, an important analysis is \"Control Flow Analysis\". We have recently developed a new approach to this problem. Our algorithm has the same complexity as state-of-the-art algorithms. In contrast to many approaches, it is semantics-based and easy to extend to new language features.\r\n\r\nThe approach is based on Game Semantics. The talk will include a brief overview of this new approach to programming language semantics.\r\n\r\n(The work reported in this seminar is joint with Pasquale Malacaria) ',1,NULL);

INSERT INTO `seminar` VALUES (239,'1998-01-13','14:30','Seminar Room 322','Neil Dodgson',NULL,'University of Cambridge',NULL,'Autostereo Displays: 3D without Glasses','3D displays which use glasses have not gained wide acceptance. Autostereo displays provide 3D perception without the need for special glasses or other head gear. I will look briefly at conventional \"3D with glasses\" systems before introducing the concept of an autostereo display. I will then go on to discuss the types of autostereo display and the mechanisms by which an autostereo display can be implemented.\r\n\r\nThree basic technologies exist to make autostereo displays: spatial multiplex, multi-projector and time-sequential. These can be used to make two types of useful device: two-view, head-tracked displays; and multi-view displays. The former tend to be single-viewer systems while the latter can support multiple viewers. The latter tend to require more processing power because they have more views than the former.\r\n\r\nResearch in the Computer Laboratory and Department of Engineering at Cambridge has produced a time-sequential, multi-view display. This is currently being commercialised by a Cambridge company: Autostereo Systems. I will report on the current state of the \"Cambridge Display\" and conclude with some discussion of future research directions in both display technology and image rendering.',1,NULL);

INSERT INTO `seminar` VALUES (240,'1998-01-27','14:30','Seminar Room 322','Pieter Hartel',NULL,'University of Southampton',NULL,'LATOS - A Lightweight Animation Tool for Operational Semantics','A lightweight tool is proposed to aid in the development of operational semantics. To use latos, an operational semantics must be expressed in its meta-language, which itself is a superset of Miranda. The latos compiler is smaller than comparable tools, yet latos is powerful enough to support publication quality rendering using LaTeX, fast enough to provide competitive execution and animation using Miranda or Haskell, and versatile enough to support derivation tree browsing using Netscape. Latos has been applied to a Java Secure Processor, which is a version of the Java Virtual Machine intended to run on smart cards. Latos has also been used with subsets of various programming languages. Latos is unique in that it helps to check that a specification is operationally conservative.',1,NULL);

INSERT INTO `seminar` VALUES (241,'1998-02-10','14:30','Seminar Room 322','Nigel John',NULL,'Silicon Graphics',NULL,'Hardware Assisted Volume Rendering: From Super Computers to the World Wide Web','In this talk, I will give an overview of how texture mapping hardware (both 3D and 2D) can be utilised to provide real-time volume rendering, including implementation details using OpenGL. A few years ago, such functionality was only available on high end visualisation super computers. Today, interactive volume rendering can be achieved on the desktop, and will be demonstrated during the talk.\r\n\r\nIs it possible to provide such functionality across the WWW? A volume rendering implementation using VRML and JAVA will also be demonstrated. This work was presented at \"Medicine Meets Virtual Reality\" in January.',1,NULL);

INSERT INTO `seminar` VALUES (242,'1998-02-17','14:30','Seminar Room 322','Derek Coleman',NULL,'King''s College, London',NULL,'UML: Standardising Object-Oriented Software Development','Last October, the Object Management Group (OMG) voted to accept the Unified Modeling Language (UML) as a standard for developing object-oriented software. UML is a language for specifying, visualizing, constructing, and documenting the artefacts of software systems, as well as for business modeling and other non-software systems. UML is a standard modeling language, not a standard process. Although the UML must be applied in the context of a process, experience has shown that different organizations and problem domains require different processes. UML was developed by Rational Software and its partners including IBM, Hewlett-Packard and Microsoft. UML is the successor to the modeling languages found in the Booch, OOSE/Jacobson, OMT and other methods. UML is a very large language that has been constructed from the union of a number of different notations including Object Model Diagrams, Use Cases, State Machines and Collaboration Diagrams. In this talk I will provide an overview of UML and discuss the role of the various UML notations in a systematic development process.',1,NULL);

INSERT INTO `seminar` VALUES (243,'1998-02-24','14:30','Seminar Room 322','Natasha Alechina',NULL,'University of Birmingham',NULL,'Querying Data with Irregular Structure','I will give a survey of recent work on `semistructured data'', that is, attempts to apply database methods to collections of information which do not conform to a fixed schema (such as heterogeneous databases, or fragments of the World Wide Web). I will also talk about some expressive power/complexity results for proposed query and description languages, and many open problems.',1,NULL);

INSERT INTO `seminar` VALUES (244,'1998-03-03','14:30','Seminar Room 322','Simon Schofield',NULL,'University of Westminster',NULL,'Non-Photorealistic Rendering: the Piranesi and Morandi Systems','Simon Schofield will be talking about his work in non-photorealistic rendering and the Piranesi interactive rendering system. He will also be unveiling some new non-photoreal rendering work done in collaboration with Lightwork Design Ltd.',1,NULL);

INSERT INTO `seminar` VALUES (245,'1998-04-28','14:30','Seminar Room 322','Luke Ong',NULL,'University of Oxford',NULL,'Game semantics','Game semantics is a way of understanding computing and other interaction systems by using elementary ideas of game playing as conceptual and analytical tools. It is an unusual denotational semantics in that it captures the algorithmic and dynamical aspects of the system. This makes it an ideal semantic framework in which to seek to unify the analyses of both the qualitative (semantics) and the quantitative (complexity) aspects of computing systems, while keeping them separate. In this talk we shall give a survey of game semantics focussing on the full abstraction problem for PCF. Time permitting, we shall also mention recent progress in using game semantics to understand higher-type complexity.',1,NULL);

INSERT INTO `seminar` VALUES (246,'1998-04-30','14:30','Seminar Room 322','Alan Woods',NULL,'University of Western Australia',NULL,'Colouring rules for finite trees','Consider a set of rules for colouring the vertices of any finite rooted tree with a fixed finite number of colours, starting at the leaves and working towards the root. Assume that the colour assigned to each vertex depends only on how many of its immediate predecessors (in the process) there are of each colour. What can be said about the fraction of n vertex trees with a given root colour?\r\n\r\nThis situation arises when considering sentences in monadic second order logic, about a rooted tree. It turns out that every such sentence has a well defined asymptotic probability. (In a slightly more general setting, this limit might, for example, be the probability that a \"random\" database organized as a rooted tree, has the property described by the sentence.)\r\n\r\nA second situation to which the theory applies, is in finding the probability that a Boolean formula of size n in k variables computes a particular Boolean function, when n is large compared to k.\r\n\r\nThe methods used involve a smattering of logic, generating series, nonnegative matrices, and even (just a touch of) complex analysis.',1,NULL);

INSERT INTO `seminar` VALUES (247,'1998-05-05','14:30','Seminar Room 322','Matthew Hennessy',NULL,'University of Sussex',NULL,'Types and Capabilities for Mobile Agents','A language called Dpi is presented for describing ``mobile agents''''. Both the syntax and reduction semantics is based on that of the picalculus in that communication is channel based, and these may be created dynamically and shared privately among agents. However in Dpi channels reside at explicit locations or sites and communication is local to sites. Moreover agents can migrate between sites to effect computations.\r\n\r\nWe describe a typing system for Dpi based on the novel notion of a location type. This associates with each location a set of capabilities, i.e. a set of permissions to perform certain behaviour. These capabilities include the ability to send or receive values, of specified types, on named channels.\r\n\r\nWe prove a Subject Reduction theorem and a Type Safety theorem. The latter is expressed formally in terms of the knowledge of an agent; well-typed agents can only perform actions which are consistent with their knowledge of their environment.',1,NULL);

INSERT INTO `seminar` VALUES (248,'1998-05-12','14:30','Seminar Room 322','Harry Ryland',NULL,'Westinghouse',NULL,'Railway Signalling and Safety','Railway signalling has evolved over the last 150 years to provide an extremely high level of safety, both for the railway staff and their customers. In the last 20 years, traditional approaches to safety have been modified by the introduction of microprocessors into a number of areas of signalling. New standards call for ever-improved methods for developing safety systems and software. In addition, safety cases have to be presented for all new equipment and installations. These trends, together with the increasing commercial pressures, result in a demand on those in the signalling supply industries to produce ever more innovative systems, software and methodologies.',1,NULL);

INSERT INTO `seminar` VALUES (249,'1996-10-15','14:30','Seminar Room 322','Roger Hubbold',NULL,'University of Manchester',NULL,'Auto-stereoscopic Display and Manipulation of 3D Medical Images','Direct volume rendering (DVR), by ray casting, has a number of advantages for visualizing data sets where structure boundaries are fuzzy, or where structures are nested - a common occurrence in medical images captured by scanners. However, DVR also poses some problems which must be solved if it is to find wide acceptance. First, fast but accurate algorithms are needed if interaction is required. Second, ways of presenting the resulting images unambiguously are called for, so that structures and depth relationships can be correctly perceived. Third, we need techniques for interaction with the 3D images.\r\n\r\nIn this talk I will outline how we are trying to solve these problems by integrating a parallel compute-server, network protocols to access the server from low-cost workstations, and novel auto-stereoscopic display techniques for presenting and interacting with the resulting images. I will discuss the application of these methods to the complex and safety-critical procedure of radiation therapy planning.',1,NULL);

INSERT INTO `seminar` VALUES (250,'1996-10-22','14:30','Seminar Room 322','Bruce G Batchelor',NULL,'University of Cardiff',NULL,'There is More to (Machine) Vision than Meets the Eye','Machine Vision is finding numerous applications in a wide variety of industries and it is essential for a Vision Engineer to become involved with the design of mechanical handling devices for parts and / or materials, lighting, optics, image sensors (cameras), analogue and digital electronics, software, algorithms, Artificial Intelligence, QA (Quality Assurance) techniques, ergonomics of the human-computer interface and industrial engineering. The speaker maintains that Machine Vision is an area of Systems Engineering, and hence has a distinct identity from Computer Vision, just as it has form human and animal vision. A wide variety of applications of Machine Vision will be discussed and outline solutions demonstrated using an image processing system devised by the author and his colleagues.',1,NULL);

INSERT INTO `seminar` VALUES (251,'1996-11-05','14:30','Seminar Room 322','Phil Willis',NULL,'University of Bath',NULL,'Should Animators Compute?','The computing community has put a lot of effort into software for animation, rather less towards software for animators. The key question seems to be can we provide software systems which are acceptable to animators? In fact the problem is more complex. Should computers be used at all; if so, for what tasks are they most productive?\r\n\r\nThe talk will examine some of these issues, arising out of our experience working with Cambridge Animation Systems (the leading supplier of cel (2D) animation software) and Siriol Productions (a leading animation house), as well as our own `Animachine'' research project in this area.',1,NULL);

INSERT INTO `seminar` VALUES (252,'1996-11-26','14:30','Seminar Room 322','David W. Walker',NULL,'University of Cardiff',NULL,'Software Libraries for Message Passing Computers','The development of portable and efficient software libraries for message passing computers is important fostering the more widespread use of such machines in science and engineering. This talk will discuss parallel application software libraries, in particular the ScaLAPACK library for performing dense linear algebra computations. Important features in the design of parallel software libraries will be considered, as well as strategies for the efficient use of hierarchical memory. Recent work on the design of out-of-core dense linear algebra algorithms will be discussed based on a set of parallel I/O routines. Some object-oriented approaches to parallel reusable software will be considered and compared with current procedural approaches. Finally, the integration of parallel software libraries into application-specific problem-solving environments will be discussed.',1,NULL);

INSERT INTO `seminar` VALUES (253,'1996-12-03','14:30','Seminar Room 322','Sylvia Wilbur',NULL,'QMW University of London',NULL,'Is Desktop Video Really Useful?','PC-based interactive video is becoming increasingly viable, using either commercial products operating over broadband network connections, or Internet-based software. But is desktop video just a tool for occasional remote meetings, or does it have the potential to become a general-purpose medium in a computer environment?\r\n\r\nEarlier research suggested the medium would not be very useful as a component of a networked computer. However, the results of an experimental four-node system based on analogue video, built at QMW, suggest that desktop video is useful for working with colleagues when certain criteria are met.',1,NULL);

INSERT INTO `seminar` VALUES (254,'1996-12-10','14:30','Seminar Room 322','Peter Robinson',NULL,'University of Cambridge',NULL,'Video User Interfaces','A joint project between the University of Cambridge Computer Laboratory and the Rank Xerox Research Centre in Cambridge has been looking at ways of using digitised video from television cameras in user interfaces for computer systems.\r\n\r\nThe DigitalDesk is built around an ordinary physical desk and can be used as such, but it has extra capabilities. A video camera is mounted above the desk, pointing down at the work surface. This camera''s output is fed through a system that can detect where the user is pointing and it can read documents that are placed on the desk. A computer-driven projector is also mounted above the desk, allowing the system to project electronic objects onto the work surface and onto real paper documents.\r\n\r\nAnother approach is used in BrightBoard. A video camera is pointed at an ordinary whiteboard and its output fed into a computer. The whiteboard thus becomes an alternative means of controlling the computer.\r\n\r\nThese systems show how computers can be built into everyday objects with simple user interfaces that do not require expert knowledge to operate. As such they exemplify a new approach to human-computer interaction where the computer is brought into our offices instead of squeezing an office uncomfortably into a computer screen.',1,NULL);

INSERT INTO `seminar` VALUES (255,'1997-02-11','14:30','Seminar Room 322','Grant Malcolm',NULL,'Oxford University',NULL,'A Hidden Agenda: an algebraic combination of the object and logic paradigms','This talk describes a programme of research directed to unifying the functional, logic, and object paradigms in an algebraic setting. Our chief resource in this endeavour is \"hidden algebra\", a framework that allows the specification of abstract machines with hidden local state.\r\n\r\nThe initial goal of our research was both straightforward and ambitious: to give a semantics for software engineering, and in particular for the object paradigm, supporting correctness proofs that are as simple and mechanical as possible. This emphasises proofs rather than models, and thus suggests an equational approach, because equational logic is fully expressive, yet simple and has a great deal of mechanical support.\r\n\r\nHidden algebra takes as basic the notion of behavioural abstraction, or more precisely, behavioural satisfaction: our specifications characterise how objects (and systems) behave, not how they are implemented; they provide a notion of behavioural type, which we prefer to call a hidden theory.\r\n\r\nBuilding on the algebraic specification tradition, hidden algebra uses some sorts for data values (of attributes) as in the algebraic approach to data types, and some for states, as in the algebraic approach to abstract machines; the latter give us objects and classes. These two uses of sort are dual: induction establishes properties of data types, while coinduction establishes properties of objects. Similarly, initiality is important for data types, whereas finality is important for objects. Our correctness proofs show that one such theory behaviourally satisfies another.\r\n\r\nAn important contribution of this programme of research is the development of powerful hidden coinduction techniques for proving behavioural correctness of object systems.',1,NULL);

INSERT INTO `seminar` VALUES (256,'1997-02-25','14:30','Seminar Room 322','Peter Hall',NULL,'University of Cardiff',NULL,'Nonphotorealistic Rendering by Q-mapping','Nonphotorealistic rendering is an emerging as an important research direction for Computer Graphics. The goal is to produce images that are characteristic of hand-crafted pictures. Much previous work in this area has progressed by emulating physical media such as pen-and-ink, is two-dimensional, and relies on user-interaction. We introduce Q-mapping, a method that automatically renders nonphotorealistic images from three-dimensional models. Q-mapping can draw, paint, photograph, can create natural textures such as fur, and (importantly) it has its own unique styles. Its styles all derive from a single \"texture\" that automatically adapts to suit lighting conditions. It has uses in Scientific Visualisation and Computer Graphics.',1,NULL);

INSERT INTO `seminar` VALUES (257,'1997-04-15','14:30','Seminar Room 322','Gregory McColm',NULL,'University of Southern Florida',NULL,'Models of Random Graphs','There are many models of random structures around -- more than just random n-vertex, m-edge graphs, or the n-vertex trees, etc -- and which one you use depends on what you want to do. Many of these models fix a number of vertices, and then choose a number of edges: sometimes, the edges are tossed in, one at a time. We take a general look at these models, and at ''upwards closed'' properties of graphs (properties which, once true, remain true if more edges are added), and we look at some applications of some of these models. We will also look at the asymptotic probabilities of logical queries on these models.',1,NULL);

INSERT INTO `seminar` VALUES (258,'1997-04-29','14:30','Seminar Room 322','Peter Sewell',NULL,'University of Cambridge',NULL,'Typing for Concurrent Systems','Typing for sequential languages is reasonably well understood. In contrast, types that capture behavioural disciplines of concurrent systems are only beginning to be intensively studied. In this talk I''ll give a non-technical overview of some recent work in the area, illustrating the range of possible motivations and results.\r\n\r\nI''ll touch on type systems for variants of the pi-calculus that prevent run-time errors (via simple typing), support operational reasoning and guarantee confluence (via input/output subtyping and linear typing), and allow implementation optimisations in a distributed setting (via located channel subtyping). I''ll conclude by briefly discussing type systems for synchronous circuits that support compositional abstraction results. ',1,NULL);

INSERT INTO `seminar` VALUES (259,'1997-05-06','14:30','Seminar Room 322','Yakup Paker',NULL,'QMW University of London',NULL,'Parallel Video Processing','The requirements for high quality images for broadcasting and some of the advanced applications like Virtual Studios, tele-presence and Virtual Reality require much more powerful computational facilities than is available today. Parallel processing offers a scalable solution in order to meet the stringent real time requirements.\r\n\r\nFor a recently completed EU project in Virtual Studios a novel parallel architecture has been developed (ML-PVA Mona Lisa- Parallel Video Accelerator) to handle TV quality video streams in real time. The current project AMPA is investigating the use of parallel high performance multimedia chips as an accelerator for video processing.',1,NULL);

INSERT INTO `seminar` VALUES (260,'1995-10-17','14:30','Seminar Room 322','Martin Berzins','','University of Leeds',NULL,'Numerical solution of an engine knock model problem','The numerical solution of a combustion problem modelling knock in a car engine is considered. The solution techniques used combine unstructured mesh finite volume methods with error control in both space and time. The numerical results obtained are contrasted with results obtained using a more traditional approach. Extensions to parallel solution methods are considered.',1,NULL);

INSERT INTO `seminar` VALUES (261,'1995-10-24','14:30','Seminar Room 322','David Duce',NULL,'Rutherford Laboratory',NULL,'PREMO - An emerging ISO/IEC standard for multi-media applications','There is an activity in ISO/IEC SC24, the standards committee responsible for computer graphics and image processing, to develop a new standard called PREMO, PResentation Environment for Multi-media Objects, aimed at providing an extensible programming environment for multi-media applications. This seminar will describe the motivation for PREMO and the current state of the development, and some of the difficulties of standardizing Functionality in this area.\r\n\r\nThere has been some work to develop a formal description of the PREMO object model and the PREMO functionality for managing time and synchronization. This work, which is being carried out by the presenter and others in the ERCIM Computer Graphics Network, will also be described. The approach taken uses a combination of the Z and Object-Z notations.',1,NULL);

INSERT INTO `seminar` VALUES (262,'1995-10-31','14:30','Seminar Room 322','Jonathan Bowen',NULL,'University of Reading',NULL,'Provably correct hardware compilation','The availability of Field Programmable Gate Arrays (FPGA) now allows the fast generation of hardware by a purely software process. This enables the automatic compilation of a high level description of hardware into a \"netlist\" of individual digital hardware components. The compilation scheme may be verified, allowing an arbitrary number of circuits to be compiled with the same level of assurance, instead of needing to be checked individually. The compilation theorems may be rapid-prototyped very directly in a logic programming language such as Prolog. The high level language used for the circuit description is based on Occam, which includes parallel constructs, allowing algorithms for (naturally parallel) hardware to be coded conveniently and efficiently.',1,NULL);

INSERT INTO `seminar` VALUES (263,'1995-11-07','14:30','Seminar Room 322','Vivek Gore',NULL,'University of Edinburgh',NULL,'Sampling almost uniformly from a context-free language','We present an algorithm for sampling almost uniformly at random from the $n$-slice of the language $L(G)$ generated by an arbitrary context-free grammar $G$. (The $n$-slice of a language $L$ over an alphabet $\\Sigma$ is the subset $L \\cap \\Sigma^n$ of words of length exactly $n$.) The algorithm runs in time $m^{O(\\log m)}$, where $m = \\max\\{n|G|, \\log \\varepsilon^{-1}\\}$, $|G|$ is a natural measure of the size of the grammar $G$, and $\\varepsilon$ bounds the variation of the output distribution from uniform. The algorithm uses a couple of old, simple and beautiful results, one from circuit complexity and the other from the area of Monte Carlo approximation algorithms. In this talk I shall try to explain these two results and then show how they are used in our algorithm. This is joint work with Dr Mark Jerrum.',1,NULL);

INSERT INTO `seminar` VALUES (264,'1995-11-14','14:30','Seminar Room 322','Mike Denham',NULL,'University of Plymouth',NULL,'Autonomous mobile robot control using temporal sequence learning','This talk will discuss some of the issues involved in designing autonomous mobile robots and describe an approach to the control of such agents which uses learnt sequences over time of pairs of sensory stimuli and motor actions, so-called sensory-action sequences (SAS), to build an internal model of the world in which the robot is navigating. A reward system is used to determine when and if sequences are learnt, based either on the achievement of a particular goal or the detection of novelty. A set of changing goals is therefore what intrinsically drives the robot both to move in such a way as to re-experience some previously encountered sensory experience, e.g., associated with a particular location in the robot''s world, whilst also acquiring knowledge about its world through curiosity and responding to novel sensory experiences. Associative links created between SAS provide a dynamic goal-related sensory-action based internal model in memory from which \"working memories\" can be \"activated\". The presence of a particular goal determines which set of \"working memories\" are \"active\" at a particular time, and stimulates a competition amongst these, which determines the most appropriate action to take at any time. A computational model of the system will be described, based on a particular neural network for learning, recognising and reproducing temporal sequences.',1,NULL);

INSERT INTO `seminar` VALUES (265,'1995-11-21','14:30','Seminar Room 322','Martin Dyer',NULL,'University of Leeds',NULL,'A simpler approach to randomized volume estimation','The first polynomial time algorithm for estimating the volume of a convex body in high dimension was give by Dyer, Frieze and Kannan. Their technique relied on an eigenvalue estimation called \"conductance\" and isoperimetric inequalities for convex bodies. There have been great subsequent imrovements, but all have used essentially the same approach. We will show that, in the light of some of these improvements, a rather simpler method, called \"coupling\" can be used to prove the existence of polynomial time algorithms.\r\n\r\nA review of the background, and an outline of the new approach, will be given. (No previous knowledge of the problem or the methods will be assumed.) This is joint work with Mark Jerrum and Russ Bubley.',1,NULL);

INSERT INTO `seminar` VALUES (266,'1995-11-28','14:30','Seminar Room 322','Robin Whitty',NULL,'South Bank University',NULL,'Software product measurement: an apology','Software metrics started out in the 70''s with attempts to quantify the quality and complexity of source code. Attention has since shifted away from the software product to the process by which it is produced, hence the current fashion for software process improvement. Meanwhile the nature of the product itself is changing rapidly due to another fashion: object-orientation. So has anything of lasting value been achieved during quarter of a century of research in product measurement? How should this research be viewed in the context of current developments in software engineering? I shall look at some industrial applications, the state of play in object-oriented metrics, and my own particular interest: program flowgraph functions.',1,NULL);

INSERT INTO `seminar` VALUES (267,'1995-12-05','14:30','Seminar Room 322','Richard Banach',NULL,'University of Manchester',NULL,'The Pi-Calculus and MONSTR','The pi-calculus is a process algebra in which channel names can act both as transmission medium and as transmitted data. Its basic atomic actions are individual point to point communications which are nondeterministically selected and globally sequentialised. MONSTR is a term graph rewriting language designed to be easily implementable on distributed architectures and features limited synchronisation facilities. The talk describes a translation of a version of the pi-calculus, into MONSTR. It confronts the rather different synchronisation abilities of the two systems, which are resolved by using a suitable communication protocol in the MONSTR system. The issue of the correctness of the translation raises a number of problems, not the least of which is \"what does correctness mean?\", which is resolved by demanding that a pi-calculus system and its translation are capable of the same sequences of communications. One direction of the correctness proof is then a relatively straightforward simulation, while the converse becomes a substantial exercise in serialisability. The translation thus provides a non-trivial case study in verification.',1,NULL);

INSERT INTO `seminar` VALUES (268,'1995-05-23','14:30','Seminar Room 322','Sachio Hirokawa',NULL,'University of Wales Swansea and Kyushu University',NULL,'Teaching a computer how to read data structure','Programs are made of data structures and algorithms. We specify the data structures and specify the operations on them. But we cannot actually run our programs without an instance of such data structures. And there is no canonical way to input such instances of data structures in conventional languages like C, Fortran, Pascal. Consider, for example, writing a program which calculates the normal form of a logical formula or a program which transforms a grammar into a standard form. They contain recursive data structures. The algorithms are easily found in text books. We would write the program in lisp or in prolog. Why not in C? A reason may be that lisp and prolog have built-in procedures to read data structures. And another reason may be that we do not like to write a parser of formulas or the language. I would like to report about a system being developed. It automatically generates such procedures from the definitions of data structures written in Pascal. I would like to talk about some experience and applications.',1,NULL);

INSERT INTO `seminar` VALUES (269,'1995-05-25','14:30','Seminar Room 322','Zoe Lacroix',NULL,'Universite de Paris-Sud and INRIA',NULL,'Generalized implicit definitions on finite structures','We propose a natural generalization of the concept of implicit definitions over finite structures, allowing non-determinism at an intermediate level of a (deterministic) definition. These generalized implicit definitions offer more expressive power than classical implicit definitions. Moreover, their expressive power can be characterized over unordered finite structures in terms of the complexity class NP $\\cap$ co-NP. Finally, we investigate a subclass of these where the non-determinism is restricted to the choice of a unique relation with respect to an implicit linear order, and prove that it captures UP $\\cap$ co-UP also over the class of all finite structures. These results shed some light on the expressive power of non-deterministic primitives.',1,NULL);

INSERT INTO `seminar` VALUES (270,'1995-07-04','14:30','Seminar Room 322','Steffen van Bakel',NULL,'University of Turin',NULL,'Intersection types for lambda calculus and term rewriting systems','The type systems used for functional programmings languages are for the larger part presented as systems for extended lambda calculi. However, there are several reasons to also consider other reduction systems than lambda calculus: the following definition for example,\r\n\r\n    * In-Left (Pair (x,y)) -> x\r\n    * In-right (Pair (x,y)) -> y\r\n    * Pair (In-left (z), In-right (z)) -> z\r\n\r\ncannot be expressed in lambda calculus. The systems we will consider in this talk are Curryfied term rewriting systems.\r\n\r\nThe talk will start with a short discussion of intersection type assignment for Lambda Calculus, together with its major properties, like\r\n\r\n    * a strong normalization result,\r\n    * a head-normalization result,\r\n    * an approximation theorem, together with a filter model,\r\n    * principal types.\r\n\r\nWe will then present Curryfied term rewriting systems together with a notion of intersection type assignment. This notion will be defined using the approach for the lambda calculus, taking the syntactical differences into account. We will discuss what kind of restriction has to be made in order to be able to prove for term rewriting systems similar results (if possible) as above for lambda calculus.',1,NULL);

INSERT INTO `seminar` VALUES (271,'1995-01-24','14:30','Seminar Room 322','Rick Thomas',NULL,'University of Leicester',NULL,'Formal languages and the word problem for groups','If we have a generating set X for a group G, then every word in the symbols X represents an element of G. The word problem for G is defined to be the set of all words that represent the identity element. If we can decide whether or not a word is in the word problem, then we can decide whether or not two words represent the same element of G.\r\n\r\nIn this talk, we will be interested in the following question: if the word problem is known to lie in a certain class C of languages (such as the class of regular languages), what can we say about the group? On the face of it, the question does not appear to be well posed, in that the word problem with respect to one generating set might lie in C while the word problem with respect to another might not, but we find that, under fairly mild assumptions on C, this cannot happen.\r\n\r\nThe talk will survey some of what is known in this area, in particular mentioning some work on groups where the word problem is a \"one-counter\" language. Some familiarity with the rudiments of formal language theory will be useful (such as the meanings of the words regular, context free, recursive, ...), but very little beyond the definition of a group is required from group theory.',1,NULL);

INSERT INTO `seminar` VALUES (272,'1995-01-31','14:30','Seminar Room 322','Antony Galton',NULL,'University of Exeter',NULL,'How to get rid of unwanted fuzz','Zeno''s runner, Thompson''s lamp, Littlewood''s whip: anyone who sets about trying to systematize the principles of temporal reasoning sooner or later comes face to face with the problem of what to do about the possibility of a proposition''s changing its truth-value infinitely often in a finite period of time. This phenomenon is called \"fuzz\" by Prior, \"intermingling\" by Hamblin, \"clustered variation\" by Davis. Should we allow it to happen, and if not, how can we prevent it? I shall take a look at the history of attempts to rule out phenomena of this kind by means of axioms in a temporal logic: and show that most of them fail to do exactly what was intended.',1,NULL);

INSERT INTO `seminar` VALUES (273,'1995-02-08','14:30','Seminar Room 322','Mathai Joseph',NULL,'University of Warwick',NULL,'Using transformations for proving timing and fault-tolerance properties of programs','Let program P be represented by a predicate defining its initial condition and a set of atomic state transition operations. Assume that faults in the execution environment are modelled by a program F consisting of a set of atomic\"fault\" operations. Then the effect of faults on the execution of P can be modelled as a transformation of P into FF(P,F). In a similar way, if P is executed on a set Pr of processors under a scheduler S, then this implementation of P can be represented as a transformation I(P) and the deadlines of P will be satisfied if they are satisfied by I(P).\r\n\r\nThis talk will mainly consider the verification of timing properties using transformations. I will show how real-time program specification and schedulability, which have traditionally been studied in different analytical frameworks, can be considered in the same framework and how a scheduler can be considered generically in terms of a scheduling policy.',1,NULL);

INSERT INTO `seminar` VALUES (274,'1995-02-10','14:30','Seminar Room 322','Ernst-Rudiger Olderog',NULL,'University of Oldenburg',NULL,'Design of real-time systems: from requirements to programs','We present a transformational approach to the design of real-time systems. The design starts from requirements formulated in a subset of Duration Calculus called \"implementables\" and aims at timed OCCAM-like programs. While Duration Caculus is state-based, OCCAM is event-based. To bridge this gap, an intermediate specification language SL is used. The approach is illustrated by the example of a computer-controlled gas burner.',1,NULL);

INSERT INTO `seminar` VALUES (275,'1995-02-28','14:30','Seminar Room 322','Kung-Kiu Lau',NULL,'University of Manchester',NULL,'Software engineering, object-oriented programming, and logic program synthesis','Logic programming provides a uniquely uniform, logical formalism for specification, deduction, and program. It should therefore be an ideal paradigm for program synthesis. Indeed, program synthesis was one of the first topics of research in the early days of LP, and more recently, it has become an active area of research again. The question is \"Is logic program synthesis relevant to real-world object-oriented software engineering?\". In this talk, I will give a short survey of work in this area, and briefly consider this question.',1,NULL);

INSERT INTO `seminar` VALUES (276,'1995-03-07','14:30','Seminar Room 322','Hugh Glaser',NULL,'University of Southampton',NULL,'Distributed Prograph','Prograph is a programming language and environment which is available on the Macintosh family of computers. The language uses a dataflow model of evaluation, and it provides class-based data abstraction with single inheritance. The system is entirely graphical, other than for the text of method names, and supports the program development process in a highly-interactive fashion.\r\n\r\nThe graphical nature of the language suggests that it should provide a good vehicle to exploit parallel and distributed systems.\r\n\r\nFollowing a brief introduction to the Prograph system, this seminar will discuss some of the issues associated with using Prograph to describe distributed systems.',1,NULL);

INSERT INTO `seminar` VALUES (277,'1995-03-14','14:30','Seminar Room 322','Graham Megson',NULL,'University of Newcastle',NULL,'Non-linear scheduling and allocation in regular arrays: a genetic algorithm approach','The mapping of so called regular algorithms specificed as recurrence equations in euclidean lattice via unformization and pipelining techniques is now well understood. Essentially the lattice is enclosed in a convex polytope determined by loop bounds of the algorithm and conditions based on an embedding of the polytope into a (pointed) convex cone can be used to derived linear programming problems to determine optimal linear (conflict free) schedules for evaluating the computation at integer co-ordinate positions in the polytope. A similar technique can be used to determine a placement (or allocation) of computation to processors. Thus we have methods for determining systematically the best timing and allocation pair and consequently optimal architectures for the recurrence equations. In this lecture we consider ways of extending the framework of algorithm mapping into the non-linear domain. In particular we propose new algorithms to generate non-linear timing and allocation functions based on genetic algorithm techniques. Such techniques increase the range of systematic methods considerable and overcome one of the major restrictions in the field.',1,NULL);

INSERT INTO `seminar` VALUES (278,'1994-10-04','14:30','Seminar Room 322','Magne Haveraaen',NULL,'University of Bergen',NULL,'Sophus -- a C++ library developed using algebraic techniques for solving partial differential equations','This talk presents a C++ library developed for solving partial differential equations. The library''s components were developed using algebraic techniques (algebraic specification of the individual components and category theory for the large scale organisation). The library is implemented using finite element methods for sequential and parallel processing (on a network of Sun workstations). A spectral methods implementation is planned.',1,NULL);

INSERT INTO `seminar` VALUES (279,'1994-10-06','14:30','Seminar Room 322','Magne Haveraaen',NULL,'University of Bergen',NULL,'How to program parallel machines without knowing it','This talk is on a functional programming technique suitable for implementing generalised recurrence relations, such as those used in finite element methods and dynamic programming as well as for other algorithms with regular data dependency patterns. Programs in this form may be mapped onto parallel architectures by program code defining certain embeddings.',1,NULL);

INSERT INTO `seminar` VALUES (280,'1994-10-18','14:30','Seminar Room 322','Ralph Martin',NULL,'University of Wales, Cardiff',NULL,'Capturing designers intentions from sketch input of 2D drawings','In the early stages of design of such objects as mechanical components, sketches of 2D geometry need to be input to a CAD system. This talk will discuss why mouse- and menu-based interfaces such as are found in most of today''s drawing packages are not well suited to this task, and why a freehand sketching approach is more appropriate. In turn, this means that the computer system must be capable of interpreting the designer''s intentions, as such a sketch will be far from perfect, and turning the sketch into an internal description of the represented geometry. This talk will describe a program we have developed (Easel) which uses a series of steps to produce a final tidied drawing. Easel involves such processes as detection of various curve types, inferring constraints the designer intended, and methods of attempting to enforce those constraints.',1,NULL);

INSERT INTO `seminar` VALUES (281,'1994-10-25','14:30','Seminar Room 322','Sarah Rees',NULL,'University of Newcastle upon Tyne',NULL,'Finite state automata in group theory','The talk will be an introduction to the theory of automatic groups.\r\n\r\nAn automatic group is a group with certain finiteness properties which allow it to be described by finite state automata. Automatic groups arise naturally out of many mathematical questions in geometry and topology. Often they are groups of isometries of negatively curved (hyperbolic) space. The automata associated with automatic groups allow calculations to be done which would normally be infeasible.\r\n\r\nThe construction and manipulation of the finite state automata associated with an automatic group depend on various techniques from computer science, such as the Knuth Bendix rewriting procedure and algorithms to manipulate finite state automata. Other interesting classes of groups can be associated with more complex classes of machines than FSAs.',1,NULL);

INSERT INTO `seminar` VALUES (282,'1994-11-01','14:30','Seminar Room 322','Keith Clark',NULL,'Imperial College',NULL,'April: a language for implementing distributed agent based systems','April is a programming language that has evolved out of research into designing and implementing concurrent logic programming languages and in trying to use such languages to implement multi-agent systems. It is best suited to course grained concurrent symbolic computation using machines on a local area network, but it can be used to implement ''global'' applications running over the internet.\r\n\r\nIt can be also viewed as a concurrent object oriented programming language, or an actor style language. It inherits from logic programming pattern matching processing of messages and pattern matching retrieval of information. This talk will introduce the key features of April.',1,NULL);

INSERT INTO `seminar` VALUES (283,'1994-11-08','14:30','Seminar Room 322','Colin Runciman',NULL,'University of York',NULL,'Functional programs for embedded systems',NULL,1,NULL);

INSERT INTO `seminar` VALUES (284,'1994-11-15','14:30','Seminar Room 322','Marta Kwiatkowska',NULL,'University of Birmingham',NULL,'Concurrency, fairness and complexity','We consider a connection between fairness and $\\Pi_0^3$ sets of functions made recently by Darondeau, Nolte, Priese and Yoccoz, and extend their work to cater for effective asynchronous transition systems with concurrency structure represented by a Mazurkiewicz independency relation.',1,NULL);

INSERT INTO `seminar` VALUES (285,'1994-11-22','14:30','Seminar Room 322','Peter Jimack',NULL,'University of Leeds',NULL,'Parallel and adaptive finite element algorithms for solving partial differential equations','Our present research at Leeds is looking at efficient parallel and adaptive algorithms for the solution of differential equations on domains of a potentially complex geometry. This talk will focus mainly on our work into scalable distributed memory finite element algorithms for the solution of elliptic PDEs on unstructured grids. In particular the issues of parallel mesh generation and parallel domain decomposition preconditioning will be addressed. The talk will also consider related issues such as suitable measures of parallel efficiency for large problems, and different possibilities for adaptive remeshing in a parallel environment.',1,NULL);

INSERT INTO `seminar` VALUES (286,'1994-11-29','14:30','Seminar Room 322','Mike Gordon FRS',NULL,'University of Cambridge',NULL,'Mechanizing higher order logic on top of set theory','Set theory is the standard foundation for mathematics. However, the majority of general purpose mechanized proof assistants support versions of type theory (higher order logic). Examples include Alf, Automath, Coq, Ehdm, HOL, IMPS, Lambda, LEGO, Nuprl, PVS and Veritas. For many applications type theory works well and provides, for specification, the benefits of type-checking that are well-known in programming. However, there are areas where types get in the way or seem unmotivated. Furthermore, most people with a scientific or engineering background already know set theory, whereas type theory may appear inaccessable and so be an obstacle to the uptake of proof assistants based on it.\r\n\r\nMy talk will describe some experiments (using the HOL system) in combining set theory and type theory; the aim is to get the best of both worlds in a single system. Three approaches have been tried, all based on an axiomatically specified type V of ZF-like sets:\r\n\r\n   1. HOL is used without any additions besides V\r\n   2. a \"hard-wired\" shallow embedding of the HOL logic into V is provided\r\n   3. a mechanism is implemented for converting HOL axiomatic theories into set-theoretic definitional theories\r\n\r\nThese approaches are illustrated with two examples: the construction of lists and a simple lemma in group theory. Various advantages and disadvantages are discussed and some tentative conclusions drawn.\r\n\r\nKnowledge of HOL will not be assumed.',1,NULL);

INSERT INTO `seminar` VALUES (287,'1994-12-06','14:30','Seminar Room 322','Howard Barringer',NULL,'University of Manchester',NULL,'Symbolic verification of deterministic machines','One approach commonly used for establishing the behavioural equivalence of hardware systems uses state-space exploration to establish a bisimulation relation between the systems, modelled as labelled transition systems. It has the distinct advantage of being automatic, and can produce counter-example information when a verification fails, although this is usually in low level terms of traces leading to divergence. However, it suffers from the problem of combinatorial explosion, even though its domain of applicability can be significantly extended with the introduction of special encodings, such as binary decision diagrams (BDDs).\r\n\r\nA second method represents system behaviour using logical expressions, and then establishes equivalence by employing theorem-proving techniques. It operates abstractly at a high level, thus not suffering from combinatorial explosion. Further, when two systems are shown to be different, it is possible to give structured debugging feedback information at the level of the initial system representation. Although varying degrees of automation are possible, the approach currently requires significant user input in order to be able to establish design equivalence.\r\n\r\nIn this talk, we introduce a novel verification approach which effectively merges the above techniques. We take Park and Milner''s standard (strong) bisimulation equivalence as our notion of equivalence between labelled transition systems. However, we present the transition systems abstractly as deterministic machines and then define a state bisimulation relation between the state spaces of the two machines. This is provably equivalent to a strong bisimulation between the derived transition systems for the deterministic machines. The advantage of this is that each system is expressed by a pair of (response and evolution) functions, together with an initial state, and the state bisimulation can then be established semi-automatically through a state evolution rule. The analysis proceeds in a truly symbolic manner, at the level at which the design is expressed.',1,NULL);

INSERT INTO `seminar` VALUES (288,'1994-04-26','14:30','Seminar Room 322','Ananda Manikam',NULL,'University of Wales Swansea',NULL,'Inductive machine learning',NULL,1,NULL);

INSERT INTO `seminar` VALUES (289,'1994-05-03','14:30','Seminar Room 322','Lincoln Wallen',NULL,'University of Oxford',NULL,'Logic programming via proof-valued computations',NULL,1,NULL);

INSERT INTO `seminar` VALUES (290,'1994-05-10','14:30','Seminar Room 322','Tom Anderson',NULL,'University of Newcastle upon Tyne',NULL,'Can software systems ever be safe? (Safety: truth and fibs)','Software is going to be used in lots of systems in which the activation of a bug could mean one or more people dying. Indeed, such systems already exist and people have already died. Because safety is an issue of public concern, and of such obvious importance, computer specialists need to have a consistent perspective on safety and reliability with respect to software as well as hardware. This talk will pose some questions, and seek to provoke debate on the answers.',1,NULL);

INSERT INTO `seminar` VALUES (291,'1994-01-25','14:30','Seminar Room 322','Cliff Jones',NULL,'University of Manchester',NULL,'A concurrent object-based design notation and its semantics','A software development method which makes it possible to verify one set of design decisions before moving to the next stage of design has the potential to save time for developers. For sequential programs, it is not difficult to find formal design methods which are \"compositional\". But the interference which comes from parallel processes makes compositionality much more elusive. Earlier research on documenting rely and guarantee conditions did something to tame the dragon of interference but the approach still required too much work to expect it to be used even as widely as sequential development methods like VDM. It would appear that constraining the languages in which programs are written is the only way of reducing the work involved. This seminar will exhibit the problem with examples, outline some notations to reason about interference, and explain why concepts from object-oriented programming languages are helpful. Finally, a semantics in terms of the pi-calculus will be sketched.',1,NULL);

INSERT INTO `seminar` VALUES (292,'1994-02-01','14:30','Seminar Room 322','Tony Hoare FRS',NULL,'University of Oxford',NULL,'Models and algebra','Science makes progress by constructing mathematical models, deducing their observable consequences, and testing them by experiment. Successful theoretical models are later taken as the basis for engineering methods and codes of practice for design of reliable and useful products. Models can play a similar central role in the progress and practical application of Computing Science.\r\n\r\nA model of a computational paradigm starts with choice of a carrier set of potential direct or indirect observations that can be made of a computational process. A particular process is modelled as the subset of observations to which it can give rise. Process composition is modelled by relating observations of a composite process to those of its components. Indirect observations play an essential role in such compositions. Algebraic properties of the composition operators are derived with the aid of the simple theory of sets and relations. Feasibility is checked by a mapping from a more operational model.\r\n\r\nA model constructed as a family of sets is easily adapted as a calculus of design for total correctness. A specification is given by an arbitrary set containing all observations permitted in the required product. It should be expressed as clearly as posssible with the aid of the full power of mathematics and logic. A product meets a specification if its potential observations form a subset of its permitted observations. This principle requires that all envisaged failure modes of a product are modelled, as indirect observations, so that their avoidance can be proved. Specifications of components can be composed mathematically by the same operators as the components themselves. This permits top-down proof of correctness of designs even before their implementation begins. Algebraic properties and reasoning are helpful throughout development. Non-determinism is seen as no problem, but rather as a part of the solution. ',1,NULL);

INSERT INTO `seminar` VALUES (293,'1994-02-08','14:30','Seminar Room 322','Matt Fairtlough',NULL,'University of Sheffield',NULL,'The proof theory of Lax logic','In this work we investigate a novel intuitionistic modal logic, called Propositional Lax Logic, with promising applications to the construction of formal proofs, and in particular to the formal verification of computer hardware. The logic has emerged from an attempt to express correctness \"up to\" behavioural constraints (a central notion in hardware verification) as a logical modality. The resulting logic is unorthodox in several respects. As a modal logic it is special since it features a single modal operator O (somehow) that has a flavour of both a modality of possibility and of necessity. As for hardware verification it is special since it is an intuitionistic rather than classical logic which so far has been the major logic of choice. Finally, its models are unusual since they feature worlds with inconsistent information and furthermore the only frame condition is that the O-frame be a subrelation of the ->-frame. In the work we will provide some motivation for Propositional Lax Logic and present several technical results. We will investigate some of its proof-theoretic properties, and prove a cut-elimination theorem for a standard Gentzen-style sequent presentation of the logic. We sketch proofs of soundness and completeness for a class of fallible two-frame Kripke models. In this framework we present a concrete and rather natural class of models from hardware verification such that the modality O models correctness up to timing constraints. This is a report on joint work with Dr. Michael Mendler of theTechnical University of Denmark, to whom any correspondence should be directed.',1,NULL);

INSERT INTO `seminar` VALUES (294,'1994-03-01','14:30','Seminar Room 322','Stan Wainer',NULL,'University of Leeds',NULL,'Ordinal bounds for programs','This is joint work with H. Schwichtenberg (Munich), due to appear in the forth- coming volume \"Feasible Mathematics II\" edited by P.Clote and J.Remmel and published by Birkhauser. We use methods of Proof Theory and Subrecursive Hierarchies to assign ordinals to classes of terminating programs, the idea being that the ordinal assignment provides a uniform way of measuring complexity \"in the large\". We are not concerned with placing prior, e.g., polynomial, bounds on computation length, but with general methods of assessing complexity of natural classes of functional programs. The crucial idea is supplied by the Omega-+ rule of Buchholz which gives a method of describing computational uniformity in terms of uncountable \"tree ordinals\" which are then \"collapsed\" in a now-standard way to give sub-recursive bounds in terms of the Slow Growing Hierarchy. As an example the machinery is applied to a large class of higher order programs based on Plotkin''s PCF but with \"bounded fixed point operators\" controlled by given well-orderings. If the given well-ordering is just N, the Howard ordinal arises as a natural upper bound.',1,NULL);

INSERT INTO `seminar` VALUES (295,'1994-03-08','14:30','Seminar Room 322','John Vince',NULL,'Hughes Ltd., Crawley',NULL,'Virtual reality techniques in flight simulation',NULL,1,NULL);

INSERT INTO `seminar` VALUES (296,'1994-03-15','14:30','Seminar Room 322','John Darlington',NULL,'Imperial College',NULL,'Parallel application development using skeleton functions','Programming parallel machines is notoriously difficult. Factors contributing to this difficulty include the complexity of concurrency, the effect of resource allocation on performance and the current diversity of parallel machine models. The net result is that effective portability, which depends crucially on predictability of performance, has been lost.\r\n\r\nFunctional programming languages have been put forward as solutions to these problems, because of the availability of implicit parallelism. However, performance will be generally poor unless the issue of resource allocation is addressed explicitly, diminishing the advantage of using functional languages in the first place.\r\n\r\nWe have been developing a methodology which is a compromise between the extremes of explicit imperative parallel programming and implicit functional programming. This methodology use a repertoire of higher-order parallel forms, skeletons, as the basic building blocks for parallel implementations and provides program transformations which convert between skeletons, giving portability between differing machines. Resource allocation issues are documented for each skeleton/machine pair and are addressed explicitly during implementation in an interactive, selective manner, rather than by explicit programming. The ideas underlying skeleton programming can be extended into particular application domains facilitating the construction of domain specific parallel application generators.\r\n\r\nThis talk will outline the philosophy underlying skeleton based application development, contrasting it with the general purpose programming approach and describe current implementation and performance results. ',1,NULL);

INSERT INTO `seminar` VALUES (297,'1993-09-21','14:30','Seminar Room 322','Erik Palmgren',NULL,'Uppsala University',NULL,'Nonstandard modelling of infinite computations',NULL,1,NULL);

INSERT INTO `seminar` VALUES (298,'1993-10-19','14:30','Seminar Room 322','Ivor Grattan-Guinness',NULL,'Middlesex University',NULL,'Living apart: algebraic logic versus mathematical logic, 1850-1910','The algebraic logicians, largely working out from George Boole and Augustus De Morgan, adopted practices from algebras of their time. They stated laws (such as commutativity) and stressed duality; for theories of collections they drew upon the part-whole method. Content was even similar: Boole''s algebra of logic was modelled upon different operators, while De Morgan''s logic of relations closely followed functional equations. By and large (especially from Boole) they sought consequences from premises, omitting details of deriviation. Both strands were united in their principal successors, Charles S. Peirce and Ernst Schroeder. They often saw logic as applied mathematics.\r\n\r\nThe mathematical logicians, especially Giuseppe Peano and his school, and then their British followers Bertrand Russell and A.N. Whitehead, were inspired by mathematical analysis; so their theory of collections was Cantorian, with membership and inclusion explicitly distinguished. They emphasised axioms and definitions and laid out derivations in detail. They hoped to embrace \"all\" or parts of mathematics within their conception, making mathematics a sort of applied logic. Gottlob Frege was similar in some ways, but he did not gain a wide reputation.\r\n\r\nNo definitive position over logic and foundations of mathematics emerged during the 1900s, although the mathematical traditions rather eclipsed the algebraic. At that time emerged also (and none too coherently) the metamathematics of David Hilbert, and also model theory in the USA with Edward Huntingdon and others. Further, the paradoxes of set theory came to be recognised as serious issues for all approaches.',1,NULL);

INSERT INTO `seminar` VALUES (299,'1993-11-02','14:30','Seminar Room 322','Alan Gibbons',NULL,'University of Warwick',NULL,'Problems on pairs of trees and the four colour problem of planar maps','In 1977, Appel and Haken proved that every planar graph is four vertex colourable. Their proof is very long and the implicit algorithm for four colouring is rather impractical. This talk descibes a new characterisation of the four colour problem by showing that it is equivalent, by a very fast reduction, to a simply stated problem of 3-edge colouring pairs of trees. This new problem, in turn, is equivalent to non-trivial subclasses of other problems in mathematics and computer science of which we describe three. These are problems of intersection of regular languages, of integer linear equations and of algebraic expressions. In the general case, all these problems require exponential time to find a solution. We show that if these problems are defined on pairs of trees, then polynomial time is sufficient. In addition, these problems offer enticing opportunities in the search for a shorter proof of the four colour theorem and for more practical algorithms for four colouring planar graphs.',1,NULL);

INSERT INTO `seminar` VALUES (300,'1993-11-09','14:30','Seminar Room 322','John Lloyd',NULL,'University of Bristol',NULL,'Programming in Goedel','In this seminar, I will discuss the programming language Goedel, which is a declarative, general-purpose programming language in the family of logic programming languages. It is a strongly typed language, the type system being based on many-sorted logic with parametric polymorphism. It has a module system. Goedel supports infinite precision integers, infinite precision rationals, and also floating-point numbers. It can solve constraints over finite domains of integers and also linear rational constraints. It supports processing of finite sets. It also has a flexible computation rule and a pruning operator which generalises the commit of the concurrent logic programming languages. Considerable emphasis is placed on Goedel''s meta-logical facilities which provide significant support for meta-programs that do analysis, transformation, compilation, verification, debugging, and so on. The declarative nature of Goedel makes it particularly suitable for use as a teaching language; narrows the gap which currently exists between theory and practice in logic programming; makes possible advanced software engineering tools such as declarative debuggers and compiler generators; reduces the effort involved in providing a parallel implementation of the language; and offers substantial scope for parallelization in such implementations. I will illustrate the main features of the language with various example programs.',1,NULL);

INSERT INTO `seminar` VALUES (301,'1993-11-18','14:30','Seminar Room 322','Ronan Sleep',NULL,'University of East Anglia',NULL,'Term graph rewriting','Term graph rewriting refers to techniques and theories for representing terms and term rewriting rules as graphs and graph rewriting rules. Many modern programming paradigms - most notably the functional and logic paradigms - have term rewriting at their heart, although the control regimes and semantics are very different. Practical implementations of these languages share subterms using pointers, and the machine code for such programs manipulates shared structures which we call term graphs. Reasoning about the correctness and efficiency of such representations relies on our ability to reason about term graph rewriting systems, and to relate them to other semantic models. Used in this way, term graph rewriting offers a model of computation which is closer to real implementations than pure term rewriting, but which avoids much unnecessary machine detail. The use of term graph rewriting to implement term rewriting will be illustrated, and some results concerning the correctness of term graph rewriting for term rewriting presented.',1,NULL);

INSERT INTO `seminar` VALUES (302,'1993-11-23','14:30','Seminar Room 322','Martin Thomas',NULL,'Praxis plc, Bath',NULL,'The industrial relevance of theoretical computer science','The IT industry is in a mess. Most commercial and industrial IT departments, worldwide, are incompetent, yet the requirements for new IT systems grow in importance and complexity every year. There are now 1K of code in an electric razor, 4K in a vacuum cleaner, 500K in a television, and (allegedly) 7 million lines of Ada in the Boeing 777. Not surprisingly, many systems fail, with expensive (and occasionally fatal) consequences. This seminar suggests what we need to do about it and, in passing, offers some help in writing the \"industrial relevance\" section of your next grant application.',1,NULL);

INSERT INTO `seminar` VALUES (303,'1993-11-30','14:30','Seminar Room 322','Huw Jones',NULL,'Middlesex University',NULL,'Iterated function systems in the modelling of natural phenomena','IFSs (Iterated Function Systems) were popularised by Michael Barnsley, who used them to generate images of organic forms showing high degrees of self similarity, such as the Spleenwort Fern. The seminar outlines the main concepts of IFS image generation and shows how structures within a three dimensional environment can be illustrated. Examples include still and animated images of trees and clouds which have genuine three dimensional characteristics and can be animated.',1,NULL);

INSERT INTO `seminar` VALUES (304,'1993-12-07','14:30','Seminar Room 322','Samson Abramsky',NULL,'Imperial College',NULL,'Full abstraction for PCF','The full abstraction problem for PCF is one of the best-known and longest standing problems in the semantics of computation. It concerns the semantic characterization of sequential, functional computation at higher types, and holds (part of) the key to the proper understanding of many important programming mechanisms. This problem has recently been solved by the author and his colleagues, using tools from game semantics and Linear logic. The background and history of the problem, and the key ingredients of the solution, will be described. (This is joint work with Radha Jagadeesan and Pasquale Malacaria.)',1,NULL);

INSERT INTO `seminar` VALUES (305,'2001-06-07','14:00','Robert Recorde Room','Dave Rodgman',NULL,'Swansea University',NULL,'Refraction in Discrete Ray Tracing','Refraction is an important graphics feature for synthesising photo-realistic images. This paper presents a study on refraction rendering in volume graphics using discrete ray tracing. We describe four basic approaches for determining the relative refractive index at each sampling position, and examine the relative merits of them. We discuss two types of anomalies associated with some approaches and three different mechanisms for controlling sampling intervals. We apply the refraction rendering to objects with uniform as well as non-uniform optical density, and objects built upon mathematical scalar fields as well as volumetric datasets. In particular, the study shows that the normal estimation plays a critical role in synthesising aesthetically pleasing images. The paper also includes the results of various tests, and our quantitative and qualitative analysis.',5,NULL);

INSERT INTO `seminar` VALUES (328,'2001-06-07','14:00','Robert Recorde Room','Andrew Winter',NULL,'Swansea University',NULL,'A Volume Graphics API','This paper describes vlib, a generic application programming interface for volume graphics which supports many of the significant developments in the field to date. We present an overview of the interface and describe how its novel object modeling framework is able to facilitate a variety of modeling and rendering effects. We also discuss a volumetric ray-tracing algorithm for producing high quality images with a minimal of memory overhead. The paper closes with some comments on our freeware implementation of the interface.',5,NULL);

INSERT INTO `seminar` VALUES (329,'2001-06-07','14:00','Robert Recorde Room','Richard Satherley',NULL,'Swansea University',NULL,'Hybrid Distance Field Computation for Volumetric Datasets','Distance fields are a widely investigated area within the area of Volume Graphics. Research is divided between applications; such as -- skeletonisation, hypertexture, voxelisation, acceleration of rendering techniques, correlation and collision detection; and the fundamental algorithmic calculation of the distance fields. This paper concentrates on the latter by presenting a new method for calculating distance fields and comparing it with the current \"best\" approximate method and the \"true\" Euclidean distance field. Details are given of the algorithm, and the acceleration methods that are used for calculating the true distance field. Brief descriptions of applications for these accurate distance fields are given at the end of the paper.',5,NULL);

INSERT INTO `seminar` VALUES (306,'1996-02-27','14:30','Seminar Room 322','Ken Brodlie',NULL,'University of Leeds',NULL,'Scientific visualization - past, present and future','This talk will begin with a look at the development of scientific visualization as a discipline, starting long before the computer was ever thought of, and addressing the question of what the computer has contributed. The middle part of the talk will review the current state of the art, and the tools that are now available to the scientist and engineer. The final part of the talk will look at two current major limitations of these tools: first, the fact that scientists want problem solving environments, not data visualizers; second, the fact that scientists work in teams and want CSCW-type tools, not single-user applications. Current research aimed at overcoming these limitations will be described.',1,NULL);

INSERT INTO `seminar` VALUES (307,'1996-01-30','14:30','Seminar Room 322','Alan Chalmers',NULL,'University of Bristol',NULL,'Photo-realistic visualisation of archaeological sites','A great deal of evidence exists for a variety of activities at most archaeological sites. However, the interpretation of these activities, even using the archaeological finds of elaborate ritual architecture, specific furniture and artefacts, is difficult without a complete and flexible three dimensional reconstruction of their context. Recent developments in computer graphics have made it possible to \"construct\" virtual environments on a computer and view photo-realistic images of these scenes. It is possible, therefore, to recreate an archaeological site on a computer and provide the viewer with a representation of the site as it may have appeared to the original inhabitants. This experience will be enhanced by the photo-realism of the computer model including accurate illumination and the presence of environmental and climatic factors such as flame, smoke, dust or fog. The calculation of such photo-realism is very computationally intense and so parallel processing is necessary in order to produce the images in reasonable times.\r\n\r\nThis seminar will discuss computer graphic and parallel processing techniques that are being developed to enable archaeologists to evaluate hypotheses concerning ritual performances, utilisation, structure, contents and development of important heritage sites.',1,NULL);

INSERT INTO `seminar` VALUES (308,'1996-03-05','14:30','Seminar Room 322','Abbas Edalat',NULL,'Imperial College',NULL,'Dynamical systems, measures and fractals via domain theory','Domain theory investigates properties of \"continuous posets\". It was introduced by Dana Scott in 1970 as a mathematical theory of computation in the semantics of programming languages, and since then, it has developed extensively in various areas of semantics. In recent years, a new direction for applications of domain theory has emerged as it was uncovered that there are indeed natural domain-theoretic computational structures in dynamical systems, measure theory and fractals. In particular, a computational framework for measure theory was established, which then led to a generalisation of the Riemann theory of integration with diverse applications.\r\n\r\nWe will give a survey of this work and describe a number of results and algorithms in the periodic doubling route to chaos and in the theory of iterated function systems, with applications in the one-dimensional random field Ising model, forgetful neural nets and fractal image compression. We also explain the basics of a programming language with a real number data type for exact real number computation which includes computing integrals.',1,NULL);

INSERT INTO `seminar` VALUES (309,'1996-01-24','14:30','Seminar Room 322','Jan Heering',NULL,'CWI, Amsterdam',NULL,'PIM - A complete transformational toolkit for compilers','PIM is a \"transformational toolkit\" to be used by compilers and analysis tools for imperative languages, and has been applied to such problems as program slicing, symbolic evaluation, conditional constant propagation, and dependence analysis. PIM consists of the untyped lambda calculus extended with a first-order rewrite system that characterizes the behavior of lazy stores and generalized conditionals. We systematically derive a complete equational axiomatization of the lazy store component of PIM as the culmination of a sequence of increasingly powerful equational systems starting from a straightforward \"interpreter\" for closed terms.\r\n\r\nThis is joint work with Jan Bergstra (University of Amsterdam), T.B. Dinesh (CWI, Amsterdam), and John Field (IBM T.J. Watson Research Center).',1,NULL);

INSERT INTO `seminar` VALUES (310,'1996-01-23','14:30','Seminar Room 322','Mike Holcombe',NULL,'University of Sheffield',NULL,'Complete functional testing','All software systems are subject to testing - for some of them, particularly safety-critical systems, testing is the major activity in the project. The principal purpose of testing is to detect faults in a software system (to enable their removal). However, no existing methods allow us to make any statement about the type or precise number of faults that remain undetected after testing is completed. In particular we are unable to state that specific components of the system are free from fault after testing has been concluded. We demonstrate that a new method for generating test cases allows us to make sensible claims about the level and type of faults remaining after the testing process is complete. The method is illustrated by a case study.',1,NULL);

INSERT INTO `seminar` VALUES (311,'1996-03-12','14:30','Seminar Room 322','Chris Tofts',NULL,'University of Manchester',NULL,'Abstraction in probabilistic process algebras','There has been an increasing interest over the last few years in the use of formal approaches in performance modelling and simulation. In particular probabilistic process algebra permits a natural description of interacting systems. In this talk we address some issues in the efficient calculation of performance parameters derived from the formal description of these systems. We shall concentrate on abstraction techniques that permit us to address large scale problems and have reliable approximation properties.',1,NULL);

INSERT INTO `seminar` VALUES (312,'1996-02-22','14:30','Seminar Room 322','Ian Wand',NULL,'University of York',NULL,'Ada - is it a success?','The Ada programming language has been in use for 12 years and a major revision of the language, now called Ada 95, was adopted as a new international standard on 15 February 1995. There have been a number of accounts of the use of Ada (83) in a variety of applications but little has been revealed about the construction, performance and correctness of Ada compilers. We will discuss two issues: (a) the proand efficient compiler (based on experience from the York Ada compiler project), and (b) the lessons learned from the use of Ada and how they have influenced the language revision process.\r\n\r\nWe conclude by evaluating the impact that Ada has made on the software engineering process. Are programming language issues as important today as they were perceived to be in the 70s and 80s? Indeed, was Ada a ''red herring''?',1,NULL);

INSERT INTO `seminar` VALUES (313,'1996-02-20','14:30','Seminar Room 322','John Whiteman',NULL,'Brunel University',NULL,'Numerical methods for partial differential Volterra equations','The subject of partial differential equations with memory, Volterra-type equations, is first introduced by discussing a number of physical problems which can be modelled in this way. These are mainly taken from viscoelasticity theory. The equations are essentially of canonical elliptic, parabolic and (second order) hyperbolic type, each augmented with a \"hereditary\" integral. The numerical analysis of problems involving these equations is briefly surveyed, after which some recent results are presented in more detail. Both classical (i.e., finite difference plus quadrature) and modern (i.e., finite element) techniques of time discretization are discussed, with particular regard in the latter case to the possibility of providing robust adaptive solvers.',1,NULL);

INSERT INTO `seminar` VALUES (157,'2007-10-02','14:00','Robert Recorde Room','Manfred Droste','http://www.informatik.uni-leipzig.de/~droste/','Universit&auml;t Leipzig','http://www.informatik.uni-leipzig.de/idxeng.html','Weighted automata and quantitative logics','In automata theory, a classical result of B&uuml;chi states that the recognizable languages are precisely the ones definable by sentences of monadic second order logic. We will present a generalization of this result to the context of weighted automata. A weighted automaton is a classical nondeterministic automaton in which each transition carries a weight describing e.g. the ressources used for its execution, the length of time needed, or its reliability. The behaviour (language) of such a weighted automaton is a function associating to each word the weight of its execution. We develop syntax and semantics of a quantitative logics; the semantics counts ''how often'' a formula is true. Our main result shows that if the weights are taken in an arbitrary commutative semiring, then the functions associated to weighted automata are precisely the ones definable by sentences of our quantitative logic.\r\n(Joint work with Paul Gastin (Cachan)). ',1,'');

INSERT INTO `seminar` VALUES (314,'1996-10-24','14:30','Seminar Room 322','Dafydd Rees',NULL,'University of Wales Swansea',NULL,'An Algebraic Approach to Distributed Object Computing',NULL,5,NULL);

INSERT INTO `seminar` VALUES (315,'1996-10-31','14:30','Seminar Room 322','Anthony Fox',NULL,'University of Wales Swansea',NULL,'Algebraic Modelling of Microprocessors',NULL,5,NULL);

INSERT INTO `seminar` VALUES (316,'1996-11-07','14:30','Seminar Room 322','Adrian Leu',NULL,'University of Wales Swansea',NULL,'Multi Volume Rendering on Distributed Memory Architectures',NULL,5,NULL);

INSERT INTO `seminar` VALUES (317,'1996-11-14','14:30','Seminar Room 322','Simon Michael',NULL,'University of Wales Swansea',NULL,'to be announced',NULL,5,NULL);

INSERT INTO `seminar` VALUES (318,'1996-11-21','14:30','Seminar Room 322','Jason Anderson',NULL,'University of Wales Swansea',NULL,'Intelligent Agents within the Concurrent Engineering Design Arena',NULL,5,NULL);

INSERT INTO `seminar` VALUES (319,'1996-12-05','14:30','Seminar Room 322','Kristian Stewart',NULL,'University of Wales Swansea',NULL,'to be announced',NULL,5,NULL);

INSERT INTO `seminar` VALUES (320,'2000-09-14','14:00','Robert Recorde Room','Rafal Somla',NULL,'Uppsala University',NULL,'On the expressive power of CTL*','In this talk, we show that the expressive power of the branching time logic CTL* coincides with that of the class of bisimulation invariant properties expressible in so-called monadic path logic: monadic second-order logic in which second-order (set) quantification is restricted to paths. The result in itself is interesting and important for the problem of classifying temporal logics. However, of equal interest and importance is its method of proof, which exploits the use of Ehrenfeucht-Fraisse games.\r\n\r\n(This is a presentation of the paper by Faron Moller and Alex Rabinovich from LICS''99. My purpose in studying it is to get a taste of \"Games for Processes\", which is the title of Faron''s research project at Uppsala which I just started working on as a PhD student.)',5,NULL);

INSERT INTO `seminar` VALUES (321,'2000-10-12','14:00','Robert Recorde Room','Monika Seisenberger',NULL,'University of Munich',NULL,'Computer Demo: Interactive theorem proving and program synthesis',NULL,5,NULL);

INSERT INTO `seminar` VALUES (322,'2000-11-23','14:00','Robert Recorde Room','Jens Blanck',NULL,'Swansea University',NULL,'Domain theory and CVG',NULL,5,NULL);

INSERT INTO `seminar` VALUES (324,'2001-02-20','14:00','Robert Recorde Room','Jens Blanck',NULL,'Swansea University',NULL,'Effectivity of regular spaces',NULL,5,NULL);

INSERT INTO `seminar` VALUES (325,'2001-03-08','14:00','Robert Recorde Room','Ulrich Berger',NULL,'Swansea University',NULL,'On the computational content of the axiom of choice','This talk builds on a paper with the same title by S Berardi, M Bezem and T Coquand (Proceedings of TLCA''95, LNCS 902, 602-622, 1995). The following story tries to illustrate the problem.\r\n\r\nHarry Potter''s first Coursework at Hogwarts\r\n\r\nThe coursework is to get a jewel out of the schools treasure. Since Harry did not pay much attention to the lessons he does not know how to do this by magic, but instead has to use other information he collected when snooping around at Hogwarts. Harry found out that there is an infinite number of secret doors at Hogwarts, and that the Professors McGonagal, Dumbledore and Snape are able to do the following actions:\r\n\r\n    * If Professor McGonagal is given one after the other a key k1 for the first door, a key k2 for the second door, and so on, she will, after having received a finite number of keys k1, ..., kn, return a jewel. The number n may depend on the keys she got (there are many different keys for each door).\r\n\r\n\r\n    * If Professor Dumbledore is given a number n and a method that produces from any key for the n-th door a jewel, then he will return a jewel.\r\n\r\n\r\n    * If Professor Snape is given a jewel, then he will return for any number n a key for the n-th door.\r\n\r\nHow can Harry manage to get a jewel with the help of the three Professors?\r\n\r\nHint: use the magic of recursion and continuous higher-order operations.\r\n\r\nThe puzzle above contains the essence in the problem of finding computational content for the Classical Axiom of Choice. In the talk I will present a solution to this problem and discuss its possible impact to program synthesis from classical proofs.',5,NULL);

INSERT INTO `seminar` VALUES (326,'2001-05-10','14:00','Robert Recorde Room','Simon Hands',NULL,'Swansea University',NULL,'Supercomputing Quarks','Lattice gauge theory (LGT) simulations are currently our best theoretical technique for understanding the strong interaction responsible for binding nucleons (protons and neutrons) within nuclei, and quarks and gluons within nucleons. I will review LGT and the physics it addresses focussing on the numerical methods used, and attempt to explain why LGT has become a \"Grand Challenge\" project requiring the dedicated use of the world''s most powerful computers. One such machine, the APEMille, capable of a sustained performance of 20 Gflops, has just arrived on level 4 of the Vivian Tower, and will be used by the Swansea theory group to study the strong interaction under extreme conditions of pressure and density.',5,NULL);

INSERT INTO `seminar` VALUES (327,'2001-06-05','14:00','Robert Recorde Room','Martin Otto',NULL,'Swansea University',NULL,'Finite conformal hypergraph covers with two applications',NULL,1,NULL);

INSERT INTO `seminar` VALUES (330,'2001-07-05','14:00','Board Room','Peter Hancock',NULL,'',NULL,'How to Program a Cruise Missile in Martin-Loef Type Theory',NULL,5,NULL);

INSERT INTO `seminar` VALUES (331,'2001-09-11','14:00','Board Room','Jens Blanck',NULL,'Swansea University',NULL,'On exact real arithmetic ',NULL,5,NULL);

INSERT INTO `seminar` VALUES (332,'2001-09-18','14:00','Robert Recorde Room','Oliver Kullmann',NULL,'Swansea University',NULL,'Generalized satisfiability problems ','In my talk I want to discuss \"systems of problem instances\", a very general (and natural) framework for \"satisfiability problems\", where it has to be decided whether a \"satisfying assignment\" of some sort exists or not. Examples for systems of problem instances are clause-sets, constraint satisfaction problems, or systems of polynomial equations over any field (in case of an ordered field like the real numbers also inequalities can be considered).\r\n\r\nTo handle unsatisfiability for systems of problem instances, a general form of relativised resolution is introduced. Relativised tree resolution in this general context (corresponding to backtracking algorithms searching for satisfying assignments) can be quasi-automatised, that is, there is a (natural) satisfiability decision procedure D* whose running time on unsatisfiable instances is quasi-polynomial in the length of a shortest tree resolution refutation. Full resolution admits a weaker form of automisation. Both general procedures use an \"oracle\" U for detecting \"easy\" cases of unsatisfiable instances to capture *relativised* resolution.\r\n\r\nAn important feature of D* is, that D* also finds satisfying assignments parallel to the search for short refutations. The running time of D* in inputs P is tightly governed by a hardness measure h(P), which on unsatisfiable inputs is closely related to (relativised) tree resolution complexity, and on satisfiable instances now opens up the possibility to prove also some kind of general lower bounds on *satisfiable* inputs.\r\n\r\nD* deploys also an oracle S for detection of \"easy\" satisfiable cases, and thus can be adapted to a given problem class from \"practice\" (in fact, in this way a far reaching generalisation of Stalmarck''s algorithm is reached). Efficient handling of satisfiable inputs needs different algorithmic \"resources\" than what is needed for handling unsatisfiability, and therefore I consider the separation of oracles U and S as important. In order to construct efficient oracles S, I will give a short overview on the theory of \"autarky systems\" for the search of satisfying assignments, which enables us to use methods from combinatorial optimisation.',5,NULL);

INSERT INTO `seminar` VALUES (333,'2001-09-27','14:00','Robert Recorde Room','Anton Setzer',NULL,'Swansea University',NULL,'Interactive Programs in Dependent Type Theory','Functional programming is essentially the evaluation of expressions. Programs we can write in this way are not very interactive: we can only apply an expression to several arguments and get as answer the result of the reduction of this expression, so we have a fixed finite number of inputs and one output. This way one cannot write truly interactive programs like an editor, which have possibly infinitely many interactions with the user.\r\n\r\nWe will review several approaches taken in functional programming for solving the problem and present our approach which is essentially based on Moggi''s monads: interactive programs are possibly non-well-founded trees with nodes labeled by interactive commands and with branching degree over the response set corresponding to this command. We will then discuss the problem: as in ordinary mathematics, in dependent type theory most standard structures are well-founded, but what is needed for defining interactive programs are non-well-founded structures. We will slightly generalize this problem to the problem of having rules for final coalgebras in dependent type theory.\r\n\r\nWe will then, using ideas present in Peter Aczel''s non-well-founded set theory, introduce such rules: Non-well-founded structures are introduced as graphs, but we have only restricted elimination rules available. We define rules corresponding to coiteration and corecursion. We indicate, why the successor for the co-natural numbers is difficult to compute using coiteration and results in high complexity, whereas with corecursion this is simple, similar to the fact that the predecessor is difficult to compute for the natural numbers using iteration, but easy using recursion. Finally we introduce useful functions for defining elements of the final coalgebras: while- and repeat loops, a fixed-point construction and redirect, which allows to translate programs in a high-level language into a low level language by replacing commands of the high level language by programs in the low level language. Redirect allows to refine programs in a top down approach and to build libraries.',5,NULL);

INSERT INTO `seminar` VALUES (334,'2001-10-02','14:00','Robert Recorde Room','Anton Setzer',NULL,'Swansea University',NULL,'Interactive Programs in Dependent Type Theory (Cont.)','Functional programming is essentially the evaluation of expressions. Programs we can write in this way are not very interactive: we can only apply an expression to several arguments and get as answer the result of the reduction of this expression, so we have a fixed finite number of inputs and one output. This way one cannot write truly interactive programs like an editor, which have possibly infinitely many interactions with the user.\r\n\r\nWe will review several approaches taken in functional programming for solving the problem and present our approach which is essentially based on Moggi''s monads: interactive programs are possibly non-well-founded trees with nodes labeled by interactive commands and with branching degree over the response set corresponding to this command. We will then discuss the problem: as in ordinary mathematics, in dependent type theory most standard structures are well-founded, but what is needed for defining interactive programs are non-well-founded structures. We will slightly generalize this problem to the problem of having rules for final coalgebras in dependent type theory.\r\n\r\nWe will then, using ideas present in Peter Aczel''s non-well-founded set theory, introduce such rules: Non-well-founded structures are introduced as graphs, but we have only restricted elimination rules available. We define rules corresponding to coiteration and corecursion. We indicate, why the successor for the co-natural numbers is difficult to compute using coiteration and results in high complexity, whereas with corecursion this is simple, similar to the fact that the predecessor is difficult to compute for the natural numbers using iteration, but easy using recursion. Finally we introduce useful functions for defining elements of the final coalgebras: while- and repeat loops, a fixed-point construction and redirect, which allows to translate programs in a high-level language into a low level language by replacing commands of the high level language by programs in the low level language. Redirect allows to refine programs in a top down approach and to build libraries. ',5,NULL);

INSERT INTO `seminar` VALUES (335,'2001-10-18','14:00','Board Room','J. Roger Hindley',NULL,'Swansea University',NULL,'The early days of combinators and lambda calculus','This talk will be about the origins and early development of combinatory logic and lambda calculus. Both these systems led to impressive technical successes in their very early years, and, after some a period of relative disuse, became standard linguistic tools in computer science. The talk will contain material from an article being written with Felice Cardone for a book on the history of mathematical logic, to be published by North-Holland Elsevier. It will also mention some points which cannot be decently put into writing. ',5,NULL);

INSERT INTO `seminar` VALUES (336,'2001-10-30','14:00','Robert Recorde Room','Peter G. Hinman',NULL,'University of Michigan, visiting Swansea',NULL,'Density of Medvedev degrees of Pi^0_1-classes',NULL,5,NULL);

INSERT INTO `seminar` VALUES (337,'2001-12-11','14:00','Board Room','Paulo Oliva',NULL,'BRICS, Århus, visiting Swansea',NULL,'On the relation between modified bar recursion and other bar recursive definitions','I will present the work I have been doing with Ulrich Berger during the last two months. The talk will roughly consist of three parts: Introduction to the different forms of bar recursion and how they have been used; analysis of the relation between them, including the results we have obtained; open problems. ',5,NULL);

INSERT INTO `seminar` VALUES (323,'2001-02-15','14:00','Robert Recorde Room','Peter Hancock','','','','Machine-checked wellordering-proofs','',5,'');

INSERT INTO `seminar` VALUES (338,'2002-03-07','14:00','Robert Recorde Room','Faron Moller',NULL,'Swansea University',NULL,'Lower bounds for equivalence checking one-counter automata',NULL,5,NULL);

INSERT INTO `seminar` VALUES (339,'2002-03-12','14:00','Robert Recorde Room','Oliver Kullmann',NULL,'Swansea University',NULL,'Phase transitions and thresholds, the Advanced Encryption Standard (AES), databases for combinatorial problems, and heuristics for SAT solvers ','Random propositional formulas (CNF''s) and their satisfiability distribution have attracted a great deal of attention in the area of complexity theory and algorithms, especially since the connection with the nature of phase transitions in Physics is under investigation (see \"Determining computational complexity from characteristic ''phase transitions''\"in Nature, 1999, volume 400, pages 133-137).\r\n\r\nBased on AES (the successor of DES) I want to present a new generator (\"OKsolver\") for random CNF''s and discuss, why this generator is useful. A large database for these instances shall be built up to systematically explore the phenomenon of phase transitions (experimentally and numerically). Finally I will present a program how to use this database in order to get a general adaptive heuristics for a given SAT solvers A, resulting in a (hopefully) improved SAT solver A''.',5,NULL);

INSERT INTO `seminar` VALUES (340,'2002-03-19','14:00','Robert Recorde Room','Oliver Kullmann',NULL,'Swansea University',NULL,'Phase transitions and thresholds, the Advanced Encryption Standard (AES), databases for combinatorial problems, and heuristics for SAT solvers (II)','Random propositional formulas (CNF''s) and their satisfiability distribution have attracted a great deal of attention in the area of complexity theory and algorithms, especially since the connection with the nature of phase transitions in Physics is under investigation (see \"Determining computational complexity from characteristic ''phase transitions''\"in Nature, 1999, volume 400, pages 133-137).\r\n\r\nBased on AES (the successor of DES) I want to present a new generator (\"OKsolver\") for random CNF''s and discuss, why this generator is useful. A large database for these instances shall be built up to systematically explore the phenomenon of phase transitions (experimentally and numerically). Finally I will present a program how to use this database in order to get a general adaptive heuristics for a given SAT solvers A, resulting in a (hopefully) improved SAT solver A''. ',5,NULL);

INSERT INTO `seminar` VALUES (341,'2002-03-21','14:00','Robert Recorde Room','Oliver Kullmann',NULL,'Swansea University',NULL,'Phase transitions and thresholds, the Advanced Encryption Standard (AES), databases for combinatorial problems, and heuristics for SAT solvers (III)','Random propositional formulas (CNF''s) and their satisfiability distribution have attracted a great deal of attention in the area of complexity theory and algorithms, especially since the connection with the nature of phase transitions in Physics is under investigation (see \"Determining computational complexity from characteristic ''phase transitions''\"in Nature, 1999, volume 400, pages 133-137).\r\n\r\nBased on AES (the successor of DES) I want to present a new generator (\"OKsolver\") for random CNF''s and discuss, why this generator is useful. A large database for these instances shall be built up to systematically explore the phenomenon of phase transitions (experimentally and numerically). Finally I will present a program how to use this database in order to get a general adaptive heuristics for a given SAT solvers A, resulting in a (hopefully) improved SAT solver A''. ',5,NULL);

INSERT INTO `seminar` VALUES (342,'2002-03-26','14:00','Robert Recorde Room','Ulrich Berger',NULL,'Swansea University',NULL,'While-programs are Turing-incomplete for non-strict oracles','We show that while-loops (or primitive recursion + unbounded search) form a less powerful programming concept than recursion when oracles accepting partially defined inputs are present. This implies that in a non-strict functional programming language while-programs cannot replace recursive programs with regard to the computation of functionals of type two.',5,NULL);

INSERT INTO `seminar` VALUES (343,'2002-05-16','14:00','Robert Recorde Room','Neal Harman',NULL,'Swansea University',NULL,'Correctness and Verification of Microprocessors',NULL,5,NULL);

INSERT INTO `seminar` VALUES (344,'2002-07-11','14:00','Robert Recorde Room','Ulrich Berger',NULL,'Swansea University',NULL,'A domain-theoretic realization of the classical axiom of countable choice','In JSL 63(2), Berardi, Bezem and Coquand proposed a realization PHI of the classical axiom of choice, that could be used to extract computational content from classical proofs. In order to prove correctness of PHI they introduced a rather ad-hoc and complicated notion of realizability based on an infinitary term system allowing to exploit PHI''s intensional behavior.\r\n\r\nIn the seminar I will give an alternative correctness proof in a purely extensional setting based on standard domain-theory, realizability and A-translation. I will concentrate on the technically somewhat simpler, but essentially equivalent problem of proving termination of the corresponding recursion.\r\n\r\nThe problem is illustrated by the following little story:\r\n\r\n********************************************************************\r\n\r\nHackers on trial\r\n\r\nA group of hackers, H_1, H_2, H_3, ... (infinitely many in fact), is accused of some offense.\r\n\r\nThe Professional Hacker''s Investigation bureau, PHI, employs a panel, Y, questioning the hackers and deciding on how to penalize them.\r\n\r\nOf course, the panel Y can only question finitely many hackers, but which and how many of them, will depend on the hackers'' answers.\r\n\r\nTogether with the accusation the PHI office has received a record r = [(k1,a1),...,(kn,an)] saying that hacker H_ki has already given answer xi (i=1,...,n).\r\n\r\nIt is possible that Y can make a judgment on the basis of the given record r alone. If not, Y needs to question some further hacker H_k (where k is different from all ki).\r\n\r\nH_k''s answer will, of course, be the result of a hack: She breaks into PHI''s computer system and sends faked requests to the PHI office for investigating the hackers with extended records of the form [(k1,x1),...,(kn,xn), (k,x)], where x is a possible answer. Based on PHI''s reactions to these requests for various x, H_k will finally decide to give some answer.\r\n\r\nOf course, also H_k can send only finitely many faked requests, but which and how many she will send will depend on PHI''s reactions.\r\n\r\nThe question is: Will this trial ever end?\r\n\r\nMathematically, the panel Y and the hackers H_k can be modeled as continuous functionals\r\n\r\nY : [N -> A] -> P\r\n\r\nH_k : [A -> P] -> A\r\n\r\nwhere N = {1,2,3,...}, A is the type of possible answers given by hackers, and P is the type of possible penalties. The trial can now be described by the following recursive definition of a function\r\n\r\nPHI : R -> P\r\n\r\nwhere R is the type of records, that is, R = (N x A)^*. The definition of PHI reads\r\n\r\nPHI [(k1,x1),...,(kn,xn)] =\r\n\r\nY ( lambda k if k = ki then xi else H_k ( lambda x PHI [(k1,x1),...,(kn,xn), (k,x)] ) endif )',5,NULL);

INSERT INTO `seminar` VALUES (345,'2002-11-07','14:00','Robert Recorde Room','Anton Setzer',NULL,'Swansea University',NULL,'Java as a functional programming language',NULL,5,NULL);

INSERT INTO `seminar` VALUES (346,'1999-12-09','15:00','Seminar Room 322','Neal Harman',NULL,'Swansea University',NULL,'Microprocessor Verification in Maude','Basic methods for algebraically representing microprocessors, and their correctness will be introduced. The resulting proof obligations can be substantially simplified if some easily-checked conditions hold. Example verifications of an abstract pipeline, and of a simple pipelined microprocessor have been undertaken using the equational language Maude, based on these simplifications. Maude will be introduced, and ongoing work on these and larger examples, and on reducing the level of manual direction required in proofs, will be discussed.',5,NULL);

INSERT INTO `seminar` VALUES (161,'2007-10-03','14:15','Board Room','Manfred Droste','http://www.informatik.uni-leipzig.de/~droste/','Universit&auml;t Leipzig','http://www.informatik.uni-leipzig.de/idxeng.html','Almost every domain is universal ','In classical results, Scott, Plotkin and others proved that\r\nvarious classes of domains contain universal objects,\r\ni.e. domains which contain any other domain of the given\r\nclass as a subdomain (up to isomorphism); such domains can\r\nbe used to provide models of the untyped \\lambda-calculus.\r\n\r\nWe will present an inductive probabilistic construction\r\nof bifinite domains and of Scott domains and show that\r\nwith probability 1 our construction produces a universal\r\nbifinite domain resp. universal Scott-domain which, moreover,\r\nhas a large degree of symmetry. We also develop similar\r\nprobabilistic constructions for prime event structures and\r\nfor causal sets. The latter have been used as basic models\r\nfor discrete space-time in quantum gravity.\r\n\r\nJoint work with Dietrich Kuske resp. Guo-Qiang Zhang.\r\n',2,'');

INSERT INTO `seminar` VALUES (347,'2007-11-13','14:00','Robert Recorde Room','Abi Sellen','','Microsoft Research','','Designing for Human Values in the Digital Age','What do we want from technology in the 21st century?  What is the vision that we want to buy into and aspire to as we move forward?  In this talk I will compare and contrast some of those visions, setting out the direction in which I believe Human-Computer Interaction should take us. I will start with Mark Weiser''s notion of \"calm computing\" (where computers are everywhere and yet nowhere) and set this against the proposition that we must engage with computers and express ourselves through them.  I will also contrast the idea of \"intelligent environments\" (where computers act on our behalf), with the idea that technology should act to augment and enrich human action and intelligence. Using examples from our group''s work, I will go on to show how we must put human values front and centre as we design and develop technology in order to fully explore the enormous potential of computing in the Digital Age.\r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (348,'2007-11-22','14:00','Robert Recorde Room','mc schraefel','http://users.ecs.soton.ac.uk/mc/','Southampton University, CS','http://www.ecs.soton.ac.uk/~ mc','Towards a \"Perfect\" Digital Assistant. Is a change in the personal computing paradigm in the offing?','In 1992, the \"personal digital assistant\" or PDA\r\nwas introduced, embodied as the first Apple\r\nNewton. A variety of PDA tools have followed from\r\nthe Palm to the increasingly ubiquitous smart\r\nphone, each bringing together a set of\r\napplications: calendar, note pad, to do''s and\r\naddress book - tools that work adequately well\r\nfor the narrow percentage of people who are\r\norganized, schedule things anyway and can\r\ntolerate filling in forms.\r\n\r\nThe precursor of the PDA was the more visionary\r\n1987 concept of the knowledge navigator: an\r\nimaginary Apple vision of what a PDA might be\r\nwhen it grew up: something that would actively\r\nblend awareness of personal and public data to\r\nprovide support for the human operator. It could,\r\nfor instance, present comparison of stats from\r\ndiscrete papers, handle phone calls in the\r\nbackground while other activities were taking\r\nplace in the foreground, such as preparing notes\r\nfor a class. While the current PDA is focused on\r\norganizational tools that require constant and\r\nmanual attention, the knowledge navigator was\r\nfocused on supportive, dynamic interaction based\r\non existing and new public and private\r\ninformation blending.\r\n\r\nRecently we''ve been looking at what it might take\r\nto bring the current state of information\r\nmanagement tools away from their manual\r\napplication/form filling capacity towards the\r\nvision of the knowledge navigator, or what we''ve\r\nbeen calling the \"perfect digital assistant.\"\r\n\r\nWe are exploring the first part of this process\r\ntowards the new PDA in a project called Jourknow\r\nbetween MIT and Southampton. Here, we''re\r\ninvestigating different desktop models for data\r\nrepresentation and storage. Fundamentally we have\r\nalso been looking at new ways to capture the\r\nstructure of information but in a form free way.\r\nWe have then been exploring how this information\r\ncan be enriched for retrieval by automatically\r\nassociating it with what we can know about the\r\ncontext of the information at the time of capture\r\n- what we were doing; who we might be with; where\r\nwe were; any applications/documents open. This\r\nproject has very much captured on improving\r\npersonal information management by improving\r\ncapture and retrieval contexts. While we hope the\r\napproach is better than current ap/form PIM\r\nmodels, it is not the knowledge navigator. The\r\nactive assistance component is missing.\r\n\r\nIn a new project, Idoru, we have just begun to\r\nlook at how we might blend public data sources\r\nlike rss feeds and other mine-able Web resources,\r\nwith ubiquitous sensor or data feeds, and these\r\nwith our personal data in order to begin to see\r\nhow this might be purposeable for active support:\r\nif our knowledge navigator is watching sources of\r\ndata for things we care about, and also knows our\r\nschedule, can it find a hole in our schedule to\r\nalert us to an opportunity for a new gallery\r\nopening for instance, and then book the tickets\r\non approval? Could it likewise, knowing we''ve\r\nbeen pulling all-nighters for a CHI deadline,\r\nrecommend something we should have for dinner to\r\nhelp replenish our health? We have developed an\r\nearly prototype, AtomsMasher, to explore how we\r\ncan push existing RSS technologies to support\r\nsuch interactions.\r\n\r\nIn this talk, i will go over the work informing\r\nthese projects and our findings to date, with an\r\neye towards exploring with you shared interests\r\nand possible collaborations towards a perfect\r\ndigital assistant.',1,'');

INSERT INTO `seminar` VALUES (350,'2003-06-05','15:00','Robert Recorde Room','Peter Aczel',NULL,NULL,'http://www-compsci.swan.ac.uk/~csetzer/logic-server/manchester.html','Nested Data Types in polymorphic type theory and dependent type theory','Nested Data Types were introduced in the context of functional proramming languages like Haskell. They have also been studied in the context of the impredicative polymorphic type theory, system F^omega. But they can also be represented in weak predicative dependent type theories. \r\n\r\nMy talk will introduce the topic with some of the standard examples, including the nested dtat type treatment of the de Bruijn approach to the syntax of the untyped lambda calculus. ',1,NULL);

INSERT INTO `seminar` VALUES (351,'2000-09-14','14:00','Robert Recorde Room','Ulrich Berger',NULL,'Swansea University',NULL,'On the computational content of the axiom of choice','This talk builds on a paper with the same title by S Berardi, M Bezem and T Coquand (Proceedings of TLCA''95, LNCS 902, 602-622, 1995). The following story tries to illustrate the problem. \r\n\r\nHarry Potter''s first Coursework at Hogwarts \r\n\r\nThe coursework is to get a jewel out of the schools treasure. Since Harry did not pay much attention to the lessons he does not know how to do this by magic, but instead has to use other information he collected when snooping around at Hogwarts. Harry found out that there is an infinite number of secret doors at Hogwarts, and that the Professors McGonagal, Dumbledore and Snape are able to do the following actions: If Professor McGonagal is given one after the other a key k1 for the first door, a key k2 for the second door, and so on, she will, after having received a finite number of keys k1, ..., kn, return a jewel. The number n may depend on the keys she got (there are many different keys for each door). \r\n\r\n\r\n\r\nIf Professor Dumbledore is given a number n and a method that produces from any key for the n-th door a jewel, then he will return a jewel. \r\n\r\n\r\n\r\nIf Professor Snape is given a jewel, then he will return for any number n a key for the n-th door. \r\n\r\n\r\n\r\nHow can Harry manage to get a jewel with the help of the three Professors? \r\n\r\nHint: use the magic of recursion and continuous higher-order operations. \r\n\r\nThe puzzle above contains the essence in the problem of finding computational content for the Classical Axiom of Choice. In the talk I will present a solution to this problem and discuss its possible impact to program synthesis from classical proofs.',1,NULL);

INSERT INTO `seminar` VALUES (352,'2002-03-26','14:00','Robert Recorde Room','Ulrich Berger',NULL,'Swansea University',NULL,'While-programs are Turing-incomplete for non-strict oracles','We show that while-loops (or primitive recursion + unbounded search) form a less powerful programming concept than recursion when oracles accepting partially defined inputs are present. This implies that in a non-strict functional programming language while-programs cannot replace recursive programs with regard to the computation of functionals of type two. ',1,NULL);

INSERT INTO `seminar` VALUES (353,'2002-07-11','14:00','Robert Recorde Room','Ulrich Berger',NULL,'Swansea University',NULL,'A domain-theoretic realization of the classical axiom of countable choice','In JSL 63(2), Berardi, Bezem and Coquand proposed a realization PHI of the classical axiom of choice, that could be used to extract computational content from classical proofs. In order to prove correctness of PHI they introduced a rather ad-hoc and complicated notion of realizability based on an infinitary term system allowing to exploit PHI''s intensional behavior. \r\n\r\nIn the seminar I will give an alternative correctness proof in a purely extensional setting based on standard domain-theory, realizability and A-translation. I will concentrate on the technically somewhat simpler, but essentially equivalent problem of proving termination of the corresponding recursion. \r\n\r\nThe problem is illustrated by the following little story: \r\n\r\n******************************************************************** \r\n\r\nHackers on trial \r\n\r\nA group of hackers, H_1, H_2, H_3, ... (infinitely many in fact), is accused of some offense. \r\n\r\nThe Professional Hacker''s Investigation bureau, PHI, employs a panel, Y, questioning the hackers and deciding on how to penalize them. \r\n\r\nOf course, the panel Y can only question finitely many hackers, but which and how many of them, will depend on the hackers'' answers. \r\n\r\nTogether with the accusation the PHI office has received a record r = [(k1,a1),...,(kn,an)] saying that hacker H_ki has already given answer xi (i=1,...,n). \r\n\r\nIt is possible that Y can make a judgment on the basis of the given record r alone. If not, Y needs to question some further hacker H_k (where k is different from all ki). \r\n\r\nH_k''s answer will, of course, be the result of a hack: She breaks into PHI''s computer system and sends faked requests to the PHI office for investigating the hackers with extended records of the form [(k1,x1),...,(kn,xn);

INSERT INTO `seminar` VALUES (k,x)], where x is a possible answer. Based on PHI''s reactions to these requests for various x, H_k will finally decide to give some answer. \r\n\r\nOf course, also H_k can send only finitely many faked requests, but which and how many she will send will depend on PHI''s reactions. \r\n\r\nThe question is: Will this trial ever end? \r\n\r\nMathematically, the panel Y and the hackers H_k can be modeled as continuous functionals \r\n\r\nY : [N -> A] -> P \r\n\r\nH_k : [A -> P] -> A \r\n\r\nwhere N = {1,2,3,...}, A is the type of possible answers given by hackers, and P is the type of possible penalties. The trial can now be described by the following recursive definition of a function \r\n\r\nPHI : R -> P \r\n\r\nwhere R is the type of records, that is, R = (N x A)^*. The definition of PHI reads \r\n\r\nPHI [(k1,x1),...,(kn,xn)] = \r\n\r\nY ( lambda k if k = ki then xi else H_k ( lambda x PHI [(k1,x1),...,(kn,xn);

INSERT INTO `seminar` VALUES (k,x)] ) endif )',1,NULL);

INSERT INTO `seminar` VALUES (354,'2003-06-25','12:00','Robert Recorde Room','Matthew Collinson',NULL,'Manchester University',NULL,'Transition Structures and Topologies','I will discuss a number of ways of combining transition structures with topologies. These lead to a family of duality results in the style of point-free topology (locale theory). As a consequence soundness and completeness for certain versions of propositional intuitionistic logic with modal operators are implicit. ',1,NULL);

INSERT INTO `seminar` VALUES (355,'2003-07-01','14:00','Robert Recorde Room','Lyndon Drake',NULL,'York University',NULL,'Inference and search for the propositional satisfiability problem','Propositional satisfiability (SAT) is the archetypal NP-complete problem, with important practical applications. Backtracking search is the most effective way of solving many SAT problems. It is sometimes possible to improve the performance of search-based SAT solvers by using inference methods. I will present an overview of existing methods, such as unit propagation and conflict recording, as well as my own work over the course of my PhD. ',1,NULL);

INSERT INTO `seminar` VALUES (356,'2003-05-27','14:00','Robert Recorde Room','Alan Frisch',NULL,'York University',NULL,'Solving Non-Boolean Satisfiability Problems','State-of-the-art procedures for determining the satisfiability of formulas of Boolean logic have developed to the point where they can solve problem instances that are large enough to be of practical importance. Many of the problems on which satisfiability procedures have been effective are non-Boolean in that they are most naturally formulated in terms of variables with domain sizes greater than two. Boolean satisfiability procedures have been applied to these non-Boolean problems by reformulating the problem with Boolean variables. An alternative, previously unexplored approach, is to generalise satisfiability procedures to handle non-Boolean formulas directly. This talk compares these two approaches. \r\n\r\nWe begin by presenting two procedures that we have developed for solving non-Boolean formulas directly. We also present three methods for systematically transforming non-Boolean formulas to Boolean formulas. Finally, experimental results are reported on using all these methods to solve random formulas, graph colouring problems and planning problems. ',1,NULL);

INSERT INTO `seminar` VALUES (357,'2003-05-08','14:00','Robert Recorde Room','Erich Grädel',NULL,'Aachen',NULL,'Model checking games','Model checking problems (\"is a given formula true in a given structure?\") for almost every logic can be cast as strategy problems (\"which player does have a winning strategy in a given game?\") for the appropriate evaluation games (also called Hintikka games). \r\n\r\nIn games for first-order logic, all plays are finite and the strategy problem can be solved in linear time in the size of the game graph. For fixed point logics, the appropriate evaluation games are parity games, which admit also infinite plays. Each position is assigned a priority, and the winner of an infinite play is determined according to whether the least priority seen infinitely often during the play is even or odd. \r\n\r\nInfinite games are also important for other applications. They model in a natural way the non-terminating interaction of a reactive system with its environment: the specification of a reactive system can be seen as a winning condition in a game, and a reactive program that fulfills the specification implements a winning strategy. Parity games are especially interesting because on one side, they are powerful enough to simulate large classes of games and, on the other side they admit positional winning strategies. \r\n\r\nAn polynomial time algorithm for computing winning sets and winning strategies of parity game would also provide a solution for the model checking problem for the modal mu-calculus, and vice versa. While we do not know whether this is possible in general, we can analyze the structure of parity games and isolate `easy'' cases that admit efficient solutions. We link these `easy games'' to logic and thus obtain efficient model checking algorithms for fragments of fixed point logic. ',1,NULL);

INSERT INTO `seminar` VALUES (358,'2003-05-29','14:00','Robert Recorde Room','Peter Hancock',NULL,'Edinburgh University',NULL,'Interfaces, components, formal spaces and continuous functions','Quite a bit of programming consists in implementing high-level procedural interfaces in terms of low-level interfaces. One approach to modelling this is with a category in which the objects are interfaces, and the morphisms are components.\r\n\r\nIn collaboration with Pierre Hyvernat and Anton Setzer, I have succeeded in ironing some wrinkles out of such a model. Unexpectedly, the category turns out to be (the opposite of) a category of generalised formal topologies and continuous functions figured out by Giovanni Sambin and others at Padua. Components are continuous functions. \r\n\r\nSo as not to paint too rosy a picture, I shall indicate some of the problems that arise when one confronts such a model with component-based architectures that arise in practice. ',1,NULL);

INSERT INTO `seminar` VALUES (359,'2003-05-06','14:00','Robert Recorde Room','Harold Simmons',NULL,'Manchester University',NULL,'Forms of Recursion','Recursion theory as currently understood is concerned with the analysis of Turing degrees. In this topic any two Turing computable functions are deemed to be equivalent. However, there is an earlier, less expensive, set of material which is concerned with recursion and is in danger of being forgotten. \r\n\r\nSome of the better know forms of recursion go by the names `Primitive recursion'', `Course of value recursion'', `Tail recursion'', and the like. These are all concerned with converting given natural number functions into natural number functions. However, there are many other kinds of recursion, not all concerned with natural number functions, and some concerned with higher order functions. \r\n\r\nIn this talk I will try to put these method into a general setting, and suggest ways that this material could be turned into at least one course that could be taught at a postgraduate level (and perhaps earlier). \r\n\r\nSome jokes, both pc and non-pc, may be included, but CZJ will not be mentioned. ',1,NULL);

INSERT INTO `seminar` VALUES (360,'2003-05-07','14:00','Robert Recorde Room','Harold Simmons',NULL,'Manchester University',NULL,'Notations for Iterations (Panzerdivision proof theory done properly)','Some of you may have seen some of the topic of `ordinal notations'' and been impressed, or perhaps not. The standard approach to this topics obscures a lot of what is going on, and often misses the point. In fact, it is about the nesting of iterations and how complicated thees can become. \r\n\r\nIn this talk I will explain some of the background from the stand point of iterations. I will then go on to describe an applied lambda-calculus with explication notations for these gadgets. Finally, I will indicate how these notations are related to the standard Bachmann notations.\r\n\r\nThe first part of the talk should be understandable without a knowledge of ordinals.',1,NULL);

INSERT INTO `seminar` VALUES (361,'2003-06-03','14:00','Robert Recorde Room','Andrew Simpson',NULL,'Oxford University',NULL,'eDiaMoND: towards a national database for digital mammograms','One in eight women in the western world will get breast cancer at some stage of their lives. The earlier the diagnosis, the better the prognosis: this is the basis of the breast screening process. In this talk I will describe work being undertaken by the University of Oxford and IBM to deliver a protoype solution for a national database to support this process.',1,NULL);

INSERT INTO `seminar` VALUES (362,'2003-07-15','14:00','Robert Recorde Room','Dieter Spreen',NULL,'Siegen',NULL,'The Largest Cartesian Closed Category of Domains, Considered Constructively','A conjecture of Smyth is discussed which says that if $D$ and $[D \\rightarrow D]$ are effectively algebraic directed-complete partial orders with least element (cpo''s), then $D$ is an effectively strongly algebraic cpo, where it was not made precise what is meant by an effectively algebraic and an effectively strongly algebraic cpo. \r\n\r\nNotions of an effectively strongly algebraic cpo and an effective SFP domain are introduced and shown to be (effectively) equivalent. Moreover, the conjecture is shown to hold if instead of being effectively algebraic, $[D \\rightarrow D]$ is only required to be $\\omega$-algebraic and $D$ is forced to have a completeness test, that is a procedure which decides for any two finite sets $X$ and $Y$ of compact cpo elements whether $X$ is a complete set of upper bounds of $Y$. As a consequence, the category of effective SFP objects and continuous maps turns out to be the largest Cartesian closed full subcategory of the category of $\\omega$-algebraic cpo''s that have a completeness test. \r\n\r\nIt is then studied whether such a result also holds in a constructive framework, where one considers categories with constructive domains as objects, that is, domains consisting only of the constructive (computable) elements of an indexed $\\omega$-algebraic cpo, and computable maps as morphisms. This is indeed the case: the category of constructive SFP domains is the largest constructively Cartesian closed weakly indexed effectively full subcategory of the category of constructive domains that have a completeness test and satisfy a further effectivity requirement. ',1,NULL);

INSERT INTO `seminar` VALUES (363,'2003-05-20','14:00','Robert Recorde Room','Harold Thimbleby',NULL,'University College London Interaction Centre (UCLIC)','http://www.uclic.ucl.ac.uk/','Surviving culture clash!','Computing technology is supposed to be magic and do all things well. Secretly, though, we admit our programs don''t work and we can''t use even ''simple'' systems easily. This seminar will discuss two symtoms of this: the broken programs described in the programming literature, and the low usability of consumer products, which run these broken programs. The seminar will then introduce two new tools to solve all known problems: yes, computers are magic!\r\n\r\nThe tools will be of interest to people who like Java, XML, TeX and Mathematica, and who hate user interfaces. But no prior knowledge of such systems will be needed.\r\n\r\nHarold Thimbleby is Director of UCLIC, the UCL Interaction Centre. He is also Gresham Professor of Geometry and a Royal Society-Wolfson research merit award holder.',1,NULL);

INSERT INTO `seminar` VALUES (364,'2003-06-24','14:00','Robert Recorde Room','Toby Walsh','http://4c.ucc.ie/~tw/personal.html','Cork, Ireland','http://www-compsci.swan.ac.uk/~csetzer/logic-server/cork.html','Local consistencies in SAT','Propositional satisfiability (SAT) and constraint satisfaction problems (CSPs) are closely related NP-complete problems. In this talk, I explore some of these connections. I show how a wide variety of inference methods (so called \"local consistencies\") in CSPs can be simulated by unit propagation, the basic inference method in SAT. Technology developed for SAT solving can therefore be readily used to solve CSPs. Joint work with Emmanuel Hebrard and Brahim Hnich (4C, Cork, Ireland) and Christian Bessiere (LIRMM, Montpelier, France). ',1,NULL);

INSERT INTO `seminar` VALUES (365,'2007-10-18','14:00','Robert Record Room','Petter Kristian Kober','http://www.uio.no/sok?person=petterk','Swansea (on leave from Oslo)','','Definitions by positive induction in a category of domain representable spaces','The topological spaces which admit ?-admissible domain representations have\r\nbeen characterised as the qcb_0 spaces (i.e. T_0 quotients of countably\r\nbased spaces), and this forms a cartesian closed category with\r\n(sequentially) continuous functions as morphisms. An algebraic domain is\r\ndefined by positive induction if it is the canonical solution of a\r\nrecursive domain equation which does not directly involve functions defined\r\non the space itself.\r\n\r\nIn this talk, we ask whether qcb_0 spaces admit definitions by positive\r\ninduction, and explain why it is a both natural and adequate choice to\r\nconsider domains with dense and local partial equivalence relations in\r\norder to find a solution. We show that strictly positive operators on qcb_0\r\nspaces have canonical fixed points, using the intuition of a fundamental\r\nexample. We briefly discuss why it seems reasonable to restrict ourselves\r\nto Hausdorff spaces when searching for fixed points of general positive\r\noperators.\r\n',2,'');

INSERT INTO `seminar` VALUES (366,'2007-10-23','14:00','Robert Recorde Room','Chris Tofts','','HPLB','','Exploiting strong attractors to slaughter monsters - Taming 10^(1500) states and beyond','The `holy grail'' of automated state based model checking is to build precisely the states needed to validate a property and no more. In this paper I present a natural filter on automata which exploits the nature of the design of concurrent systems to order the state construction. I demonstrate that this can provide a sequence of approximating models which permit us to both address infinite systems and large finite systems (a 500 component 10^(1500) state system being effectively modelled). The models are optimal, in the number of states used, for the parameters (state occupancy probabilities and consequent rewards) they attempt to approximate. The filter on the states we deduce is an interesting variant on the near decomposable class of systems presented by Simon and Ando (1961), but one where the small value terms do not necessarily dominate the long run behaviour. The semantic nature of the decomposition avoids the need to instantiate any values, or introduce arbitrary numerical bounds during the automata construction, enabling us to derive bounds on permitted behaviour without an expensive rebuild of the automata. Whilst the main focus of the work is the evaluation of properties of probabilistic systems, probabilities are not required for the construction, consequently the approach can be exploited for qualitative arguments of system correctness. Seven examples of layering of various systems are presented. One of the most powerful properties of the approach is - that it is reasonable to argue that either the approximation technique works, or the system is inherently badly designed.',1,'');

INSERT INTO `seminar` VALUES (367,'2007-11-27','14:00','Robert Recorde Room','Paul Rosin','','Cardiff University','','Some Measures for Shape Analysis','Shape is an important aspect of biological vision and computer\r\nvision. In particular, global shape measures are a convenient way to describe regions. They are generally simple and efficient to extract, easily interpreted by humans, and provide an easy means for high level tasks such as classification as well as helping direct low-level computer vision processes such as segmentation.\r\nThis talk discusses a variety of global shape measures recently developed for computer vision, and also mentions in passing some related perceptual aspects of shape.',1,'');

INSERT INTO `seminar` VALUES (369,'2007-10-30','14:00','Robert Recorde Room','Georg Struth','http://www.dcs.shef.ac.uk/~georg/','The University of Sheffield','http://www.shef.ac.uk/dcs/','Modal Kleene Algebras: Foundations, Models, Automation','Kleene algebras are fundamental structures in computing.\r\nApplications range from formal language theory to program\r\nanalysis and verification, concurrency control and the design of\r\nalgorithms. This talk surveys recent extensions of Kleene algebras by\r\nmodal operators. It sketches the axiomatisation and calculus of modal\r\nKleene algebras, some interesting models, such as traces, graphs,\r\nrelations and predicate transformers, and their connection with\r\nBoolean algebras with operators, propositional dynamic logics and\r\ntemporal logics. A particular benefit of the algebraic approach is\r\nthat some complex analysis tasks that previously required higher-order\r\nreasoning can, for the first time, be fully automated through\r\nequational reasoning with off-the-shelf theorem provers. This is\r\nillustrated through several examples: program analysis in Hoare logic,\r\nBachmair and Dershowitz''s termination theorem for rewrite systems,\r\nBack''s atomicity refinement theorem and a correspondence proof\r\nof Loeb''s formula in modal/provability logic.\r\n',1,'');

INSERT INTO `seminar` VALUES (349,'2007-12-04','14:00','Robert Recorde Room','Xianghua Xie','','Swansea University, CS','http://cs.swan.ac.uk/','Active Contouring','Deformable contour models or snakes are commonly used in image\r\nprocessing and computer vision due to their natural handling of shape\r\nvariation and independence of operation (once initialised). Although\r\nsignificant improvements have been made in this field over the last\r\ndecade, there are still great challenges in handling weak edges, image\r\nnoise, and complex topologies and geometries which often occur in\r\nreal world images.\r\nIn this talk, we will examine the three fundamental issues in designing\r\nan active contour model, namely contour representation and its\r\nnumerical solution, object boundary description and stopping function\r\ndesign, and initialisation and convergence. The speaker will show how\r\nwe can enhance the performance of active contour models, such as\r\nhandling weak edges and improving initialisation invariancy, through\r\ndesigning novel external force field. A novel contour representation\r\nmethod which transfers difficult PDE problem to simpler ODE problem\r\nwill also be presented. More sophisticated topological changes are now\r\nreadily achievable. A couple of applications to medical image analysis\r\nof the active contours will be briefly discussed as well.',1,'');

INSERT INTO `seminar` VALUES (368,'2007-12-06','14:00','Board Room','Annelies Gerber','','Swansea','','Towards Geometrical Models of Proof Systems and Hidden Resolution Proofs','It may be of interest to characterise certain information from logic\r\ngeometrically. Any geometrical model of proofs for instance has to be\r\nable to deal with their non-deterministic behaviour.  Mathematical\r\nstructures such as Boolean algebras can reflect certain properties of\r\npropositional logic.  Apart from finding geometries that deal with\r\nnon-deterministic behaviour another aim of this research is to find\r\nanalogies between existing structures from mathematics or physics and\r\nstructures from logic.  All mathematical models of proofs need to\r\nreflect the complexity of the corresponding proofs.\r\n\r\nWe present some first examples of analogies based on Euclidean\r\ngeometry for certain input resolution proofs. We also discuss \r\nhow unit resolution proofs can be viewed as particular sequences \r\nof completely inelastic particle collisions.\r\n',2,'');

INSERT INTO `seminar` VALUES (370,'2008-02-12','14:00','Robert Recorde Room','Paul Curzon','','Queen Mary University','','Serious Fun in Computer Science','\r\nComputer Science has been in crisis for several years with interest in\r\nstudying it having dropped dramatically. Our solution has been to show\r\nhow much fun it is based on leading-edge research presented in offbeat\r\nways. This is more effective than selling ourselves directly. Computer\r\nScience is after all a naturally exciting, innovative and\r\nthought-provoking subject. cs4fn (www.cs4fn.org), a website and magazine\r\nthat we''ve been writing for the sheer enjoyment of it, is a key part of\r\nthe solution that can help everyone. It is now funded by an EPSRC PPE\r\naward. We also do Computer Science  Research \"shows\" for kids, including\r\na Magic Show and an AI show that involves building a working brain out\r\nof rope and toilet roll.\r\n\r\nOur approach works: teachers are positive (eg \"This has to be THE most\r\ninspired bit of literature/content for getting youngsters switched onto\r\nComputer Science!\") as are industry, and the International Review of ICT\r\ncommended us ... and we have seen an increase in undergraduate\r\napplications of over 130% in 2 years.\r\n\r\nIn this talk we will demonstrate some of the live activities we do, show\r\nhow some have translated to online activities and discuss some of the\r\nissues in making sure Computer Science is fun as well as serious.\r\n',1,'');

INSERT INTO `seminar` VALUES (372,'2008-04-29','14:00','Robert Recorde Room','Tim Unwin','','Royal Holloway','http://www.gg.rhul.ac.uk/Tim/','The 4 in ICT4D: making computer science relevant in a development context','Tim Unwin (born 1955) is UNESCO Chair in ICT4D and Professor of Geography at Royal Holloway, University of London. From 2001-2004 he led the UK Prime Minister''s Imfundo: Partnership for IT in Education initiative based within the Department for International Development, and he is currently Senior Advisor to the World Economic Forum''s Partnerships for Education initiative with UNESCO, a High Level Advisor for the UN''s Global Alliance for ICT and Development, and President of the Advisory Board of Eduvision. He was previously Head of the Department of Geography at Royal Holloway, University of London between 1999 and 2001, and has also served as Honorary Secretary of the Royal Geographical Society (with The Institute of British Geographers) (1995-1997). He has written or edited 13 books, and over 170 papers and other publications, including \"Wine and the Vine\" (Routledge, 1991; translated into three languages), \"The Place of Geography\" (Longman, 1992), as well as his edited \"Atlas of World Development\" (Wiley, 1994) and \"A European Geography\" (Longman, 1998). His research has taken him to more than 25 countries across the world, from Sénégal to Singapore, and Estonia to Ethiopia, and he has worked on subjects as diverse as the role of banknotes as expressions of national identity, and the educational needs of out of school youth in the Philippines. His recent research has concentrated especially on ICT4D, focusing on its use in the context of teacher training in Africa, on a critique of budget support mechanisms in international aid, and on the use of partnerships in ICT4D practice. He has recently completed a collaborative book on ICT4D to be published by Cambridge University Press in 2008. The UK''s Secretary of State for International Development appointed him as a Commonwealth Scholarship Commissioner in 2004; he also serves as Academic Advisor and External Examiner of the Institute of Masters of Wine. He is a frequently invited keynote speaker, facilitator and moderator at high level international meetings, including the World Economic Forum''s annual meetings in Davos, UNESCO round tables, WSIS follow-up meetings (such as the ICT 4 All Tunis + 2 Forum in Tunisia in 2007), Online Educa, e-Learning Africa, and bilateral donor events (such as BMZ''s Capacity Development Forum in 2008)',1,'');

INSERT INTO `seminar` VALUES (373,'2008-05-06','14:00','Robert Recorde Room','Roy Davies','','Royal Holloway','','Fast visual search: from inspection to guidance and surveillance','This talk considers a range of vision problems that can best be summed up \r\nas "fast visual search". After airing what the human eye can and can''t achieve, \r\nthe talk looks at the problems of real-time inspection of products on product \r\nlines, and considers the location of insects in batches of cereal grain. It also \r\nanalyses how the grains themselves can be located at the fastest possible rates \r\nby judicious sampling of the input images. The idea is extended to general \r\nlocation of any objects, and a parallel is drawn with the sampling technique \r\nemployed by the human visual system (HVS). This inspiration is taken further, \r\nin a vehicle guidance application, with the aim of locating pedestrians before \r\naccidents can occur. It is usual for 3D scene analysis to proceed via the \r\nidentification of salient features in the image, but there is some doubt whether \r\nthis is necessary. Further work employing a ''form + motion channel'' model to \r\nthe vision system, similar to that hardwired in the HVS, also suggests that \r\nsalient features may not be so necessary, and an integrated theory of guided \r\nsampling will be discussed.',1,'');

INSERT INTO `seminar` VALUES (375,'2008-04-22','14:00','Robert Recorde Room','Kenton OHara','','HP Labs','','Beyond in situ consumption of a location-based experience: exploring everyday practices of geocaching','Geocaching is a location-based activity that has been\r\npracticed for a number of years. As a sustained and established activity\r\nit represents an important opportunity for understanding everyday\r\npractices and motivations that can build up around a location-based\r\nactivity. I present findings from a field study of everyday geocaching\r\nbehaviour. In contrast to previous work, the presented research will\r\ntake a broad perspective on the activity focusing beyond the in situ\r\n/consumption/ of these experiences. It looks, too, at the practices and\r\nmotivations surrounding participants /creation/ of these experiences.\r\nFurther, I will examine these behaviours within the social context of\r\nthe on-line community that provides a significant basis for many of\r\nthese behaviours. In light of the findings I will go on to discuss some\r\nof the broader implications for location-based experiences.',1,'');

INSERT INTO `seminar` VALUES (378,'2008-02-19','14:00','Robert Recorde Room','Yorick Wilks','http://www.dcs.shef.ac.uk/~yorick/','University of Sheffield','http://www.shef.ac.uk/','The Semantic Web as the apotheosis of annotation, but what are its semantics?','The paper discusses what kind of entity the proposed Semantic Web (SW) is, and\r\ndoes so principally by reference to the relationship of natural language\r\nstructure to knowledge representation (KR). It argues that there are three\r\ndistinct views on the issue: first, that the SW is basically a renaming of the\r\ntraditional AI knowledge representation task, with all its problems and\r\nchallenges. If that is the case, as some believe, then there is no particular\r\nreason to expect progress in any new form of presentation of this issue, as\r\nall the traditional problems of logic and representation will reappear, ones\r\nthat have resisted definitive solutions within AI for fifty years. That route\r\nwill be no more successful outside the narrow scientific domains where KR\r\nseems to work, even though the formal ontology movement has undoubtedly\r\nbrought benefits. The paper contains some discussion of the relationship of\r\ncurrent SW doctrine to representation issues covered by traditional AI, and\r\nalso discusses the issues of how far SW proposals are able to deal with\r\ndifficult semantic relationships in some well-defined areas of e-science.\r\n\r\n\r\nSecondly, there is a view that the SW will be, at a minimum, the WorldWideWeb\r\n(WWW) with its constituent documents annotated so as to yield their content,\r\nor meaning structure, more directly. This view of the SW makes natural\r\nlanguage processing central as the procedural bridge from texts to KR, usually\r\nvia some form of automated Information Extraction. This view is discussed in\r\nsome detail and it is argued that this can also be seen as a way of justifying\r\nthe structures used as KR for the SW. There is a third view, possibly\r\nBerners-Lee''s own, that the SW is about trusted databases as the foundation of\r\na system of web processes and services, but it is argued that this ignores the\r\nwhole history of the web as a textual system, and gives no better guarantee of\r\nagreed meanings for terms than the other two approaches. There is also a\r\nfourth view, much harder to define and discuss, which is that if the SW just\r\nkeeps moving as an engineering development and is lucky (as the successful\r\nscale-up of the WWW seems to have been luckier, or better designed, than many\r\ncynics expected) then real problems will not arise. This view is a hunch and\r\nnot open to close analysis but one can only wish it well, as it were, without\r\nbeing able to discuss it in detail further at this stage. In this paper we\r\nwill concentrate on the first three approaches, their problems and their\r\npossible solutions.',1,'');

INSERT INTO `seminar` VALUES (379,'2008-03-13','14:00','Robert Recorde Room','Zhaohui Luo','http://www.cs.rhul.ac.uk/~zhaohui/','Royal Holloway, University of London','http://www.rhul.ac.uk/','Type theory and its applications','Dependent type theory provides a powerful logical calculus for formalisation of mathematics and verification of programs. I shall present two applications of type theory based proof assistants, one on the formalisation of Weyl''s predicative mathematics and the other on the modelling and verification of object-oriented programs.',1,'');

INSERT INTO `seminar` VALUES (380,'2008-03-04','14:00','Robert Recorde Room','Richard Taylor, Chris Tofts','','Hewlett Packard Laboratories Bristol','','Do Services need Science? Are there any hard problems?','Services, or non-productive labour, have become nearly 80% of economic activity. Although service activities are now dominant, there appears to be very little understanding of how they should be designed, delivered and optimised. Public service systems that rely heavily on IT have a well documented record of costly failure in delivery, expectation or unintended consequences. In many respects this should be unsurprising as it is human components that usually underpin these systems. The totality of a service system is one of the most complicated conceived by humans, formed from the interaction of computing and communications hardware, deep software stacks and human operators. To make things worse from a corporate perspective services have proved remarkably resistant to delivering the same kind of productivity improvements which manufacturing has seen in the last 50 years.\r\n\r\nAs IT based services now represent about 10% of high value services, it is not surprising that there is a great deal of interest in achieving the efficiency gains shown by manufacturing. As a consequence of this <a href=\"http://www.research.ibm.com/ssme\">IBM</a> and <a href=\"http://www.services-sciences.org\">HP</a> along with BT have research and development activities in the area. The Communications of the ACM dedicated its July 2006 issue to Services Sciences, and the Cambridge Institute for Management recently held a meeting on <a href=\"http://www.ifm.eng.cam.ac.uk/ssme\"> \"Succeeding through Service Innovation\"</a> along with the emergence of a knowledge sharing network for the activity within <a href=\"http://www.ssmenetuk.org\">UK universities</a>.\r\n\r\nShould we leave the provision of \"good\" services to the dead hand of economics via the market and penalty clauses - or the blind eyes of the law through contract clauses and the courts? Or should we develop understanding which permits all of the parties in a service system to understand the value they obtain and deliver.',1,'');

INSERT INTO `seminar` VALUES (381,'2008-05-13','14:00','Robert Recorde Room','Glynn Winskel','http://www.cl.cam.ac.uk/~gw104/','University of Cambridge','http://www.cam.ac.uk/','Symmetry and Concurrency ','TBA',1,'');

INSERT INTO `seminar` VALUES (382,'2008-05-13','16:00','Robert Recorde Room','Glynn Winskel','http://www.cl.cam.ac.uk/~gw104/','University of Cambridge','http://www.cam.ac.uk/','Symmetry and Concurrency, Part II','TBA',3,'');

INSERT INTO `seminar` VALUES (383,'2008-02-14','14:00','Board Room','Faron Moller','','Swansea','','Games for Model-checking','',2,'');

INSERT INTO `seminar` VALUES (384,'2008-03-06','14:00','Robert Recorde Room','Klaus T Aehlig','','Swansea','','Hauptseminar \"Theory of Computation\": IP = PSPACE, part 1','Dexter Kozen: \"Theory of Computation\"\r\nLecture 15 and 16 ',2,'');

INSERT INTO `seminar` VALUES (376,'2008-02-28','14:00','Board Room','Arnold Beckmann','','Swansea','','On the complexity of parity games','',2,'');

INSERT INTO `seminar` VALUES (504,'2010-11-09','14:00','Robert Recorde Room','Edwin Beggs','','Swansea (Maths)','','Combining algorithms and physical systems','   I will explain what a physical oracle is, and how it is used. After a look at what sort of experiments might constitute a physical oracle, I will look at the theory of such devices. This comes in two parts:\r\n1) How a physical oracle can boost the computational power of a Turing machine.\r\n2) How computation places a limit on the experimental method.\r\nI will end by talking about some areas of current research; measurable numbers, axiomatising physical oracles, and a conjecture on physically aided computation.\r\n',1,'');

INSERT INTO `seminar` VALUES (385,'2008-04-01','14:00','Robert Recorde Room','Christian Urban','http://www4.in.tum.de/~urbanc/','TU M&uuml;nchen','http://portal.mytum.de/welcome','Nominal Techniques in the Theorem Prover Isabelle or, How\r\nNot to be Intimidated by the Variable Convention','Dealing with binders, renaming of bound variables, capture-avoiding\r\nsubstitution, etc., is very often a major problem in formal proofs,\r\nespecially in proofs by induction. In informal proofs by induction\r\none often assumes a variable convention in order to sidestep all\r\nproblems and to obtain simple proofs. Unfortunately, this convention\r\nis usually not formally justified, which makes it hard to formalise\r\nsuch proofs. In this talk I will show how strong induction principles\r\ncan be formally derived that have the variable convention already\r\nbuilt in. I will also show that the variable convention depends on\r\nsome non-trivial conditions in order to be a sound reasoning principle.\r\nThe aim of this work is to provide all proving technology necessary\r\nfor reasoning conveniently about the lambda-calculus and programming\r\nlanguages.\r\n',2,'http://www4.in.tum.de/~urbanc/picture-small.jpg');

INSERT INTO `seminar` VALUES (387,'2008-03-13','14:00','Robert Recorde Room (Talk in Colloquium)','Zhaohui Luo','','Royal Holloway, University of London','','Type theory and its applications','',2,'');

INSERT INTO `seminar` VALUES (388,'2008-04-24','14:00','Robert Recorde Room','Klaus T Aehlig','','Swansea','','Hauptseminar \"Theory of Computation\": IP = PSPACE, part 2','Dexter Kozen \"Theory of Computation\"\r\nLecture 17',2,'');

INSERT INTO `seminar` VALUES (389,'2008-05-01','14:00','Robert Recorde Room','Petter Kristian Kober','','Swansea','','Hauptseminar \"Theory of Computation\":  Complexity of Decidable Theories','Dexter Kozen \"Theory of Computation\"\r\nLecture 21',2,'');

INSERT INTO `seminar` VALUES (371,'2008-04-15','14:00','Robert Recorde Room',' Boriana Koleva','','Nottingham University','http://www.mrl.nott.ac.uk/','Interfaces for Public Spaces','A growing focus for HCI research has been the development of interactive technologies for public spaces such as galleries, museums, stations, shopping malls and city streets. This talk presents work in the development of interfaces for public settings and discusses the emerging design challenges in this area. \r\n\r\nThe talk begins by describing two interfaces that have been deployed in a museum: the Augurscope, a mobile outdoors interface that enables visitors to view 3D historical reconstructions when exploring present day sites, and the Storytent, an interface in the form of an A-frame tent, where two projectors throw different but synchronised images onto its surface while surrounding speakers play sounds. \r\n\r\nThis is followed by presenting ongoing work that focuses on exploring how best to integrate mobile devices with public situated installations to enable users to engage in a series of activities as part of a coherent experience, and exploring unobtrusive vision techniques to classify visitor behaviour around situated displays in order to dynamically configure the content shown on displays and the available interaction techniques. \r\n\r\nThe talk concludes by reflecting on the additional challenges that have to be addressed when developing interfaces for public settings. Issues include designing the physical form factor, allowing learnability-at-a-distance, providing different means of engagement, encouraging collaboration and managing the overall experience.  \r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (377,'2008-04-17','14:00','Robert Recorde Room','John Crossley','','Monash University','','Double Decker Logic','Each country has its own language yet we hear and read reports about other countries. Likewise, agents working in different domains sometimes need to communicate global information. For example, if we want to buy a house in Spain then our agent needs to know the local information from the agent there, but in terms we can understand.\r\n\r\nThis talk, based on work with my student Lito Cruz, describes a double-decker system comprising two tiers. Each domain in tier zero has its own language but information about different domains can be exchanged in tier one, one level up. In the example I give, the logic for the lower tier is predicate logic while that of tier one is propositional. However, the technique can be used for different combinations of logics, even having different logics in different domains in tier zero.\r\n\r\nConsistency and completeness results will be sketched. A basic implementation has been done by Lito. ',2,'');

INSERT INTO `seminar` VALUES (391,'2008-05-15','14:00','Robert Recorde Room','Dieter Spreen','','Siegen (visiting Swansea)','','Effectivity and effective continuity of multifunctions ','Multifunctions are used with great success in analysis and logic. In the talk different effectivity notions for such functions are discussed as well as effective versions of various continuity notions proposed in the literature. A general result on the effective continuity of effective multifunctions is presented and some important special cases are discussed. ',2,'');

INSERT INTO `seminar` VALUES (390,'2008-05-08','14:00','Robert Recorde Room','Jose Felix Costa','http://fgc.math.ist.utl.pt/jfc.htm','Lisboa (visiting Swansea)','','A Foundation for Real Recursive Function Theory ','The class of recursive functions over the reals, denoted by REC(R), was                                                                                        \r\nintroduced by Cristopher Moore in his seminal paper written in 1995. Since                                                                                     \r\nthen many subsequent investigations brought new results: the class REC(R)                                                                                      \r\nwas put in relation with the class of functions generated by the General                                                                                       \r\nPurpose Analog Computer of Claude Shannon; classical digital computation was                                                                                   \r\nembedded in several ways into the new model of computation; restrictions of                                                                                    \r\nREC(R) where seen to represent different classes of recursive functions, e.g.,                                                                                 \r\nrecursive, primitive recursive and elementary functions, and structures such                                                                                   \r\nas the Ritchie and the Grzergorczyk hierarchies. The class of real recursive                                                                                   \r\nfunctions was then stratified in a natural way, and REC(R) and the analytic                                                                                    \r\nhierarchy were recently recognized as two faces of the same mathematical                                                                                       \r\nconcept.                                                                                                                                                       \r\n                                                                                                                                                               \r\nIn this new seminar, we bring a strong foundational support to the Real                                                                                        \r\nRecursive Function Theory, rooted in Mathematical Analysis, in a way that                                                                                      \r\nthe reader can easily recognize both its intrinsic mathematical beauty and                                                                                     \r\nits extreme simplicity. The new paradigm is now robust and smooth enough to                                                                                    \r\nbe taught. To achieve such a result some concepts had to change and some new                                                                                   \r\nresults were added.                                                                                                                                            \r\n                                                                                                                                                               \r\n                                                                                                                                                               \r\n(Joint work with Bruno Loff and Jerzy Mycka.)                                                                                                                  \r\n                                                 ',2,'');

INSERT INTO `seminar` VALUES (392,'2008-05-20','14:00','Robert Recorde Room','Peter D Mosses (joint work with Mark New) ','','Swansea','','Implicit Propagation in Structural Operational Semantics ','In contrast to a transition system specification in process algebra,\r\na structural operational semantics (SOS) of a programming language\r\nusually involves auxiliary entities: stores, environments, etc.\r\nWhen specifying  SOS rules, particular auxiliary entities often\r\nneed to be propagated unchanged between premises and conclusions.\r\nThe standard technique is to make such propagation explicit, using\r\nvariables. However, referring to all entities that need to be\r\npropagated unchanged in each rule can be tedious, and it hinders\r\ndirect reuse of rules in different language descriptions.\r\n\r\nThis talk proposes a new interpretation of SOS rules, such that\r\neach auxiliary entity is implicitly propagated in all rules in\r\nwhich it is not mentioned. The main benefits include significant\r\nnotational simplification of SOS rules and much-improved reusability.\r\nThis new interpretation of SOS rules is based on the same\r\nfoundations as Modular SOS, but avoids the notational overhead\r\nof grouping auxiliary entities together in labels.\r\n\r\nAfter motivating and explaining implicit propagation, we recall\r\nthe foundations of SOS and Modular SOS specifications, and define\r\nthe meaning of SOS specifications with implicit propagation by\r\ntranslating them to Modular SOS. We then show how implicit\r\npropagation can simplify various rules found in the SOS literature.\r\nFinally, we propose the use of the new framework in connection\r\nwith so-called ''constructive semantics''.\r\n\r\nNote:\r\n\r\nThe talk is based on a paper that has been accepted for the\r\nSOS workshop at ICALP this summer. Copies will be handed out\r\nat the seminar.\r\n',2,'');

INSERT INTO `seminar` VALUES (395,'2008-06-05','15:00 (!)','Robert Recorde Room','Graham Birtwistle','','University of Sheffield','','The family of 4-phase latch controllers','This talk describes joint work with Ken Stevens (University of\r\nUtah) on the design of 4-phase asynchronous latch controllers.\r\n\r\nIt is easy to argue for a specification of the most concurrent\r\npossible protocol specification (there are mild restrictions),\r\nexpress it as a simple state machine, and then examine how it\r\nbehaves when pipelined (single and parallel pipelines).\r\n\r\nWe then apply simple and clear rules to cut away states and\r\nsystematically uncover the family of related less state-rich\r\nmachines that still adhere to the 4-phase protocol and how\r\nthey behave when pipelined.\r\n\r\nThe cut rules allow us to order the whole family into a lattice\r\nand relate and compare members.  The approach is quite general\r\nand would seem to be applicable to many other protocols.\r\n\r\nNo knowledge of asynchronous hardware design is required.',2,'');

INSERT INTO `seminar` VALUES (396,'2008-05-27','14:00','Robert Recorde Room','Abbas Edalat','http://www.doc.ic.ac.uk/~ae/','Imperial College','http://www3.imperial.ac.uk/','Weak topology and a differentiable operator for Lipschitz maps ','Many fundamental topologies in functional analysis arise as weak topologies. We show that the Scott topology induces a topology for real-valued Lipschitz maps on Banach spaces which we call the L-topology: It is the weakest topology with respect to which the domain-theoretic L-derivative operator, as a second order functional which maps the space of Lipschitz functions into the function space of non-empty weak* compact and convex valued maps equipped with the Scott topology, is continuous. For finite dimensional Euclidean spaces, where the L-derivative and the Clarke gradient coincide, we provide a simple characterisation of the basic open subsets of the L-topology in terms of ties or primitive maps of functions. We use this to verify that the L-topology is strictly coarser than the well-known Lipschitz norm topology. We then develop a fundamental theorem of calculus of second order in finite dimensions showing that the continuous integral operator from the continuous Scott domain of non-empty convex and compact valued functions to the continuous Scott domain of ties is inverse to the continuous operator induced by the L-derivative. ',1,'');

INSERT INTO `seminar` VALUES (397,'2008-03-27','14:00','Robert Recorde Room','Derrick Kourie','http://www.cs.up.ac.za/userinfo.php?uid=dkourie','University of Pretoria','http://www.cs.up.ac.za/','A new CSP operator for optional parallelism','We introduce a new CSP operator for modeling scenarious characterized by partial or optional parallelism. We provide examples of such scenarios and sketch the semantics of our operator. Relevant properties are proven.',3,'');

INSERT INTO `seminar` VALUES (394,'2008-05-29','14:00','Robert Recorde Room','Petter Kristian Kober','','Oslo, visiting Swansea','','Inductive Definitions over Domain Representable Spaces','We study strictly positive inductive definitions over a class of topological\r\nspaces with admissible domain representation, the qcb0 spaces. In\r\nparticular, we prove that if A and B are qcb0 spaces, then there exists a\r\nminimal qcb0 space X which satisfies the equation X = A + [B => X]. \r\nThis least fixed point is obtained via a similar construction over a certain\r\nclass of domains with partial equivalence relations, using standard domain\r\nrepresentations of A and B. In fact, a least fixed point exists for every\r\nstrictly positive operator.  \r\nWe also look at how further generalisations, e.g. admitting generalised\r\npositive induction or free algebra constructions in the defining equation,\r\ntend to somewhat complicate the situation.\r\n\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (398,'2008-07-03','14:00','Robert Recorde Room','David Chisnall','','Swansea','http://www.swan.ac.uk/compsci/','Dynamic Object Oriented Languages','Dynamic languages have a long history, going back to the second programming language to be generally considered ''high level'' - Lisp.  In recent years they have undergone a renaissance, spurred by the growth of the World Wide Web, with JavaScript - a derivative of Self - found in every Web Browser and languages such as Ruby - a derivative of Smalltalk - on the server.\r\n\r\nThis talk will discuss the strengths and weaknesses of the dynamic approach to programming languages, their relation to object orientation, and techniques which can be used to improve their current implementation.',3,'');

INSERT INTO `seminar` VALUES (401,'2008-10-07','14:00','Robert Recorde Room','Stephen Gilmore','http://www.dcs.ed.ac.uk/home/stg/','The University of Edinburgh','http://www.inf.ed.ac.uk/','Service-level agreements for service-oriented computing','Service-oriented computing is dynamic.  There may be many possible service instances available for binding, leading to uncertainty about where service requests will execute.  We present a novel Markovian process calculus which allows the formal expression of uncertainty about binding as found in service-oriented computing. We show how to compute meaningful quantitative information about the quality of service provided in such a setting.  These numerical results can be used to allow the expression of accurate service-level agreements about service-oriented computing.',1,'');

INSERT INTO `seminar` VALUES (403,'2008-10-28','14:00','Robert Recorde Room','Eike Ritter','http://www.cs.bham.ac.uk/~exr/','Birmingham','http://www.cs.bham.ac.uk/','Characterising the computational power of an intruder in the Applied Pi-Calculus','The Applied Pi-Calculus has been used successfully as a formalism to\r\nverify security protocols. Many important security properties can be\r\nmodelled as observational equivalences in this calculus. An important\r\npart of such an observational equivalence between two processes is to\r\nshow that the computational power of an intruder is the same for both\r\nprocesses. In this talk we give a characterisation the computational\r\npower of an intruder.\r\n\r\nThis is joint work with Aybkek Mukhamedov and Mark Ryan.',1,'');

INSERT INTO `seminar` VALUES (402,'2008-09-16','14:00','Robert Recorde Room','Achim Jung','http://www.cs.bham.ac.uk/~axj/','University of Birmingham','','3 = 4 ? ','In three-valued logic one considers a third truth value besides the usual \"true\" and \"false\", namely, \"unknown\". This is a useful concept when one is dealing with situations where knowledge is partial (as in many AI applications) or uncomputable.\r\n\r\nIn four-valued logic, a further value is considered, representing \"contradiction\". This, too, arises naturally when one tries to formalise the knowledge that one holds (or that one has been told) about aspects of the real-world.\r\n\r\nFor a logic we need more than the truth values, however, and one can wonder what logical connectives would be appropriate in these multi-valued settings, and what their proof rules should be. In this talk I will present a point of view (developed jointly with Drew Moshier) which is strongly model-theoretic. By studying sets of models, one is led fairly naturally to consider axiomatisations of three- and four-valued logic which make a clear distinction between \"logic\" and \"information\". Furthermore, it emerges that there is in fact a 1-1 translation between the three- and four-valued approach.\r\n',2,'');

INSERT INTO `seminar` VALUES (404,'2008-09-23','14:00','Robert Recorde Room','Heike Janicke','http://www.informatik.uni-leipzig.de/bsv/bsvneu/index.php?option=content&task=view&id=64','Institut fur Informatik, Universitat Leipzig','http://www.informatik.uni-leipzig.de/','Visualization of Unsteady Multivariate Data Using Information Theory','Visualizations are well suited to communicate a large amount of complex data. With increasing resolution in the spatial and temporal domain, simple imaging techniques meet their limits, as it is quite difficult to display multiple variables in 3D or analyze long video sequences. Techniques from information theory can help to compress the original data and extract the essential. In the presentation two techniques based on ideas from computational mechanics will be presented: Local statistical complexity identifies regions in the data-set whose local dynamics diverge from the dynamics in the rest of the data-set and can be used to identify extraordinary events. A precise analysis of these structures is provided by the second method - epsilon-machines. Epsilon-machines reconstruct a finite state machine from the given data and can be visualized as directed graphs. These graphs allow for a steady two-dimensional visualization of unsteady data. Both techniques will be illustrated using examples from fluid and weather simulations. ',1,'');

INSERT INTO `seminar` VALUES (406,'2008-11-11','14:00','Robert Recorde Room','Robin Green','','FIT Lab, Swansea','http://www.fitlab.eu/','','',1,'');

INSERT INTO `seminar` VALUES (407,'2008-12-09','14:00','Robert Recorde Room','Frederic Labrosse','http://users.aber.ac.uk/ffl','Aberystwyth University','http://www.aber.ac.uk/compsci/public/','Image manifolds: their representation and their use in IBR and robotics','In this seminar, I will introduce the idea of image manifold (a \"surface\" in image space, the space containing all possible images of a given size, that encompasses all possible views of an object) and briefly talk about some of their good and not so good properties. I will then present two applications that can benefit from the idea of the image manifold. The first is image based rendering where any view of an object can easily be created if a continuous representation of its image manifold is available. I will discuss the issues in that area and what we are doing to solve them.  The second application is that of mobile robotics and specifically visual navigation. I will show how local approximation of the manifold and sampling of it can be used in such task.',1,'');

INSERT INTO `seminar` VALUES (410,'2008-10-16','14:00','Robert Recorde Room','Ulrich Berger','http://cs.swan.ac.uk/~csulrich/','Swansea','http://www.swan.ac.uk/compsci/index.html','A coinductive approach to digital computation','We present digit spaces and their coinductively defined morphisms as an abstract approach to digital computation. A digit space is a set X together with a set D of functions, from X to X. The elements of D are called digits. A standard example of a digit system is the compact real interval I = [-1,1] together with the functions av_i : I -> I (i = -1,0,1) defined by av_i(x) = (x+i)/2. This digit space corresponds to the well-known binary signed digit representation of real numbers in [-1,1] which has been extensively studied in exact real number computation, type theory and domain theory. \r\n\r\nOur approach contains two novelties:\r\n\r\n1. We define coinductively a set of morphisms between digit spaces which, in the standard cases, coincides with the set of uniformly continuous functions.\r\n\r\n2. We use the proof-theoretic technique of program extraction to automatically synthesise from constructive proofs lazy algorithms for these morphisms.\r\n\r\nWe show how constructive analysis and corresponding certified algorithms can be developed in this approach.\r\n\r\nStructures similar to digit spaces are known as iterated function systems in the theory of dynamical systems and fractals. Since our theory has different goals we chose a different name. \r\n\r\n\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (411,'2008-10-23','14:00','Robert Recorde Room','Ulrich Berger','','Swansea','','A coinductive approach to digital computation (Part II)','We present digit spaces and their coinductively defined morphisms as an abstract approach to digital computation. A digit space is a set X together with a set D of functions, from X to X. The elements of D are called digits. A standard example of a digit system is the compact real interval I = [-1,1] together with the functions av_i : I -> I (i = -1,0,1) defined by av_i(x) = (x+i)/2. This digit space corresponds to the well-known binary signed digit representation of real numbers in [-1,1] which has been extensively studied in exact real number computation, type theory and domain theory.\r\n\r\nOur approach contains two novelties:\r\n\r\n1. We define coinductively a set of morphisms between digit spaces which, in the standard cases, coincides with the set of uniformly continuous functions.\r\n\r\n2. We use the proof-theoretic technique of program extraction to automatically synthesise from constructive proofs lazy algorithms for these morphisms.\r\n\r\nWe show how constructive analysis and corresponding certified algorithms can be developed in this approach.\r\n\r\nStructures similar to digit spaces are known as iterated function systems in the theory of dynamical systems and fractals. Since our theory has different goals we chose a different name.\r\n',2,'');

INSERT INTO `seminar` VALUES (408,'2008-11-18','14:00','Robert Recorde Room','Benjamin Mora','http://cs.swan.ac.uk/~csmora/','Swansea University','http://www.swan.ac.uk/compsci/index.html','On the complexity of some rendering algorithms','Complexity of rendering 3D scenes with ray-tracing is usually described as logarithmic in publications focusing on this area of Computer Graphics. In this presentation, I will discuss on the complexity of some rendering algorithms, and demonstrate that complexity can actually been improved by exploiting spatial coherency in 3D renderings in a better way. If time permits, a new technique for storing and representing light fields will also be presented.',1,'');

INSERT INTO `seminar` VALUES (412,'2008-11-06','14:00','Robert Recorde Room','Mark New','','Swansea','','Operational Conservative Extension and Bisimulation for Modular SOS','Descriptions written using the Structural Operational Semantics (SOS) framework suffer with poor modularity: extending descriptions often requires extensive reformulation of the rules, which hinders changes and discourages reuse. The Modular SOS (MSOS) framework solves this problem, allowing specifications to be developed that can be extended or reused without reformulation.\r\n\r\nWe present the first study of proving semantic equivalences based on MSOS. After giving an overview of MSOS, we present a format that ensures that extensions are operationally conservative. We then give definitions of bisimulation for MSOS as well as example proofs based on simple programming language constructs. Finally, we discuss the modularity of these proofs.',2,'');

INSERT INTO `seminar` VALUES (413,'2008-11-13','14:00','Robert Recorde Room','John Power','','Bath','','Structural Operational Semantics for Computational Effects ','In seeking a unified study of computational effects, a fundamental task\r\nis to give a unified structural operational semantics, together with an\r\nadequate denotational semantics for it, in such a way that, for the\r\nleading examples of computational effects, the general definitions are\r\nconsistent with the usual operational semantics for the relevant\r\neffects. One can readily produce a unified operational semantics that\r\nworks fine for examples that include various forms of nondeterminism\r\nand probabilistic nondeterminism. But that simple semantics fails to\r\nyield a sensible result in the vitally important case of state or\r\nvariants of state. The problem is that one must take serious account of\r\ncoalgebraic structure. I shall not formally enunciate a general\r\noperational semantics and adequacy theorem in this talk, but I shall\r\nexplain the category theory that supports such a semantics and theorem.\r\nI shall investigate, describe, and characterise a kind of tensor of a\r\nmodel and a comodel of a countable Lawvere theory, calculating it in\r\nleading examples, primarily involving state. Ultimately, this research\r\nsupports a distinction between what one might call coalgebraic effects,\r\nsuch as state, and algebraic effects, such as nondeterminism.\r\n\r\n(Joint work with Gordon Plotkin) \r\n',2,'');

INSERT INTO `seminar` VALUES (405,'2008-11-04','14:00','Robert Recorde Room','Keith Cheverst','http://www.comp.lancs.ac.uk/department/staff.php?name=kc','University of Lancaster','','Exploring Awareness Related Messaging through Two Situated Display based Systems','My talk will focus on our exploration of awareness issues through the\r\ndesign and long term deployment of two systems: the Hermes office door\r\ndisplay system (which enables staff in a University Department to post\r\nawareness messages to their door displays) and SPAM (a messaging\r\nsystem for supporting coordination and communication between staff at\r\ntwo associated residential community care facilities). In the case of\r\nboth systems, a significant number of the messages sent can be\r\nclassified as relating to awareness. Furthermore, with both systems,\r\nthe situatedness of displays (outside office doors in the case of\r\nHermes and in staff offices in the case of SPAM) has had a significant\r\nimpact on the design and subsequent use of the deployed systems. In\r\nparticular, the placement of displays provides significant context for\r\nawareness messages, including, for example, the identity of the sender\r\nof the message and the intended audience of the message. Both systems\r\nhighlight the need for interaction methods that fit in with existing\r\nworking practices and that enable the user to manage their presence.\r\nHowever, we have found that many of the messages sent using the\r\nsystems have as much to do with playfulness and notions of community\r\nas supporting coordination.',1,'');

INSERT INTO `seminar` VALUES (409,'2008-11-20','14:00','Robert Recorde Room','Benedikt L&ouml;we','http://staff.science.uva.nl/~bloewe/','ILLC, Universiteit van Amsterdam','http://www.illc.uva.nl/','Analyzing TV crime story plots as games with mistaken beliefs','When are two stories the same? Is a remake of a movie ''identical'' with the\r\noriginal? Obviously, this depends on what features of the story you look\r\nat. In this talk, we analyse stories by their doxastic structure, i.e., we\r\nthink of the storyline as a sequence of events and actions driven by\r\n(potentially false) beliefs about the preferences of the other agents. We\r\nthen apply this formal model to the TV crime series \"CSI: Crime Scene\r\nInvestigation\", and identify a very small number of low-level doxastic\r\nbuilding blocks sufficient to construct the structure of these stories as\r\ngames with mistaken belief. The talk reports on joint work with Eric\r\nPacuit and Sanchit Saraf.',1,'');

INSERT INTO `seminar` VALUES (414,'2008-11-20','14:00','Robert Recorde Room','Benedikt Loewe','','Amsterdam','','Talk in Computer Science Colloquium','',2,'');

INSERT INTO `seminar` VALUES (415,'2008-12-11','14:00','Robert Recorde Room','Klaus Aehlig','','','','Talk in Computer Science Colloquium','see <a href=http://www.swan.ac.uk/compsci/research/seminars/seminar.php?seminar=399>Colloquium  announcement</a>',2,'');

INSERT INTO `seminar` VALUES (399,'2008-12-11','14:00','Robert Recorde Room','Klaus Aehlig','http://www.linta.de/~aehlig/','Swansea University','http://www.swan.ac.uk/compsci/index.html','Parallel Time and Proof Complexity','By introducing a parallel extension rule that is aware of independence of the introduced extension variables, a calculus for quantified propositional logic is obtained where heights of derivations correspond to heights of appropriate circuits.  Adding an uninterpreted predicate on bit-strings (analog to an oracle in relativised complexity classes) this statement can be made precise in the sense that the height of the most shallow proof that a circuit can be evaluated is, up to an additive constant, the height of that circuit.\r\n\r\nThe main tool for showing lower bounds on proof heights is a variant of an iteration principle studied by Takeuti. This reformulation might be of independent interest, as it allows for polynomial size formulae in the relativised language that require proofs of exponential height.\r\n\r\nAn arithmetical formulation of the iteration principle yields a strength measure for theories in the language of relativised two-sorted Bounded Arithmetic. This measure provides all the separations Dynamic Ordinal Analysis provides, but extends to theories where the latter fails to produce any separation, due to the overhead of first-order (i.e., sharply-bounded) cut elimination. The new measure can also be used to investigate relativised theories for small complexity classes that are not necessarily based on restricted forms of induction. In particular, it can be used for theories that axiomatise computations, most prominently, deterministic and non-deterministic space computations, and the evaluation of circuits. Before studying relativised versions of these theories it is necessary to define relativised versions of the corresponding complexity classes. This can be done in such a way that the known inclusions are preserved.\r\n',1,'http://www.linta.de/~aehlig/university/portrait-small.jpg');

INSERT INTO `seminar` VALUES (417,'2009-02-19','14:00','Robert Recorde Room','Majid Mirmehdi','http://www.cs.bris.ac.uk/~majid','University of Bristol','http://www.cs.bris.ac.uk','Real-time detection and tracking of text in videos','We present a real-time text tracking system capable of detecting and tracking text using a hand-held mobile camera at rates of above 25 frames per second. The method is based on extracting text regions using a novel tree-based connected component filtering approach, combined with the Eigen-Transform texture descriptor. The method can efficiently handle dark and light text on light and dark backgrounds. Predictive tracking (using either particle filters or the unscented Kalman Filter) is used to follow the text in the face of multiple regions of interest, fast displacements, and erratic motions. Strengths and shortcomings of the approach, plus future work, will be discussed.',1,'');

INSERT INTO `seminar` VALUES (419,'2009-05-26','14:00','Robert Recorde Room','Robert Kirby','http://www.cs.utah.edu/~kirby','University of Utah','http://www.cs.utah.edu','Leverhulme Lecture - Building Symbiotic Relationships Between Formal Verification and High Performance Computing','Computational simulations for scientific and engineering applications are becoming more ubiquitous as part of the engineering design cycle. The application of simulation science to complex problems often requires complex models, sophisticated numerics and intricate implementations. Tremendous effort has been expended towards the development of systematic techniques for model validation and numerical method verification. As most researchers hesitantly admit, the amount of time spent debugging intricate high performance parallel implementations of their simulations consumes a large bulk of their time. In particular, many would argue that although this debugging time is necessarily, it distracts one from the science or engineering problem of interest. In this talk, we will present our continuing effort by the Utah Gauss Group to employ formal verification techniques to the debugging of parallel high performance computing codes using MPI. This synergistic combination of formal techniques with HPC is designed to infuse news ways of thinking about parallel code design through interaction of two normally disparate communities, with the goal of benefiting both communities.',1,'');

INSERT INTO `seminar` VALUES (420,'2009-03-17','14:00','Robert Recorde Room','Enrico Rukzio','','Lancaster University','','Mobile Interaction with Pervasive User Interfaces','We currently observe the trend that more and more displays can be\r\nfound in homes, office environments, buildings and public spaces.\r\nFurthermore, it is predicted that interactive surfaces, such as Microsoft\r\nsurface and projector phones, will become pervasively available.\r\nThe presented research will show our investigation into new interaction\r\ntechniques and applications in which mobile phones interact with such\r\npervasive user interfaces. Through these techniques and applications, it is\r\npossible to overcome the limited output capabilities of mobile devices,\r\nenable multi-user applications, and to contribute or take away information.\r\nI will present our research on Touch & Interact (touch-based mobile\r\ninteraction with displays providing e.g. map-based information for tourists\r\nor photo sharing), Projector Phones (interaction techniques enabling mobile\r\ninteraction with large, high-resolution maps or photo collections) and\r\nRotating Compass (provision of personalized navigation information by public\r\ndisplays). I will show the implementation and evaluation of those systems,\r\nand will talk about their potential and shortcomings.',1,'');

INSERT INTO `seminar` VALUES (400,'2009-02-12','14:00','Robert Recorde Room','Jim Austin','http://www-users.cs.york.ac.uk/austin/','The University of York','http://www.cs.york.ac.uk/','Collecting old computers - an obsession or a necessity?','I have been collecting computer systems for over 25 years, initially focussing on mainframes, super computers and mini computers. Later additions include home computers and smaller systems. The collection now numbers well over 450 machines, including parts of EDSAC II, Pegasus 2 as well as 4 complete Cray''s and IBM mainframes and a Fujitsu supercomputer weighing many tonnes. These machines are stored in a number of sheds on the East Yorkshire Wolds. This talk will tell the story of the collection, highlighting some of the more interesting acquisitions. I will go on to address the reasons for collecting these systems - madness or an important undertaking. I will also bring along some interesting parts of some of the machines.',1,'');

INSERT INTO `seminar` VALUES (423,'2009-02-24','14:00','Robert Recorde Room','Andrew Blyth','http://www.comp.glam.ac.uk/staff/ajcblyth/','University of Glamorgan','http://www.glam.ac.uk/','Residual Data and Disk Stenography for Computer Hard-Drives','Computer Forensics is built upon the ability of an examiner to\r\nrecover data from digital media. However this process is built upon an\r\nassumption. The assumption is that computer media do not lie. In this talk I\r\nwill explore a) the level to which residual data can be found on second hand\r\ncomputer hard-drives, and b) can a computer hard-drive be made to lie?\r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (425,'2009-03-03','14:00','Robert Recorde Room','Grant Malcom','http://www.csc.liv.ac.uk/~grant/','Liverpool University','http://www.liv.ac.uk/','Algebraic Specification of Systems of Concurrent Components','We examine the use of algebraic theories in specifying evolving systems,\r\nby which we mean systems of objects where objects may be created and\r\ndestroyed, and where relationships between objects may change.\r\nIn particular, we look at how such systems can be modelled by\r\nevolving specifications: rather than having one specification\r\ndescribing a system, a hierarchically structured specification\r\ndescribes a state of the system; as the state of the system changes,\r\nso too does the hierarchically structured specification.\r\n\r\nOur main concern is in developing the model theory\r\nof such evolving systems, building on top\r\nof hidden algebra.  Hidden algebra was introduced by Goguen as a formal\r\nbasis for semantics of systems of interacting objects, and allows the\r\nspecification of concurrent, interacting objects through the so-called\r\nconcurrent connection.  This is an operation that works at the level of\r\nspecifications; i.e., two specifications, each specifying an object, and\r\npossibly interacting through a shared subcomponent, can be combined to\r\ngive a specification of a system comprising the two objects, together\r\nwith any shared subcomponents.  Our evolving specifications can be\r\nviewed as a system of concurrent connections of hidden algebraic\r\ntheories.\r\n',1,'');

INSERT INTO `seminar` VALUES (428,'2009-04-28','14:00','Robert Recorde Room','Mark Priestley','http://users.wmin.ac.uk/~priestm/','University of Westminster','http://wmin.ac.uk/','The changing role of logic in the history of programming languages','Two major episodes in the history of programming languages are the \r\nintroduction of structured and object-oriented programming, and both these \r\nparadigms are still very much alive in current mainstream languages.  \r\nThis talk will look at the very different role played by logic in the \r\ndevelopment of these two approaches, and I will argue that whereas logic \r\nplayed a dynamic and creative role in the development of structured \r\nprogramming, this was not the case in the development of object-orientated \r\nideas.  The talk will conclude by offering an explanation of this \r\nphenomenon which considers both logic and programming in the wider context \r\nof changing ideas about machinery.',1,'');

INSERT INTO `seminar` VALUES (429,'2009-10-06','14:00','Robert Recorde Room','Monika Seisenberger','http://www-compsci.swan.ac.uk/~csmona/','Swansea University','http://www.swan.ac.uk/compsci/index.html','Efficient program synthesis from proofs','In this talk we aim to promote program synthesis from formal proofs as a powerful technique to obtain certified programs. We discuss and demonstrate the advantages of this method and show how it is supported by the interactive proof assistant Minlog.\r\nFinally, we look at program extraction from coinductive proofs\r\nand applications thereof where the efficiency of the method\r\nalso becomes visible in the effort needed for the formalisation.\r\n',1,'');

INSERT INTO `seminar` VALUES (416,'2009-02-17','14:00','Robert Recorde Room','Johan Glimming','','University of Cambridge','','Towards Parametric Direcursion','Often, denotational semantics is based on solving recursive domain\r\nequations of mixed-variant type, such as untyped lambda calculus,\r\nobject calculi, or, languages with higher-order store. Denotational\r\nsemantics in these cases involve recursive function spaces in the\r\ndomain, and for such domains Freyd proposed a recursion scheme, called\r\ndirecursion, which allows definition and proofs for semantic elements,\r\nas studied also in the work of Pitts. We will in this paper generalise\r\nthis mixed-variant recursion scheme and show that it can be\r\nparameterised by an adjunction equipped with two natural\r\ntransformations that distribute the functors of the adjunction in a\r\ncertain sense over the domain constructors, generalising strength for\r\nendofunctors to the mixed-variant situation. The new recursion scheme,\r\ncalled parametric direcursion, solves the problem of maintaining\r\nadditional arguments while computing with recursive types. In addition\r\nto constant parameterisations (c.f. Cockett et al''s strong\r\ninitiality), we also deal with parameterisations where, at each\r\nrecursive step, the parameters may be modified both covariantly and\r\ncontravariantly. This amounts to what functional programmers have\r\ntermed ``accumulating parameters'''' (c.f. Pardo), but here in the\r\ncontext of recursive domain equations. We illustrate the applicability\r\nof the result with some examples of parameterisations in denotational\r\nsemantics.',2,'');

INSERT INTO `seminar` VALUES (433,'2009-05-14','14:00','Robert Recorde Room','Tom Chen','http://www.swansea.ac.uk/iat/Staff/AcademicStaff/ProfessorThomasChen/','Swansea University','http://www.swansea.ac.uk/iat/','Top 5 Web Threats','A few years ago, the greatest worry for PC users were viruses and worms through e-mail. While viruses and worms are still prevalent, the Web has recently become the main avenue for attacks on PC users because the Web allows stealthy \"pull\" attacks where malicious sites wait for unsuspecting visitors. In this talk, we will highlight five stealthy and common Web-based attacks and research that is being done to protect users.\r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (434,'2009-05-21','14:00','Digital Technium, Room 05 (Access Grid Room) ','Jose Fiadeiro','http://www.cs.le.ac.uk/people/jfiadeiro/','University of Leicester','http://www.le.ac.uk/external/','An abstract  model of service discovery and binding','We put forward a formal operational semantics for service discovery and binding based on a graph-based representation of the configuration of global computers typed by business activities.  Business activities execute distributed workflows that can trigger, at run time, the discovery, ranking and selection of services to which they bind, thus reconfiguring the workflows that they execute.  Discovery, ranking and selection are based on compliance with required business and interaction protocols and optimisation of quality of service constraints.  Binding and reconfiguration are captured as algebraic operations on configuration graphs. This is joint work with Antonia Lopes, University of Lisbon.',3,'');

INSERT INTO `seminar` VALUES (418,'2009-03-10','14:00','Robert Recorde Room','Richard Wilson','http://www-users.cs.york.ac.uk/~wilson/','University of York','http://www.cs.york.ac.uk/','Pattern Recognition with Graphs and Trees','Relational representations arise naturally from some types of data. They can also be used as an alternative representation of more traditional problems. These representations can be captured by graphs. Graph data provides some interesting and difficult challenges to the traditional pattern recognition model. In this talk I will survey more than a decade of research at York aimed at addressing some of this problems.\r\nStarting from a standard model of recognition, I will highlight some of the particular challenges and some of the various approaches. I will begin by discussing the problem of comparing graphs via alignment and explain some optimisation-based approaches using graph deconstruction. I will then talk about the feasibility of extracting useful features directly from graphs without the need for alignment. Here spectral methods are an invaluable tool for finding descriptors which are invariant to graph order and be used as graph features. Finally, generative models are an important tool in machine learning. Recent work at York has investigated the use of generative models of graph structure. I will present a number of possible generative models for graphs and explain their use of different graph data. ',1,'');

INSERT INTO `seminar` VALUES (422,'2009-03-04','12:15 onwards','Board Room','Yoshiki Kinoshita, Makoto Takeyama, John Power','','AIST, Japan, Bath University, UK','','3rd Wessex Theory Seminar, Swansea day','The third meeting of the Wessex Theory Seminar will be on Tuesday 3rd and Wednesday 4th March, co-located between Bath (3rd March) and Swansea (4th March).\r\n\r\nFor further information please see\r\n<a href=\"http://wiki.bath.ac.uk/display/wessex/3rd+Wessex+Theory+Seminar\"> \r\n3rd Wessex Theory Seminar</a>',2,'');

INSERT INTO `seminar` VALUES (430,'2009-03-12','14:00','Robert Recorde Room','Dirk Pattinson','','Imperial College, London','','Recent Developments in and around Coalgebraic Logics','Applications of modal logics are abundant in computer science, and a large number of structurally different modal logics have been successfully employed in a diverse spectrum of application contexts:\r\nknowledge representation, reasoning about distributed and multi-agent systems and the verification of distributed systems. Coalgebraic semantics provides  a uniform and encompassing view on the large variety of specific logics used in particular domains.  The coalgebraic approach is generic and compositional: tools and techniques simultaneously apply to a large class of application areas and can moreover be combined in a modular way.\r\n\r\nIn particular, this facilitates a pick-and-choose approach to domain specific formalisms, applicable across the entire scope of application areas, leading to generic and feature-richsoftware tools that are easier to design, to implement, and to maintain.\r\n\r\nThis talk gives an introduction to coalgebraic logics, highlights some of the recent achievements, and demonstrates a proof-of-concept implementation. ',2,'');

INSERT INTO `seminar` VALUES (432,'2009-03-19','14:00','Robert Recorde Room','Matthew Gwynne','','Swansea','','A topological proof of Van der Waerden''s theorem','(Joint event with the MRes seminar.)\r\n\r\n\r\nVan der Waerden''s theorem states that for any finite partitioning of the natural numbers, there must be one part which contains arithmetic progressions of arbitrary length. This theorem provides an example of a particular kind of Ramsey-type problem, and provides a basis for discussion of the finite version of the theorem, leading to the notion of the Van der Waerden numbers.\r\n\r\nIn this talk, a proof is given of Van der Waerden''s theorem using topological notions, and algebraic structures over \"ultrafilters\". Such ultrafilters, in this case, are used to generalise the notion of addition and arithmetic sequences within the natural numbers and motivate the proof.\r\n\r\n\r\n\r\nThe plan is to give the talk in two parts:\r\n\r\n2-2:45   General, for a wider audience.\r\n3-3:45   Technical details, for those who are specifically interested ',2,'');

INSERT INTO `seminar` VALUES (426,'2009-04-21','14:00','Robert Recorde Room',' Willem Paul de Roever','http://www.informatik.uni-kiel.de/~wpr/','Christian-Albrechts University at Kiel, Germany','http://www.uni-kiel.de/','Perspective on a life in Program Verification','After giving a short overview of my own research and that of my collaborators, I address the main problems the field of Program Verification is facing as of now, and will proceed which mentioning what are its most promising directions, in my opinion.\r\n\r\nThroughout the talk references will be given to the main publications in the field, from a historical point of view, mentioning the role of the publications contained in the History of Computing Collection, especially, on Program Semantics, Specification and Verification, which are part of my former archive now gratefully donated to the University of Swansea. ',1,'');

INSERT INTO `seminar` VALUES (437,'2009-04-23','14:00','Digital Technium, Room 05 (Access Grid Room) - Joint Seminar with Bath University','Martin Brain','','University of Bath','','A Formalisation of Propositional Reasoning','This talk presents a formalism for describing the process of reasoning about propositional models, as performed by tools such as ASP, SAT and CSP solvers.  Unlike previous formalisms we start by describing the space over which the search is performed and thus produce implementation independent metrics of problem difficulty.  These are then used to show that particular problem decomposition techniques successfully target the most difficult parts of the problem.\r\n\r\nThis is a ''work in progress'' talk and as such will be somewhat informal and speculative.  The key aim is to identify relations to existing logics and algebraic models. ',2,'');

INSERT INTO `seminar` VALUES (439,'2009-04-30','14:00','Digital Technium, Room 05 (Access Grid Room) - Joint Seminar with Bath University','Pasquale Malacaria','','Queen Mary London','','Quantitative Information Flow and the Lattice of Information','Real systems leak confidential information, so instead of asking if a system is secure the question should be \"how much\" secure a system is. Quantitative Information Flow is a growing field whose aim is to address this question by measuring the leakage of confidential information in computer systems. We describe the Lattice of Information as a foundation for Quantitative Information Flow. We investigate the mathematical properties of this lattice and their relation to information theory and recent work in the area. In particular algebraic properties will be shown to simplify and clarify Quantitative Information Flow concepts as analysis of loops. Other properties like a metric distance on Lattice points will be shown to be relevant in providing robust yet tolerant declassification policies. ',2,'');

INSERT INTO `seminar` VALUES (435,'2009-05-07','14:00','Digital Technium, Room 05 (Access Grid Room) - Joint Seminar with Bath University','Jens Blanck','','Swansea','','Domain representations of spaces of compact subsets ','We present a method for constructing from a given domain representation of a space X, with an underlying domain D, a domain representation of a subspace of compact subsets of X where the underlying domain is the Plotkin powerdomain of D. We show that this operation is functorial over a category\r\nof domain representations with a natural choice of morphisms.\r\n\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (440,'2009-05-19','14:00','Robert Recorde Room','Felix Beckmann','http://www.gkss.de/institute/materials_research/structure/physical_metallurgy/structural_research_novel/staff/002866/index_0002866.html.en','GKSS-Research Centre Geesthacht, Germany','http://www.gkss.de/index.html.en','HIGH-DENSITY RESOLUTION MICROTOMOGRAPHY USING SYNCHROTRON RADIATION AT DESY','<a href=\"http://www.cs.swan.ac.uk/~csarnold/AbstractBeckmann.pdf\">pdf</a>',1,'');

INSERT INTO `seminar` VALUES (441,'2009-05-05','14:00','Robert Recorde Room','Yvonne Rogers','','Pervasive Interaction Lab, Open University.','','Pervasive Information For Everyday Decision-Making: Will People Become Wiser or Simply Ignore It?','Recent advances in affordable ubiquitous technology, including wearables with micro-projectors, ambient displays and sensor-based devices are beginning to excite researchers. Last month, Pattie Maes (Media Lab, MIT), in her much talked about TED talk, claimed that her team’s $250 ‘6th Sense” wearable device will enable ‘profound’ interactions with the world. A goal of my research is to promote ''proactive'' and ''provocative'' interactions with the environment through investigating how augmentation devices can encourage, entice and engage people to change their behaviour in response to a particular desired human value, e.g., environmental impact or well being.  The focus is at the point of decision-making during everyday activities. The aim is to provide ‘just-in-time’ information in places that can nudge, nag or nod people, such as on their clothing, food packaging, the dinner plate and other mundane objects. One project I have just started working on is investigating how to provide shoppers in food supermarkets with dynamically updated computational visualisations, through designing pervasive technologies that represent multi-dimensions they care about, e.g., price, nutritional value, carbon footprint, farming methods, etc. We are interested in whether people will pay attention to more information when making their purchase choices.  Moreover, will it enable them to make more informed decisions or will the new forms of ambient information be overwhelming and simply ignored like other kinds of food labelling? In my talk I will discuss how new ubiquitous computing approaches can overcome the ‘information overload’ problem through enhancing in situ decision making activities.\r\n\r\n-- \r\nBio\r\nSince 2006, Yvonne Rogers has been a professor of Human-Computer Interaction in the Computing Department at the Open University, where she directs the Pervasive Interaction Lab. From 2003-2006 she had a joint appointment in the schools of Informatics and Information Science at Indiana University (where she continues to be a visiting professor). Prior to that she was a professor in the former School of Cognitive and Computing Sciences at Sussex University. She has also been a Visiting Professor at Stanford, Apple, Queensland University and UCSD. Her research focuses on augmenting and extending everyday, learning and work activities with a diversity of interactive and novel technologies. She was one of the principal investigators on the UK Equator project (2000-2007), where she pioneered and experimented with ubiquitous learning. She has published widely, beginning with her PhD (Swansea) on graphical interfaces and icons in the early 80s to her most recent work on shareable interfaces and extended cognition.\r\n',1,'');

INSERT INTO `seminar` VALUES (442,'2009-05-21','15:30','Robert Recorde Room','Fernando Orejas','http://www.lsi.upc.es/~orejas/','Universitat Politecnica de Catalunya','http://www.upc.es/','Specification and implementation of model transformations using algebraic graph patterns','Model-to-model (M2M) transformation consists in transforming models from a source to a target language. Many transformation languages exist, but few of them combine a declarative and relational style with a formal underpinning able to show properties of the transformation. Pattern-based transformation is an algebraic, bidirectional, and relational approach to M2M transformation. Specifications are made of patterns stating the allowed or forbidden relations between source and target models, and then compiled into low level operational mechanisms to perform source-to-target or target-to-source transformations. In this presentation, we will introduce this specification method and study the compilation of patterns into operational triple graph grammar rules showing: (i) correctness of the compilation of a specification without negative patterns; (ii) termination of the rules, and (iii) completeness, in the sense that every  model considered relevant can be built by the rules.',3,'');

INSERT INTO `seminar` VALUES (443,'2009-06-25','14:00','Access Grid Room (Dig.Tech E05)','Matthew Lewsey ','','Swansea University','','32 categories for SAT','A few notions of category theory, mainly just the notion of a \"homomorphism\", have been considered in the literature for the satisfiability problem, either explicitly or implicitly. We are embarking on a more systematic study, starting with a thorough discussion of categories to be considered here. The \r\nemphasise of this talk is on the most basic notions, and besides (very) basic knowledge of category theory no further prerequisites are required.',2,'');

INSERT INTO `seminar` VALUES (444,'2009-06-11','14:00','Digital Technium, Room 05 (Access Grid Room) - Joint Seminar with Bath University','Andras Salamon','','Oxford','','Bounding series-parallel slowdown','We use directed acyclic graphs with node weights to model parallel programs. These are called activity-on-node networks or task graphs; each weight represents the duration of an activity. Programming constructs in parallel computing environments such as OpenCL and Matlab Parallel Computing Toolbox lead naturally to series-parallel activity networks. We consider series-parallelisations, formed by adding precedence constraints until the network becomes series-parallel. The slowdown ratio describes the resulting increase in makespan (execution time). Van Gemund conjectured that any network can be series-parallelised with slowdown at most 2, disregarding activity durations. We disprove this by considering neighbour synchronisation networks, and instead conjecture that if durations are known, then series-parallelisation is possible with slowdown at most 4/3. We show that the new conjecture is true for small networks, and outline a computer assisted proof technique for slightly larger networks. We also show that achieving 4/3 slowdown is in exp-APX, and appears to be NP-hard (joint work with Vashti Galpin, Edinburgh)\r\n',2,'');

INSERT INTO `seminar` VALUES (436,'2009-05-21','14:00','Digital Technium, Room 05 (Access Grid Room) - Joint Seminar with Bath University','Jose Fiadeiro','','University of Leicester','','An abstract  model of service discovery and binding ','We put forward a formal operational semantics for service discovery and binding based on a graph-based representation of the configuration of global computers typed by business activities.  Business activities execute distributed workflows that can trigger, at run time, the discovery, ranking and selection of services to which they bind, thus reconfiguring the workflows that they execute.  Discovery, ranking and selection are based on compliance with required business and interaction protocols and optimisation of quality of service constraints.  Binding and reconfiguration are captured as algebraic operations on configuration graphs. This is joint work with Antonia Lopes, University of Lisbon. ',2,'');

INSERT INTO `seminar` VALUES (445,'2009-11-10','14:00','Robert Recorde Room','Simon Cox','http://users.aber.ac.uk/sxc/','Institute of Mathematics and Physics, Aberystwyth University','http://www.aber.ac.uk/','The fascination of foams','Foams are used in many industrial and domestic applications and so trying to predict their behaviour is a worthwhile goal. I will describe a number of areas in which computer science contributes to achieving this goal.\r\n\r\nFirstly, the local geometric structure of a foam has a particular appeal due to the simplicity of the laws of equilibrium, themselves based upon a minimum energy principle. Determining the optimal geometric structure, that is the lowest energy minimum, is a non-trivial problem even in two dimensions (2D). I will show how it can be viewed as a problem in the enumeration of planar graphs.\r\n\r\nWhether as a test of theoretical predictions or as an exploratory tool in its own right, tomographic imaging of unstable 3D foams is now a reality. The large data sets that result require the development of new tools both to extract useful information, such as local bubble deformation and velocity, and to present this information in a meaningful and accessible manner.\r\n\r\nFinally, rheological flows of foams can be simulated with a number of numerical techniques that probe the flow on the bubble scale. This is usually a very slow computation and moving to a parallel code is not always possible. I will indicate the approximations inherent in these codes and the results that emerge. ',1,'');

INSERT INTO `seminar` VALUES (446,'2009-09-02','14:00','Robert Recorde Room','Robin Adams','','Royal Holloway, University of London','','Proof and definition in logic and type theory','Most approaches to logic focus on proof. The logic consists of the axioms and rules of deduction that may be used when proving a theorem. Definitions are secondary: to say that a function is definable typically means just that a certain formula is provable. Type theory takes the opposite approach. A type theory specifies which operations are acceptable when constructing an object. With type theory, proof is secondary: to say that a theorem is provable means just that an object of a certain type is constructible.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (447,'2009-10-20','14:00','Robert Recorde Room','Virpi Roto','http://research.nokia.com/people/virpi_roto/','Nokia Research','http://research.nokia.com/','Improving Mobile Internet User Experience','Since working on the Minimap mobile Web browser 2004-05, our research team has been investigating more direct routes for people to utilize the Internet on mobile devices. In our mobile Internet user studies, we saw that people have too many interesting Web pages and service-specific widgets to handle smoothly on a mobile device. The more integrated, or linked, the Internet services are in the mobile device UI itself, the easier it is to use them. We went public with Linked Internet UI research concept just in September, and this talk will describe the user research and motivation behind the concept.\r\n\r\n \r\n\r\nDr. Virpi Roto is a Principal Scientist in Nokia Research Center, Helsinki, and currently a visiting researcher in Tampere University of Technology, Human-Centred Technology unit. Her PhD investigated why and how people use the Web on mobile phones and what are the factors affecting user experience in mobile Web browsing. Virpi Roto has organized workshops on Mobile Internet User Experience in conjunction with MobileHCI conference and is the guest editor of the brand new IJMHCI special issue on Mobile Internet User Experience.',1,'http://research.nokia.com/files/pictures/VirpiRotoNRC.JPG');

INSERT INTO `seminar` VALUES (448,'2009-10-27','14:00','Robert Recorde Room','Robert Macredie','http://www.brunel.ac.uk/about/acad/siscm/disc/people/all/robertmacredie','Brunel University','http://www.brunel.ac.uk/','What Do You Know?: Improving student experience','This talk will take a broad perspective on understanding how to ''deliver'' an experience, through academic activities and university services, that fit students'' needs. It will provide some high-level suggestions on how to go about developing activities and services from a student perspective, rather than what activities or services might be useful to develop or improve.  The talk will also argue the value of using research into Customer Experience to help understand and respond to our students. \r\n\r\n\r\nWith over 15 years of research experience, Rob Macredie has worked with a range of organisations, ranging from large, blue-chip companies, through small businesses, to government agencies and charities.  Rob''s key research interest lies in the way in which people and organisations use technology, and his research aims to determine how work can be more effectively undertaken by improving the way that we understand how people and technology interact in organisational (and social) settings.  He is Professor of Interactive Systems and Pro-Vice-Chancellor, Brunel University, where his role spans all aspects of the Student Experience - sometimes to his colleagues'' annoyance.',1,'http://www.brunel.ac.uk/6496/Profile%20Photos/rob_mcredie.jpg');

INSERT INTO `seminar` VALUES (449,'2009-10-29','14:00 - 17:00','Robert Recorde Room','Speakers: Dirk Pattinson, Yoshiki Kinoshita, John Power','','Imperial College, AIST Japan, Bath University','','4th Wessex Theory Seminar','For further information please see:\r\nhttp://wiki.bath.ac.uk/display/wessex/4th+Wessex+Theory+Seminar',2,'');

INSERT INTO `seminar` VALUES (450,'2009-10-15','14:00','Robert Recorde Room','Ana Cavalcanti','','York','','Talk in the Algebraic Specification Seminar: Circus: Z and CSP for refinement','',2,'');

INSERT INTO `seminar` VALUES (453,'2009-12-01','14:00','Robert Recorde Room','Yulia Hicks','http://www.engin.cf.ac.uk/whoswho/profile.asp?RecordNo=367','Cardiff University','http://www.engin.cf.ac.uk/','Incremental Learning of Gaussian Mixture Models','Dr Yulia Hicks will give a quick overview of her research over the recent years, which involved using and developing statistical models for audio, image and video processing. The applications include tracking articulated human motion in video, modelling and generating human interactions, animated speech driven models of human faces, blind source separation and biological  models. The main part of the talk will be devoted to her most recent research in the area of incremental learning of Gaussian Mixture Models (GMMs) and Hidden Markov Models (HMMs) and application of these methods to image segmentation and learning dynamical models of faces. GMMs and HMMs became very popular for modelling data sets in the area of Computer Vision in recent years. However, learning GMMs and HMMs on large data sets can be both time and memory intensive. In addition, not all data may be available at once. Thus the possibility of splitting the data sets into smaller ones, learning the models separately on them, possibly at different times and sites, and then merging the models would be useful. The proposed  methods allow for this. Applications and experiments demonstrating the effectiveness of the methods will be\r\npresented.',1,'');

INSERT INTO `seminar` VALUES (454,'2009-10-22','14:00','Far-134 (Access grid room)','Yoshiki Kinoshita','','AIST Japan','','Joint talk with Bath University: Landau in Agda  ','I am writing proofs to the propositions in Landau''s Grundlagen der  Analysis (Foundation of Analysis).  Although the work is still at an early stage (only completed the addition of natural numbers), I have some observations comparing Landau''s original proofs and proofs suitable for Agda. I will talk about those observations, as well as a  \r\nsmall tool which represents equational and inequational proofs nicely.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (456,'2009-11-12','14:00','Far-134 (Video Conferencing Room)','Martin Brain','','Bath University','','Future Directions in Logic Programming  ','This talk covers one of the current ''hot'' areas in logic programming, answer set programming.  We start with an introduction to answer set semantics and where it fits in the context of non-monotonic logics and \"common sense\" reasoning.  This provides a foundation for discussing answer set programming and it''s relation to CSP and SAT based paradigmes. Finally we discuss some of the application\r\ndevelopment work that has been done at the University of Bath and explain how all of this relates to composing music, playing computer games and proving machine code to be optimal.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (457,'2009-12-03','14:00','Far-134 (Video conferencing room)','Rob Arthan','','Lemma 1 Ltd/Queen Mary','','Decision Problems in Geometry and Analysis','Powerful automatic proof procedures are essential for the application of formal methods in engineering and for the solution of verification problems in mathematics. I will describe some recent work on the decision problems for the natural two-sorted first-order theories for metric spaces, Hilbert spaces and Banach spaces. It turns out that the theory of Hilbert spaces is decidable via a reduction to the first-order theory of the reals while the theories of metric spaces and Banach spaces are undecidable in a very strong sense. The undecidability stems from phenomena that begin in dimension two and the proofs are quite pictorial. Despite the undecidability results, there are decision procedures that have proved useful in practice for fragments of the theory of Banach spaces. I will report on these and on a little challenge problem for automated proof in the real trigonometric field arising from the work on undecidability.',2,'');

INSERT INTO `seminar` VALUES (458,'2009-11-05','14:00','Robert Recorde Room','Robin Milner','http://www.cl.cam.ac.uk/~rm135/','University of Cambridge','http://www.cam.ac.uk/','The Space and Motion of Large Informatic Systems','Informatics is no longer confined to computation.  It concerns any real-world\r\nsystem, whether naturally occurring or man-made, where information flows among\r\nthe components. Examples are the internet, biological systems, and the\r\nsensors/activators and software embedded in an aircraft or even in your body.\r\nSuch systems are often called ubiquitous computing systems (ubicomp).\r\n\r\nComputer science, better called informatics, is therefore a modelling science on\r\na par with chemistry and biology.  To understand ubicomp is even more imperative\r\nthan to understand legacy computing systems.  I argue that  for this purpose we\r\nneed a tower of models of increasing abstraction, which may be combine with\r\nother models (e.g. with electro-mechanics and meteorology to model aircraft flight).\r\n\r\nI shall put forward a generic model, called bigraphs, for ubicomp. I shall\r\nillustrate it with the informatic flow in a highly instrumented built\r\nenvironment.  The model is mathematical yet highly visual.',1,'');

INSERT INTO `seminar` VALUES (455,'2009-11-05','14:00','Robert Recorde Room','Robin Milner','','University of Cambridge','','Talk in the Computer Science Colloquium','',2,'');

INSERT INTO `seminar` VALUES (459,'2009-12-10','14:00','Far-134 (Video conferencing room)','Jens Blanck','','Swansea','','Canonical effective subalgebras of classical algebras as constructive metric  completions','We prove general theorems about unique existence of effective subalgebras of classical algebras. The theorems are consequences of standard facts about completions of metric spaces within the framework of constructive mathematics, suitably interpreted in realisability models. We work with general realisability models rather than with a particular model of computation. Consequently, all the results are applicable in various established schools of computability, such as type 1 and type 2 effectivity, domain representations, equilogical spaces, and others.',2,'');

INSERT INTO `seminar` VALUES (460,'2009-11-17','14:00','Robert Recorde Room','Achim Jung','http://www.cs.bham.ac.uk/~axj/','University of Birmingham','http://www.cs.bham.ac.uk/','On domain algebras','Domains (in the sense of Dana Scott) can be characterised via \r\ntheir order structure or via their (Scott) topology. A lot is known \r\nabout their structural properties both at the individual and the \r\ncategorical level. In applications, in addition to the order structure \r\nsome algebraic operations satisfying certain equations are often \r\nrequired. The interplay between order/topology and algebra is not \r\nentirely straightforward but we do now have some general existence theorems.\r\n\r\nIn this talk I intend to present the various approaches to domain theory \r\nthat one might be interested in from an applications point of view, and \r\nthen explain the difficulties one has to overcome if one is trying to \r\nadd algebraic structure. In joint work with M. A. Moshier and S. \r\nVickers, we have found a new way of constructing domain algebras which \r\nis much more concrete than the method that was employed before. More \r\nrecently still, K. Keimel and J. Lawson discovered that this can be \r\nexplained and extended very elegantly by replacing order with topology.',1,'');

INSERT INTO `seminar` VALUES (461,'2009-11-19','14:00','Robert Recorde Room','Ursula Martin','http://www.dcs.qmul.ac.uk/~uhmm/','Queen Mary University of London','http://www.dcs.qmul.ac.uk/','impactQM - people, impact and  knowledge transfer at Queen Mary','impactqm is a new EPSRC funded knowledge transfer activity at Queen  \r\nMary, focussed largely on ICT research but linking to other EPSRC  \r\nareas such as maths, physics, chemistry, biology and medicine. We are  \r\ntaking the view that impact is about people, partnerships and  \r\nresearch, and piloting a number of activities to increase our  \r\ninteraction with users of research. I''ll give an overview of our  \r\nthinking and activities, and some thoughts on the more general \"impact  \r\nagenda\"\r\n',1,'');

INSERT INTO `seminar` VALUES (462,'2009-11-19','14:00','Robert Recorde Room','Ursula Martin','','Queen Mary','','Talk in the Computer Science Colloquium','',2,'');

INSERT INTO `seminar` VALUES (463,'2010-02-23','14:00','Robert Recorde Room','Temesghen Kahsai','http://www.swan.ac.uk/compsci/people/homepage.php?staff=T.Kahsai','Swansea','','Property preserving development and testing for Csp-Casl','The time has come to tell you a little bit about what I did in the\r\nlast three years sitting in my cubical (apart from drinking coffee and\r\nplaying Labminton). Basically, I will give an overview of the results\r\ndescribed in my PhD thesis.\r\n\r\nIn this talk I will illustrate some development notions for the\r\nspecification language Csp-Casl. Such notions are capable of\r\ncapturing informal vertical and horizontal software developments\r\nwhich we typically find in industrial applications (e.g. electronic\r\npayment system). On the other hand, such development notions allow us\r\nto verify some interesting properties, e.g., deadlock freedom.\r\n\r\nI will also present a theory for the evaluation of test cases with\r\nrespect to Csp-Casl specifications. With this approach, it is possible\r\nto develop test cases for even the most abstract and basic\r\nspecifications, and to reuse them later on in more refined systems.\r\n\r\nThe presented theoretical results have been applied to the electronic\r\npayment system EP2. Here, I have modeled the system in Csp-Casl and\r\nverified properties using tool support. Finally I will present a\r\nhardware-in-the-loop testing framework for EP2. For the latter, I will\r\ngive a concrete demo with a ''real'' payment terminal.\r\n',1,'http://cs.swan.ac.uk/~csteme/Temesghen.jpg');

INSERT INTO `seminar` VALUES (468,'2010-04-22','14:00','Far-134 (Video Conferencing Room)','Alan Frisch','http://www-users.cs.york.ac.uk/~frisch/','York','http://www.cs.york.ac.uk/','Joint talk with Bath University: The Rules of Modelling Automatic Generation of Constraint Programs','Many and diverse combinatorial problems have been solved with great success using constraint programming. However, to employ constraint programming technology to solve a problem, the problem first must be characterised, or modelled, by a set of constraints that its solutions must satisfy. Generating a correct model can be difficult; generating one that is easier to solve than its alternatives is even more difficult, often requiring considerable expertise. This so-called \"modelling bottleneck\" has inhibited the wider use of constraint programming technology. This talk describes CONJURE, a rule-based system that automatically generates constraint programs by refining an abstract problem specification. Since the high-level specification language is significantly closer than a constraint program to the way in which problems are commonly conceived, the modelling bottleneck is substantially reduced. A particular focus of this talk is showing why the refinement rules must be recursive, why this is difficult to achieve and how we ultimately solved solved this problem. This talk assumes no background in constraint programming.',2,'');

INSERT INTO `seminar` VALUES (465,'2010-02-11','14:00','Far-134 (Video Conferencing Room)','Fredrik Nordvall Forsberg','','Swansea','','Inductive-inductive definitions','We present inductive-inductive definitions, a principle for introducing new sets in Martin-Loef type theory which generalise indexed inductive data types. The principle allows one to simultaneously introduce a set A together with an A-indexed set B, where A and B(a) for a : A are mutually inductively defined. Instances of this principle have been used to formalise type theory inside type theory, but without justification why this is consistent or constructively valid.\r\n\r\nIn this talk, we will introduce the notion of inductive-inductive definitions and then give a closed axiomatisation. We prove consistency by constructing a set theoretic model.',2,'');

INSERT INTO `seminar` VALUES (471,'2010-02-04','14:00','Robert Recorde Room','Heike Jaenicke','','Swansea University','','Visualization of Time-dependent Data and its Evaluation','Time-dependent data occurs in many application areas and is often difficult to depict. In this talk, I will present visualization techniques for two quite different types of time-dependent data: a system to analyze climate variability change and a semantically-rich visual language for sound in movies. In many applications, however, it is not just important to get any visualization, but to make sure that the viewer gets the right information from it. Hence, the last section of the talk is dedicated to the question \"Do you see what I want you to see?\"',1,'');

INSERT INTO `seminar` VALUES (472,'2010-03-02','14:00','Robert Recorde Room','David Lester','http://intranet.cs.man.ac.uk/apt/people/dlester/','Manchester','http://www.cs.manchester.ac.uk/index.html','Biologically-Inspired Massively-Parallel Architectures - computing beyond a million processors','The SpiNNaker project aims to develop parallel computer systems with more \r\nthan a million embedded processors. The goal of the project is to support \r\nlarge-scale simulations of systems of spiking neurons in biological real \r\ntime; an application that is highly parallel but which also places very \r\nhigh loads on the communication infrastructure due to the extremely high \r\nconnectivity of biological neurons. The object of the research is to \r\nprovide a generic platform that can be used by neuroscientists and \r\npsychologists to test hypotheses of brain function, and also to \r\ndemonstrate a high-performance computing system with unprecedented \r\nenergy-efficiency.\r\n',1,'');

INSERT INTO `seminar` VALUES (473,'2010-02-09','14:00','Robert Recorde Room','Alex Rabinovich','','','','Extensions of the Church Synthesis Problem (a survey of results on Church''s Problem)','Church''s Problem (1963) asks for the construction of a procedure which, given a logical specification R on sequence pairs, realizes for any input sequence I an output sequence O such that (I,O) satisfies R.\r\n\r\nMcNaughton reduced Church''s Problem to a problem about two-person omega-games.\r\n\r\nThe fundamental result due to Buchi and Landweber provides a solution for Monadic Second-Order Logic of Order specifications in terms of finite-state strategies.\r\n\r\nWe survey our recent results on three natural and orthogonal\r\ngeneralizations of Church''s problem.\r\n\r\n  1. The first considers strategies definable in logical formalisms.\r\n  2. The second considers parametrized version of the church problem.\r\n  3. The third deals with long games of any ordinal length.\r\n',1,'');

INSERT INTO `seminar` VALUES (474,'2010-03-25','14:00','Robert Recorde Room','Stephen Payne','http://www.bath.ac.uk/comp-sci/people/index.php?contact=Prof_Stephen_Payne','University of Bath','http://www.bath.ac.uk','Theory of Skim Reading','It is no longer difficult to find relevant information sources for most knowledge-acquisition tasks.  Instead, the challenge is to allocate limited time effectively within and between documents.  It is a commonplace observation that on-line reading is often skim reading.  Yet little is know about how skim reading is done or how effective it is.  I will present a series of experimental studies in which participants with general learning goals allocate limited time to multiple or single on-line documents.  I will sketch a theory of skim reading that differs from conventional suppositions and offer some speculations about how the theory might inform design, and how it relates to a general approach to human activities.',1,'http://www.bath.ac.uk/comp-sci/images/people/payne_stephen.jpg');

INSERT INTO `seminar` VALUES (475,'2010-05-04','14:00','Robert Recorde Room','Mounia Lalmas','http://www.dcs.gla.ac.uk/~mounia/','University of Glasgow','http://www.dcs.gla.ac.uk/','Understanding Aggregated Search','The diversity and complexity of contents available on the web have dramatically increased in recent years. Multimedia content such as images, videos, maps, voice recordings has been published more often than before. Document genres have also been diversified, for instance, news, blogs, FAQs, wiki. These diversified information sources are often dealt with in a separated way in search results. In general, users have to switch search “domains” to access different sources. Recently, there has been a growing interest in finding effective ways to aggregate these information sources in a unified fashion. So-called aggregated search investigated by the like of Yahoo! (Alpha Yahoo!) and Google (Universal Search) are providing search results from several sources in a single result page. Such growth in the diversity of information on the web suggests investigating three important research questions. Firstly, do users actually access various types of documents to satisfy their information need? Secondly, if this is the case, are there particular patterns in how users access these various types of documents? Finally, how does the presentation of information sources influence the information seeking behavior of users? In this talk, I will report various results regarding these three research questions.\r\n\r\nThis work is being carried out in collaboration with Shanu Sushmita, Hideo Joho, and Benjamin Piwowarski from the University of Glasgow.\r\n\r\nBiography:\r\nProfessor Mounia Lalmas holds a Microsoft Research/RAEng Research Chair at the Department of Computing Science, University of Glasgow. Before that, she was Professor of Information Retrieval, at the department of Computer Science at Queen Mary, University of London, which she joined in 1999 as a lecturer. She is a Chartered IT Professional (CITP) and a Fellow of the British Computer Society (FBCS). She was also the (elected) vice chair, and before this the Information Director of ACM SIGIR. She is an editorial board member for ACM TOIS, IR (Springer) and IP&M (Elsevier). Her research focuses on the development and evaluation of intelligent access to interactive heterogeneous and complex information repositories, and covering a wide range of domains such as HTML, XML, and MPEG-7. From 2002 until 2007, she co-led with Norbert Fuhr the Evaluation Initiative for XML Retrieval (INEX), a large-scale project with over 80 participating organizations worldwide, which was responsible for defining the nature of XML retrieval, and how it should be evaluated. She is now working on technologies for aggregated search and bridging the digital divide. She is also currently getting back into theoretical information retrieval where she is looking at the use of quantum theory to model interactive information retrieval. She is/was the workshop co-chair at SIGIR 2004 and 2006, mentoring chair at SIGIR 2009, PR (co-) chair at CIKM 2008 and WI/IAT 2009, workshop chair at CIKM 2010, PC chair at ECIR 2006 (European Conference on Information Retrieval Research), vice co-chair for the XML and Web Data track at WWW 2009, and general co-chair of IIiX 2008 (Information Interaction in Context) and ECDL 2010 (European Conference on Digital Libraries).',1,'http://www.dcs.gla.ac.uk/~mounia/images/mounia_lalmas_1.jpg');

INSERT INTO `seminar` VALUES (470,'2010-03-09','14:00','Robert Recorde Room','Mila Majster-Cederbaum','http://www.verwaltung.uni-mannheim.de/i3v/index.html?00000700/00097391.htm','University of Mannheim','http://www.uni-mannheim.de/1/startseite/index.html','Analysis of Component Systems','In this talk we discuss approaches to analyse component based systems. We do so in the framework of interaction systems, a generic model for component systems proposed by Joseph Sifakis and Gregor Goessler which strictly separates local behaviour from communication/cooperation. We have shown that deciding properties of component based systems such as deadlock-freedom or liveness of components is PSPACE-hard. We devised several strategies to overcome this complexity problem which we will present in the talk. One approach is to develop sufficient conditions for important properties, that can be tested in polynomial time. Other approaches are e.g. to restrict the architecture of the system or to work with an overapproximation of the global state space that is obtained by exploiting the interaction scheme of the system. Generally \r\nspeaking the  approaches attempt to derive global properties from the inspection of subsystems.',1,'');

INSERT INTO `seminar` VALUES (479,'2010-03-04','14:00','Video conferencing room - Far 134','Ulrich Berger','http://www.cs.swansea.ac.uk/~csulrich/','Swansea University','','Program Extraction From Proofs: Induction and Coinduction','In this talk I give two examples of program extraction from proofs in a constructive theory of inductive and coinductive definitions. The first belongs to the realm of computable analysis. A coinductive predicate C0 is defined characterising those real numbers that are constructively \"approximable\". From proofs of closure properties of C0 one extract implementations of arithmetic operations with respect to the signed digit representation of real numbers. In the second example I show how to extract monadic parser combinators (Hutton and Meijer) from proofs that certain labelled transition systems are finitely branching. While in the first example coinduction is central, here induction features prominently because finiteness is an inductive concept. Both examples have in common that the data types the extracted programs operate on (infinite digit streams, higher-order functions) are not present in the (source) proofs which reside in simple extensions of first-order logic. This indicates that the perspective of replacing programming by the activity of proving is not as daunting as it seems, and that therefore program extraction might become an attractive method for producing formally certified programs in the future. ',2,'');

INSERT INTO `seminar` VALUES (476,'2010-03-11','14:00','Far-134 (Video Conferencing Room)','Nathan Bowler','','Cambridge','','Joint talk with Bath University: Multicategories as a tool for building categories of games  ','There is a well-established intuitive construction of categories of games. I''ll give an example of such a category (based on bicoloured digraphs) which allows the incorporation of some of the structure of the theory of hypergraph games, and I''ll explain how this construction points to the language  of fc-multicategories as a natural setting for the development of additional structure in categories of games. This language also provides a new setting for the construction of existing categories of games. I''ll illustrate how the constructions in this setting have a modular form, cleanly separating different aspects of the underlying combinatorics, and I''ll sketch some possible applications to the development of new constructions.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (480,'2010-03-18','14:00','Video Conferencing Room - Far-134','Nguyen Van Tang','','AIST Japan','','A Hybrid Approach to Verify A Train Fare Calculation System Using Testing and Theorem Proving. ','In this talk, I will present our work on verification of a large-scale software system (Japanese train fare calculation system) in practice. This is a collaborative research project between AIST/CVS and a company. I will briefly present our main formal verification techniques to verify the system, such as VDM (Vienna Development Method) specification\r\nlanguages + Agda (a functional programming languages and theorem prover). ',2,'');

INSERT INTO `seminar` VALUES (481,'2010-04-13','14:00','Board Room','Thomas Strahm','http://www.iam.unibe.ch/~strahm/','Bern','http://www.iam.unibe.ch/en','Two unfoldings of finitist arithmetic','The concept of the (full) unfolding U(S) of a schematic system S is used to answer the following question: Which operations and predicates, and which principles concerning them, ought to be accepted if one has accepted S? The program to determine U(S) for various systems S of foundational significance was previously carried out for a system of non-finitist arithmetic, NFA; it was shown that U(NFA) is proof-theoretically equivalent to predicative analysis. After a general introduction and explanation of previous results, the main emphasis of this talk is to discuss the unfolding notions for a basic  schematic system of finitist arithmetic, FA, and for an extension of that by a form BR of the so-called Bar Rule. It is shown that U(FA) and U(FA + BR) are proof-theoretically equivalent, respectively, to Primitive Recursive Arithmetic, PRA, and to Peano Arithmetic, PA.\r\n\r\n(joint work with S. Feferman, Stanford University)\r\n\r\nAn extended abstract with references can be found here:\r\nhttp://www.iam.unibe.ch/~strahm/Abstract_FS_UnfoldFA.pdf\r\n',2,'');

INSERT INTO `seminar` VALUES (483,'2010-04-15','11:00-17:00','Board Room','Research Meeting with Makoto Takeyama and Kinoshita Yoshiki, AIST Japan','','','','','',2,'');

INSERT INTO `seminar` VALUES (477,'2010-04-20','14:00','Robert Recorde Room','Mark Nixon','http://www.ecs.soton.ac.uk/~msn','University of Southampton','','Gait and Semantic Biometrics','My talk will be phrased around the use of semantics in gait biometrics. As a biometric, gait concerns recognising people by the way they walk. As an application in computer vision, features are derived from sequences of images which can be used to recognise the walking subjects. I shall briefly describe the background to this work, the range of approaches and illustrate the progress in this new biometric. \r\n\r\nWithin this programme we have  developing new approaches which use semantic concepts to reinforce conventional measures for pattern recognition. This has been deployed in biometrics, to improve recognition. Essentially, we augment biometric measures using measures derived largely by human intelligence. Using semantic descriptions is consistent with surveillance: for gait biometrics the semantic labels are those by which subjects are described orally. These concepts need to be labelled manually, so there are psychological considerations to be made, and there are many themes to the processing of this new data common with those in pattern recognition, including: feature set selection; classification; storage; fusion; potency; and efficacy.\r\n\r\nWe will show that by developing these semantic concepts, we can augment the feature vectors so as to improve recognition capability on standard datasets recognition capability by gait Further, we have shown how semantic concepts can be learned from the data, thus allowing object/ subject retrieval, as well as to enhance performance analysis. Further, this can relieve the manual labelling process. We show that humans can be retrieved from video recordings using descriptions notional characteristics, such as age and appearance, which is consistent with biometric search of surveillance material. We shall also describe how the \r\nparameters can be learned from the data, so as to mediate the recognition process. \r\n\r\nThe talk is an extended version of the invited talk at IEEE BCC/ BiDS 2009 http://biometrics.org/bc2009/bios/nixon_m.pdf.',1,'');

INSERT INTO `seminar` VALUES (484,'2010-04-20','14:00','Board Room','Marcin Jurdzinski','http://www.dcs.warwick.ac.uk/~mju/','Warwick University','http://www.dcs.warwick.ac.uk/','Lemke''s algorithm for discounted games','The performance of a pivoting algorithm due to Lemke is considered on linear complementarity problems (LCPs) that arise from discounted games.  The algorithm has not been previously studied in the context of infinite games, and it offers an alternative to the classical strategy-improvement algorithms.  The algorithm is described purely in terms of discounted games, thus bypassing the reduction from the games to LCPs, and hence facilitating a better understanding of the algorithm when applied to games.  A family of discounted games is given on which the algorithm runs in exponential time, indicating that in the worst case it performs no better for discounted games than it does for general P-matrix LCPs.',2,'');

INSERT INTO `seminar` VALUES (482,'2010-05-06','14:15','Video Conferencing Room - Far-134','Oliver Kullmann','http://www.cs.swan.ac.uk/~csoliver/','Swansea','','Exact Ramsey theory: Green-Tao numbers and SAT','The field of Ramsey theory offers great opportunities for improving our understanding of solving hard combinatorial instances: \r\nTry solving the problem instances arising when computing (concrete) Ramsey-type numbers, and understand/improve what''s happening.\r\n\r\nVan der Waerden numbers are obtained when seeking the smallest n such that partitioning the first n numbers into a given number of parts is guaranteed to contain an arithmetic progression of a given length in some part. We have introduced <i>Green-Tao numbers</i>, defined analogously to van der Waerden numbers, but using the first n prime numbers instead of the first n natural numbers. The existence of these numbers is guaranteed by the celebrated Green-Tao theorem (which runs under the slogan ``there are arithmetic progressions of arbitrary size in the primes''''). \r\nIn my talk I want to report on our first findings regarding these Green-Tao numbers.\r\n\r\nThis talk should be accessible by \"everybody\". \r\n\r\nSee <a href=''http://arxiv.org/abs/1004.0653v2''>http://arxiv.org/abs/1004.0653v2</a> for the underlying report.',2,'');

INSERT INTO `seminar` VALUES (485,'2010-05-27','14:00','Video Conferencing Room - Far-134','Dirk Pattinson','http://www.doc.ic.ac.uk/~dirk/','Imperial College','http://www3.imperial.ac.uk/computing/','Global Caching for Coalgebraic Description Logics','Coalgebraic description logics offer a common semantic umbrella for extensions of description logics with reasoning principles outside relational semantics, e.g. quantitative uncertainty, non-monotonic conditionals, or coalitional power. Specifically, we work in coalgebraic logic with global assumptions (i.e. a general TBox), nominals, and satisfaction operators, and prove soundness and completeness of an associated tableau algorithm of optimal complexity EXPTIME. The algorithm is based on global caching, which raises hopes of practically feasible implementation. Instantiation of this result to concrete logics yields new algorithms in all cases including standard relational hybrid logic.\r\n\r\nIn the talk, I will introduce the logics and the reasoning systems in a light-weight way by means of a running example, which will help to highlight the crucial features of the new algorithms.\r\n\r\nThis is joint work with Rajeev Gore (ANU), Clemens Kupke (Imperial) and Lutz Schroeder (DFKI Bremen).',2,'');

INSERT INTO `seminar` VALUES (467,'2010-05-20','14:00','Video Conferencing Room - Far-134','Anton Setzer','http://www.cs.swan.ac.uk/~csetzer/','Swansea','','Combining Automated and Interactive Theorem Proving in Agda','(Joint work with Karim Kanso)\r\n\r\nWe give an introduction into the theorem prover Agda. Then we show how to integrate automated theorem proving into the interactive theorem prover Agda. This is done by introducing a check function for a certain class of formulas in Agda and showing that this function returns true iff the corresponding formula holds. This way one can prove all true formulas of this class of formulas by applying this correctness proof to the trivial proof that the check function returns true. The check function will be defined in such a way that it is as simple as possible and that the correctness proof is simple. Now this check function is replaced by a builtin check function, which calls an automated theorem proving tool. We now obtain that if the automated theorem proving tool returns true, then we obtain a proof of the corresponding formula in Agda, which can be used for carrying out further proofs in Agda.\r\n\r\nWe illustrate this technique in case of a simple SAT solver.',2,'');

INSERT INTO `seminar` VALUES (486,'2010-06-03','14:00','Robert Recorde Room','Markus Hoeferlin and Benjamin Hoeferlin','','Stuttgart University','','Search-based interface for video visualization','TBA',1,'');

INSERT INTO `seminar` VALUES (488,'2010-07-22','14:00','Robert Recorde Room','Cesare Tinelli','http://www.cs.uiowa.edu/~tinelli/','University of Iowa','http://www.cs.uiowa.edu/','SMT-based model checking of data flow programs ','Data flow languages are high level programming languages commonly used in industry to model and implement reactive embedded systems controlling a vast variety of devices.\r\n\r\nWe present a general approach for proving automatically safety properties of data flow programs. The approach extends and combines Model Checking with Satisfiability Modulo Theories (SMT) techniques. In it, a given program and property are first translated into formulas belonging to a decidable fragment of first-order logic that includes the combined theory of the programs data types -- such as integers, reals, Booleans and so on. Then the property is proved by induction over the length of program executions using as reasoning engine an SMT solver specialized on that theory.\r\n\r\nDistinguishing features of this approach are that it scales better than approaches based on propositional reasoning, and it can check safety properties of infinite-state data flow programs as well as finite-state ones. This talk will provide a high level description of the basic approach and its main enhancements as applied to the data flow language Lustre, together with comparative experimental results providing evidence of its effectiveness. ',2,'');

INSERT INTO `seminar` VALUES (487,'2010-07-01','14:00','Video Conferencing Room - Far-134','Jim Laird','http://www.cs.bath.ac.uk/~jl317/','Bath','http://www.bath.ac.uk/comp-sci/','Game Semantics for a Generic Programming Language','I''ll describe a new approach to giving games models of programming languages with higher-rank polymorphism. It is based on using question and answer labelling to represent \"copycat links\" between quantified type variables. The resulting model of System F types is quite concrete --- it is effectively presentable, opening the possibility of extending existing model checking techniques to polymorphic types, for example.  It is also a novel example of a  model of System F with the genericity property.\r\n\r\nBy adding locally declared  general references, we obtain a model of a language in which polymorphic objects may be naturally represented. We prove definability of finite elements, and thus a full abstraction result, using a decomposition argument.  This also establishes that terms may be approximated up to observational equivalence when instantiation is restricted to tuples of type variables.\r\n',2,'');

INSERT INTO `seminar` VALUES (489,'2010-11-30','14:00','Robert Recorde Room','Alexei Iliasov','','Newcastle','','Modularisation in Event-B','The talk will present a novel composition/decomposition approach developed for the Event-B method. It is based on introducing the concepts of modules and module interfaces, and relies on machine decomposition using the intuitive operation call metaphor. The talk will describe the motivations for introducing the approach and demonstrate its soundness. We will introduce the modularisation plugin supporting modularisation within the Rodin Toolkit and show a brief demo. Some common patterns of model structuring will be discussed and illustrated with a case study. We will report on a substantial development of an industrial midium-scale application from the aerospace domain, in which the modularisation approach has been extensively used. This work is a result of collaboration between Newcastle University, Abo Akademy and Space Systems Finland within the ICT DEPLOY Integrated Project. More information can be found at http://wiki.event-b.org/index.php/Modularisation_Plug-in.',1,'');

INSERT INTO `seminar` VALUES (490,'2010-10-12','14:00','Robert Recorde Room','Joyce Lewis','http://www.ecs.soton.ac.uk/people/jkl2','University of Southampton','http://www.ecs.soton.ac.uk/','Living the Brand, or Branding the Community?','This presentation is about giving people the information to make the right choice. Not only do we want students to make the right choice when choosing a university department, we want to shape their choice at each stage of their engagement with us. But the process doesn''t just begin when we engage with prospective students, staff, or partners, it exists at a much deeper level of our own community, with implications for our own sense of identity as a department or institution. Although marketing is now big business in universities, the potential for effecting change at a departmental level, even with limited resources, is still exciting. Furthermore, as students and parents gain increasing access to external information that will also influence their choices, it''s important to remain in control of how that information will be understood. Topics covered in this talk include branding and messaging, brand-building, trust, community, relationship-building, new media v. traditional communications channels, outreach and business partnerships.',1,'http://www.ecs.soton.ac.uk/image.php?id=person_6219&maxw=250&maxh=300&corners=0&edge=1&checksum=9fa8d3e8ec8698e971fdaf23840b2375');

INSERT INTO `seminar` VALUES (491,'2010-08-05','14:00','Robert Recorde Room','Sylvain Dailler ','','Lyon, currently Internship Swansea','','Program extraction using real arithmetic in Coq. ','At first, I will present the Coq proof assistant (http://coq.inria.fr) and give a small interactive tutorial about how to prove theorems and extract programs using Coq.  Then, I will show how to create certified programs only relying on the axioms of real arithmetic. This can be done with easy specifications and without having to construct a huge set of functions and theorems.  As an example, we used our framework to define: unary natural numbers, binary natural numbers, a redundant version of rational numbers and a coinductive characterisation of real numbers that have a signed digit representation.\r\n',2,'');

INSERT INTO `seminar` VALUES (493,'2010-08-12','14:00','Robert Recorde Room','Syllvain Dailler','','Lyon, currently Internship Swansea','','Program extraction using real arithmetic in Coq (Part II)','At first, I will present the Coq proof assistant (http://coq.inria.fr) and give a small interactive tutorial about how to prove theorems and extract programs using Coq. Then, I will show how to create certified programs only relying on the axioms of real arithmetic. This can be done with easy specifications and without having to construct a huge set of functions and theorems. As an example, we used our framework to define: unary natural numbers, binary natural numbers, a redundant version of rational numbers and a coinductive characterisation of real numbers that have a signed digit representation.\r\n',2,'');

INSERT INTO `seminar` VALUES (494,'2010-10-19','14:00','Robert Recorde Room','Luke Ong','http://users.comlab.ox.ac.uk/luke.ong/','Oxford','http://www.comlab.ox.ac.uk/','Recursion schemes and the model checking of higher-order functional programs','Recursion schemes are in essence the simply-typed lambda calculus with\r\nrecursion, generated from uninterpreted first-order symbols.  An old\r\nmodel of computation much studied in the 70''s, there has been a\r\nrevival of interest in recursion schemes as generators of rich\r\ninfinite structures (such as infinite trees) for modelling\r\nhigher-order computation. In this talk we will survey recent proofs of\r\nthe decidability of monadic second order theories of these structures,\r\ndiscuss implementations of these algorithms, and applications to the\r\nmodel checking of higher-order functional programs.\r\n',1,'');

INSERT INTO `seminar` VALUES (496,'2010-10-14','14:00','Far-134 (Video Conferencing Room)','Pierre Clairambault','http://www.pps.jussieu.fr/~pclairam/','University of Bath','http://www.bath.ac.uk/comp-sci/','The Biequivalence of Locally Cartesian Closed Categories and Martin-L&ouml;f Type Theory with Pi, Sigma, and Extensional Identity Types','(Joint work with Peter Dybjer)\r\n\r\nIn his paper Locally cartesian closed categories and type theory (1984), Robert Seely presented a proof that the category <b>LCC</b> of locally cartesian closed categories and the category <b>ML</b> of syntactically presented Martin-L&ouml;f type theories (with Pi, Sigma, and extensional identity types) are equivalent. However, Seely''s proof relies on the problematic assumption that substitution in types can be interpreted by pullbacks in categories. In his paper \"Substitution up to isomorphism\" Curien (1993) shows that Seely''s problem is essentially a coherence problem and proposed how to solve this problem using cut-elimination. An alternative interpretation was then proposed by Hofmann (1994) based on a method due to Benabou. However, neither Curien nor Hofmann showed that their respective interpretations lead to an equivalence between <b>LCC</b> and <b>ML</b>. In this paper we show that Hofmann''s interpretation functor gives rise to a biequivalence of 2-categories, and claim that this is the appropriate formulation of Seely''s theorem. We replace <b>ML</b> with a categorical analogue <b>CWFLCC</b> of categories with families (with extensional identity types, and Sigma and Pi-types) which are democratic in the sense that each context is represented by a closed type.  Most of the difficulty of this proof already appears when relating categories with finite limits (without assuming local cartesian closure) and categories with families without Pi-types. We therefore present this biequivalence (of the 2-categories <b>FL</b> and <b>CWFFL</b>) separately.\r\n',2,'http://www.pps.jussieu.fr/~pclairam/photo.jpg');

INSERT INTO `seminar` VALUES (497,'2010-10-28','14:00','Board Room','John Power','','Bath University','','Coalgebraic Semantics for Parallel Derivation Strategies in Logic Programming','Logic Programming consists of a class of programming languages based on first-order logic, with simple and efficient tools for goal-oriented proof search. We start by making the simplifying assumption that all logic programs are ground, which is essentially as traditional denotational semantics for logic programming does. We give coalgebraic semantics for ground logic programs in terms of P_fP_f-coalgebras and in terms of ListList-coalgebras on Set. The cofree comonads on these endofunctors yield the and-or parallel trees generated by a logic program, with trees being understood either combinatorially or as embedded in the plane respectively. We then extend the analysis to arbitrary logic programs, with substitution on terms modelled by a Lawvere theory and substitution on formulae modelled by a lax natural transformation between Poset-valued functors. ',2,'');

INSERT INTO `seminar` VALUES (499,'2010-11-25','','','No talk. Level 1 Away day','','','','','',2,'');

INSERT INTO `seminar` VALUES (501,'2010-12-14','14:00','Robert Recorde Room','Shaun Lawson','http://www.lincoln.ac.uk/socs/staff/1688.asp','University of Lincoln','http://www.lincoln.ac.uk/','Big Society Computing - the potential of using interactive systems to change behaviour','This talk describes research being conducted at the Lincoln Social\r\nComputing (LiSC) Research Centre which is exploring how it might be\r\npossible to use interactive applications delivered via online social\r\nnetworks, such as Facebook, to raise awareness and change behaviour.\r\nSince using OSNs gives us hitherto unachievable insight in to what our\r\nfriends collectively think and do it is possible to use digital\r\nplatforms such as Facebook to deliver behaviour change interventions\r\nbased on social norms and peer pressure. Such an approach lies in the\r\nemerging area of persuasive technology and further exploits ideas\r\nrecently popularized by Thaler and Sunstein in that individuals can be\r\n''nudged'' to make better health and lifestyle decisions given the right\r\ninformation and the environment in which to do so. Research at LiSC has\r\nso far concentrated on domestic energy usage and personal activity\r\nmonitoring though we are also currently working on food and waste\r\nbehaviour, energy usage in corporate settings and mental health issues.\r\nThe talk will give an overview of the approach taken in each of these\r\nareas, the findings to to-date, and what the future might hold for such\r\na strand of ''big society'' computing.\r\n\r\nDr Shaun Lawson is a Reader in the School of Computer Science at the\r\nUniversity of Lincoln and Director of the Lincoln Social Computing\r\n(LiSC) Research Centre. His research is focussed on the understanding of\r\nhow, and why, people use and engage with social media, social games and\r\nother online and mobile applications. A particular focus his work is\r\nexploring how such social technologies can be used for serious purposes\r\nas well as entertainment. For instance, online communities connected\r\nthrough platforms such as Facebook have enormous untapped potential as\r\nplatforms to raise awareness and transform behaviour across many health,\r\nsustainability and lifestyle issues in a today''s digital society. See\r\nhttp://lisc.lincoln.ac.uk for details.',1,'http://www.lincoln.ac.uk/socs/staff_profile/shaun.jpg');

INSERT INTO `seminar` VALUES (502,'2010-12-07','14:00','Robert Recorde Room','Reyer Zwiggelaar','','Aberystwyth University','http://www.aber.ac.uk/','Topological Data Analysis','I will present work related to connected components in medical images and related feature spaces, which has been used for the detection and classification of micro-calcifications and texture based segmentation. This work lead to the development of manifold learning techniques and I will describe the details of our parallel projections approach.',1,'');

INSERT INTO `seminar` VALUES (503,'2010-11-02','14:00','Robert Recorde Room','Jan Kautz','http://www.cs.ucl.ac.uk/staff/j.kautz/','University College London','http://www.cs.ucl.ac.uk','Realistic, Real-Time Shading','The creation of images that are indistinguishable from photographs is a long-standing problem in computer graphics. Current methods can take minutes or even hours to produce a single realistic image. Yet, there are many applications, such as architectural walkthroughs and flight-simulators, for which real-time image synthesis is necessary. Existing solutions sacrifice image quality in order to meet time constraints; for instance, by using only point lights that cast hard and unrealistic shadows or by completely ignoring indirect illumination. I will present techniques that address these problems. First, I will introduce Convolution Shadow Maps, which enable the use of natural lighting to cast realistic, soft shadows. Second, I will present Imperfect Shadow Maps as well as Microrendering, novel rendering techniques that add realistic indirect illumination, including color bleeding and indirect shadows. Both techniques are very efficient and support fully dynamic scenes as no precomputation is required.',1,'');

INSERT INTO `seminar` VALUES (492,'2010-10-26','14:00','Robert Recorde Room','Vladimir Sazonov','http://www.csc.liv.ac.uk/~sazonov/','Liverpool','','On the extensional ordering of the sequential functionals','We will discuss the nature of the extensional ordering on structure Q_\\sigma\r\nof the hereditarily sequential functionals of finite types.\r\nIt was shown by Dag Normann that it is non-dcpo.\r\n\r\nOn the other hand, it still has good domain theoretical properties if to generalise Scott domains\r\nto so called natural domains.\r\n\r\nFrom the traditional domain theoretic point of view, it is not only non-dcpo, but the posets\r\nof sequential functionals and finite sequential functionals have anomalies which we\r\n(in a joint work with Dag Normann) characterised with a focus on:\r\n\r\n* when the sequential functionals of a given type form a directed complete partial ordering (dcpo),\r\n\r\n* and when a finite sequential functional will be the nontrivial least upper bound of an infinite chain\r\nof sequential functionals.\r\n',1,'');

INSERT INTO `seminar` VALUES (498,'2010-11-11','14:00','Far-134 (Video Conferencing Room)','Chris Broadbent','','Oxford','http://www.comlab.ox.ac.uk/','Collapsible Pushdown Graphs and First-Order Logic -- Navigating the fringe of decidability','A higher-order pushdown automaton (HOPDA) generalises the standard notion of pushdown automaton (order-1) by allowing its stack to consist of nested stacks of stacks... of stacks rather than just the usual pile of atomic alphabet symbols. A collapsible pushdown automaton (CPDA) generalises this further by attaching `links'' between different components of the higher-order stack. The interest in the latter derives from the fact that CPDA can generate precisely the same set of trees as so-called `higher-order recursion schemes'', which are systems of rewrite rules with applications to the modelling and hence verification of higher-order functional programs.\r\n\r\nWhilst the configuration graphs of HOPDA all have a decidable MSO (monadic second-order) theory, this is not the case for the configuration graphs of CPDA. Indeed, even at order-2 one can construct a graph with an undecidable MSO theory. This raises the question as to how first-order logic fares with CPDA. In a recent breakthrough, Kartzow\r\nhas shown that the configuration graphs of order-2 CPDA have decidable first-order theory -- indeed they are `tree automatic'' (the graphs can be represented using finite tree automata recognising the nodes and pairs of nodes bearing edges).\r\n\r\nDisappointingly, and a little surprisingly, we have a plethora of undecidability results that show such a result does not hold at order-3 and above. However, under certain restrictions we can recover interesting decidability results and the act of doing so introduces some novel apparatus in the form of `nested-tree automatic structures''.  \r\n\r\nIn this talk I will endeavour to explain some of the background to this work and briefly outline the way in which these results have been obtained. This is work reasonably progressed but nevertheless still in progress!',2,'');

INSERT INTO `seminar` VALUES (507,'2010-11-04','14:00','Robert Recorde Room','No talk due to 9th Wessex Theory Seminar','','','','','',2,'');

INSERT INTO `seminar` VALUES (508,'2010-11-23','14:00','Robert Recorde Room','Paulo Oliva','','Queen Mary','','The Theory of Selection Functions','Very Short Abstract: We call a \"quantifier\" any operator of type (X -> R) -> R, and a \"selection function\" any operator of type (X -> R) -> X. In this talk I will give some basic definitions and results concerning quantifiers and selection functions, and explain why these are interesting objects to study.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (509,'2010-12-02','9am - 3pm','Board Room','Model checking workshop ','','','','','',2,'');

INSERT INTO `seminar` VALUES (513,'2011-03-01','14:00','Robert Recorde Room','Sam Buss','http://www.math.ucsd.edu/~sbuss/','UCSD','http://math.ucsd.edu/','Time-Space Tradeoffs and Lower Bounds for Satisfiability','A series of results by several authors in recent years have given alternation-trading proofs that Satisfiability is not in the simultaneous time- and space-bounded class $\\DTISP(n^c,n^\\epsilon)$ for various values $c<2$ and $\\epsilon<1$.  In this talk, we characterize exactly what can be proved in the $\\epsilon=0$ case with currently known methods, and prove the earlier conjecture of Ryan Williams that $c=2\\cos(\\pi/7)$ is optimal for this.\r\n\r\nWe also give a new a theoretical and computational analysis of alternation-trading proofs for $0<\\epsilon<1$.  This both gives new lower bounds on the computational complexity of Satisfiability, and establishes precise numeric limits on what lower bounds can be proved with currently known alternation-trading techniques.\r\n\r\nThis is joint work with Ryan Williams.',1,'');

INSERT INTO `seminar` VALUES (500,'2010-12-09','14:00','Far-134 (Video Conferencing Room)','Alessio Guglielmi','http://alessio.guglielmi.name/','University of Bath','http://www.bath.ac.uk/comp-sci/','Removing Syntax from Proof Theory','In the area of proof complexity we can say much about proofs without worrying about their representation. For example:\r\n<ul><li>The notion of proof system is remarkably non-syntactic: a proof system is any algorithm that checks proofs in polynomial time.</li>\r\n<li>The class of Frege propositional systems is robust: they all are polynomially equivalent, independently of the base of connectives and the choice of inference rules.</li></ul>On the contrary, in proof theory, we find that proof properties are defined syntactically. A notable example is analyticity, or cut-freeness, and the associated notion of cut elimination.\r\n\r\nWe could argue that if a notion is syntactic, i.e., only defined in terms of a (possibly elaborate) representation, then it is poorly understood. However, are analyticity and cut elimination eminently syntactic constructions, or is there some underlying natural phenomenon?\r\n\r\nIn this talk, I argue in favour of the latter, by providing evidence that what we observe in several syntactic settings has a deeper and simpler geometric nature. For example, cut-elimination in propositional logic can be achieved with purely topological means, without any reference to logic. I will also give an idea of a wider effort, based on the newly found geometric methods, aimed at better integrating proof complexity and proof theory, by removing unnecessary syntax.\r\n\r\nThe talk is based on three recent papers:\r\n\r\nA. Guglielmi, T. Gundersen and L. Strassburger. Breaking Paths in Atomic Flows for Classical Logic. LICS 2010. <a href=''http://www.lix.polytechnique.fr/~lutz/papers/AFII.pdf''>http://www.lix.polytechnique.fr/~lutz/papers/AFII.pdf</a>.\r\n\r\nA. Guglielmi, T. Gundersen and M. Parigot. A Proof Calculus Which Reduces Syntactic Bureaucracy. RTA 2010. <a href=''http://drops.dagstuhl.de/opus/volltexte/2010/2649''>http://drops.dagstuhl.de/opus/volltexte/2010/2649</a>.\r\n\r\nP. Bruscoli, A. Guglielmi, T. Gundersen and M. Parigot. A Quasipolynomial Cut-Elimination Procedure in Deep Inference via Atomic Flows and Threshold Formulae. LPAR-16 2010. <a href=''http://cs.bath.ac.uk/ag/p/QPNDI.pdf''>http://cs.bath.ac.uk/ag/p/QPNDI.pdf</a>.\r\n\r\nJournal versions are available at <a href=''http://alessio.guglielmi.name/res/cos/''>http://alessio.guglielmi.name/res/cos/</a>. ',2,'');

INSERT INTO `seminar` VALUES (515,'2011-02-15','14:00','Robert Recorde Room','Min Chen','http://www.cs.swan.ac.uk/~cschenm','Swansea University','http://www.cs.swan.ac.uk','An Information-theoretic Framework for Visualization','This talk is an extended version of the presentation given in VisWeek 2010 on this topic. We examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.',1,'');

INSERT INTO `seminar` VALUES (517,'2011-03-08','14:00','Robert Recorde Room','Steve Maddock','http://staffwww.dcs.shef.ac.uk/people/S.Maddock/','Sheffield University','','Computer facial modelling and animation','Three-dimensional facial animation is an area where modelling and animation are intimately linked and where our familiarity imposes strict judgement criteria. This tension between modelling and animation has always interested me - it was the subject of my PhD thesis awarded in 1999 - and continues to provoke aspects of my work. In this talk I will present two pieces of work conducted at Sheffield on computer facial modelling and animation. On modelling, I will briefly present an approach to producing facial models using sketching. On animation, I will present a viseme-based approach to visual speech that employs a constraint-based interpolation scheme, as well as discussing the wider topic of facial animation.',1,'');

INSERT INTO `seminar` VALUES (520,'2011-05-03','14:00','Robert Recorde Room','Prakash Panangaden','http://www.cs.mcgill.ca/~prakash/','McGill University','http://www.cs.mcgill.ca/','Labelled Markov Processes','Labelled Markov Processes (LMPs) are a combination of traditional labelled\r\ntransition systems and Markov processes.  Discrete versions of such systems\r\nhave been around for a while and were thoroughly explored by Larsen and\r\nSkou in the late 1980s and early 1990s.  Our contribution has been to\r\nextend this study to systems with continuous state spaces.\r\n\r\nThe main technical contribution that I will discuss in this talk is a\r\ndefinition of bisimulation for such systems and a logical characterization\r\nfor bisimulation.  The big surprise is that a very simple modal logic with\r\nno negative constructs or infinitary conjunctions suffices to characterize\r\nbisimulation, even with uncountable branching.  This is quite different\r\nfrom the situation with unquantified nondeterminism nondeterminism.  This\r\nresult was proved in 1998 by Desharnais, Edalat and myself.  Since then the\r\nsubject has been actively developed by several groups including the\r\ndevelopment of a coalgebraic viewpoint culminating by several people\r\nincluding researchers at Indiana.  I will end with a survey of recent\r\ndevelopments involving metrics and approximation techniques.\r\n',1,'');

INSERT INTO `seminar` VALUES (522,'2011-02-24','14:00','Far-134 (Video Conferencing Room)','Martin Churchill','http://people.bath.ac.uk/mdc25/','University of Bath','http://www.bath.ac.uk/comp-sci/','Imperative Programs as Proofs via Game Semantics','Game semantics extends the Curry-Howard isomorphism to a three-way correspondence: proofs, programs, strategies. But the universe of strategies goes beyond intuitionistic logics and lambda calculus, to capture stateful programs. In this talk we describe a logical counterpart to this extension, in which proofs denote such strategies. We can embed intuitionistic first-order linear logic into this system, as well as an imperative total programming language. The logic makes explicit use of the fact that in the game semantics the exponential can be expressed as a final coalgebra. We establish a full completeness theorem for our logic, showing that every bounded strategy is the denotation of a proof.\r\n(Joint work with Jim Laird and Guy McCusker)\r\n',2,'http://people.bath.ac.uk/mdc25/me.jpg');

INSERT INTO `seminar` VALUES (519,'2011-01-17','11:00','Robert Recorde Room','Jan Pich ','','Charles University in Prague','http://www.karlin.mff.cuni.cz/sekce/en_index.php','Nisan-Wigderson generators in proof systems with forms of interpolation ','Razborov conjectured that certain tautologies based on suitable Nisan-Wigderson generators do not have short proofs  in strong propositional proof systems like Extended Frege.  We will discuss the conjecture and prove that tautologies from the conjecture are hard for proof systems that admit feasible interpolation.',2,'');

INSERT INTO `seminar` VALUES (526,'2011-05-05','14:00','Far-134 (Video Conferencing Room)','Matthew Gwynne','http://cs.swan.ac.uk/~csmg','Swansea University','http://cs.swan.ac.uk','On the hardness of (satisfiable) conjunctive normal forms','A new measure h(F ) of “hardness” for formulas F in conjunctive normal form (i.e., clause-sets) is introduced. h(F) for unsatisfiable clause-sets has been studied extensively in [1,2]. However, now we treat satisfiable clause-sets F differently.\r\n\r\nh(F) for satisfiable F as defined in [1,2] has a specific algorithmic viewpoint. It measures resources based on forced assignments and probing, progressing in a breadth-first manner. Now we consider boolean functions and their representations, and our new measure looks at ”complete” representations of the underlying boolean function of F. \r\n\r\nWe present the SAT representation hypothesis: The task of solving or refuting a SAT problem efficiently is captured by constructing a representation of the underlying boolean function which is of low hardness. For large boolean functions, the task becomes then to find good decompositions such that the component functions have low hardness. What it means to be a good decomposition is the next fundamental question.\r\n\r\nWe consider translations of the Advanced Encryption Standard (AES) and Data Encryption Standard (DES) as examples. We provide translations which have low hardness for all sub-functions in natural decompositions. The performance of SAT solvers on these instances is experimentally investigated.\r\n\r\nReferences\r\n[1] Oliver Kullmann. Investigating a general hierarchy of polynomially decidable classes of CNF''s based on short tree-like resolution proofs. Technical Report TR99-041, Electronic Colloquium on Computational Complexity (ECCC), October 1999.\r\n[2] Oliver Kullmann. Upper and lower bounds on the complexity of generalised resolution and generalised constraint satisfaction problems. Annals of Mathematics and Artificial Intelligence, 40(3-4):303–352, March 2004.\r\n',2,'http://cs.swan.ac.uk/~csmg/Files/me-round-small.jpg');

INSERT INTO `seminar` VALUES (527,'2011-05-12','14:00','Far-134 (Video Conferencing Room)','Andy King','http://www.cs.kent.ac.uk/people/staff/amk/','Kent','http://www.cs.kent.ac.uk/','	Automatic Abstraction for Congruences: A Story of Beauty and the Beast','Just when we thought that verification was a dead topic, the subject has bounced back with forums such as Verification, Model Checking and Abstract Interpretation (VMCAI) attracting record numbers of submissions. This is because model checking offers push button bug finding whereas abstract interpretation gives push button invariant discovery. This talk concerns an output of work funded by a Royal Society Industrial Fellowship which focuses on deriving invariants from binaries to support white-hats. It explains how bit-level operations can be automatically transformed into operations over matrices of linear congruence equations. By composing the matrices (something that is beautifully simple), the invariants in the binary then just drop-out, giving a way to discover what a program actually does without even running it (a problem that one would initially think to be an utter beast).',2,'http://www.cs.kent.ac.uk/people/staff/amk/face.jpg');

INSERT INTO `seminar` VALUES (529,'2011-02-10','14:00','Video Conferencing Room - Far134','Berndt Muller','http://staff.glam.ac.uk/users/3918-bmuller','University of Glamorgan','http://fat.glam.ac.uk/','The Model-Checking Problem for Resource-Bounded Logics','The modelling and verification of multi-agent systems has attracted much attention in recent years. The vast majority of the literature neglects resource requirements. However, the availability of resources is essential for the success in achieving many goals. Some logics have been augmented with notions of resources and resource consumption or production. The talk introduces resource-bounded logics and asks the question whether it is possible to retain the decidability of model checking. We investigate the limits of what can be verified about resource-bounded agents by considering several variations and prove that the model-checking problem is usually undecidable, with the exception of bounded or otherwise restrictive models. The results extend previous work on Resource-Bounded Tree Logics RTL and RTL*, based on the well-known Computation Tree Logics CTL and CTL*.',3,'http://staff.glam.ac.uk/system/avatars/3918/medium/IMG_0014.jpg?1295282323');

INSERT INTO `seminar` VALUES (528,'2011-02-10','14:00','Video Conferencing Room - Far 134','Berndt Muller','http://staff.glam.ac.uk/users/3918-bmuller','University of Glamorgan','http://fat.glam.ac.uk/','The Model-Checking Problem for Resource-Bounded Logics','The modelling and verification of multi-agent systems has attracted much attention in recent years. The vast majority of the literature neglects resource requirements. However, the availability of resources is essential for the success in achieving many goals. Some logics have been augmented with notions of resources and resource consumption or production. The talk introduces resource-bounded logics and asks the question whether it is possible to retain the decidability of model checking. We investigate the limits of what can be verified about resource-bounded agents by considering several variations and prove that the model-checking problem is usually undecidable, with the exception of bounded or otherwise restrictive models. The results extend previous work on Resource-Bounded Tree Logics RTL and RTL*, based on the well-known Computation Tree Logics CTL and CTL*.',2,'http://staff.glam.ac.uk/system/avatars/3918/medium/IMG_0014.jpg?1295282323');

INSERT INTO `seminar` VALUES (516,'2011-03-15','14:00','Robert Recorde Room','Oskar Juhlin','http://www.tii.se/node/2126','Interactive Institute','http://www.tii.se/','Design oriented research on the mobile life','I present research which is interdisciplinary, involving researchers from computer science,\r\ninteraction design, sociology, psychology but also game designers, artists, dancers, and fashion experts.\r\nThe Centres competitive edge lies in making serious research on what we might normally portray as\r\n\"unserious\" activities in collaboration with our industry partners Ericsson, Nokia, Microsoft Research\r\nand TeliaSonera. We get inspired by doing studies on people''s mundane leisure and creative activities\r\nsuch as horseback riding, hunting, parcour, dancing or role-playing. We use those insights to spur\r\ninnovative design processes, resulting in mobile applications, sensor-based applications, pervasive\r\ngames, mobile mash-up services, new mobile media, technical platforms and materials to support\r\namateurs'' creativity. The results range from publishing ambitious books on new playful activities, such\r\nas pervasive games and social media on the road, to generating and demonstrating innovative mobile\r\nand leisure oriented applications and finding new methods for design and evaluation.\r\n\r\nCV: Oskar Juhlin is Director at the Mobile Life VinnExcellence Center. He is also at the Mobility Studio at the Interactive Institute, Stockholm, Sweden as well as at the Department of computer and system sciences at Stockholm University. He is Associate Professor (\"Docent\") in applied information technology at the IT-university of G&ouml;teborg. He holds a Ph.D. in sociology of technology at Tema, Department of Technology and Social Change, Link&ouml;ping University.  Oskar has worked in many fields related to the sociology of technology, including sociology of knowledge and engineering work and lately sociology of traffic and road use, related to the design of mobile applications for people on the road. His current approach draws on ethnographic fieldwork of mobile user practices to influence the design of various applications. ',1,'https://www.tii.se/files/systemimages/oskar_juhlin-002.node_page.jpg');

INSERT INTO `seminar` VALUES (533,'2011-03-29','14:00','Robert Recorde Room','Tim Porter','','Bangor','','Changing Spaces','The theme of the talk is how spaces `evolve'', and how that evolution can be modelled.  In particular it will touch on some ideas from topological data analysis, and discuss directed homotopy as applied to aspects of the modelling of distributed computing.',1,'');

INSERT INTO `seminar` VALUES (525,'2011-03-31','14:00','Far-134 (Video Conferencing Room)','Isabel Oitavem','http://www.ptmat.fc.ul.pt/~isarocha/','Lisboa','http://www.dmat.fct.unl.pt/','Recursion-theoretic characterization of FPH','An algorithm working in polynomial space is allowed to reuse space, and if we look at known algorithms for PSPACE-complete problems, they always seem to rely heavily on this possibility. Our intuition then indicates that this is a crucial point concerning the problem PTIME versus PSPACE.  A rigorous formulation of this intuition is the known fact that a \"write-once\" Turing machine, given polynomial space, decides exactly PTIME. \r\nA write-once machine is one which is not allowed to erase (or rewrite) cells which have been previously written on.\r\n\r\nSince the write-once restriction can, in some sense, be seen as a monotonicity constraint on the contents of the storage, this suggests investigating how sensitive characterisations of PSPACE are to \"monotonicity constraints\".\r\n\r\nOne explores, in particular, the interplay between recursion and iteration. We take as starting point a recursion-theoretic characterisation of FPSPACE, and we show that substituting predicative primitive iteration for predicative primitive recursion also leads to FPSPACE. \r\n\r\nWe show that imposing a monotonicity constraint on the above recursion and iteration operators leads, in the case of primitive iteration, to FPTIME, and, in the case of primitive recursion, to the polynomial hierarchy FPH. We form a hierarchy based on the nesting-level of the restricted primitive recursion operator, and this provides a new implicit characterisation of all levels of the polynomial hierarchy.\r\n(joint work with Amir Ben-Amram and Bruno Loff)',2,'');

INSERT INTO `seminar` VALUES (536,'2011-06-14','14:00','Robert Recorde Room','Dines Bjørner','http://www2.imm.dtu.dk/~db/','Technical University of Denmark','http://www.imm.dtu.dk/English.aspx','The Role of Domain Engineering in Software Development: Why Current Requirements Engineering is Flawed !','We introduce the notion of domain descriptions (D) in order to \r\nensure that software (S) is right and is the right software, that \r\nis, that it is correct with respect to written requirements (R) and \r\nthat it meets customer expectations (D).\r\n\r\nThe talk will show some formulas but they are really not meant \r\nto be read by the speaker, let alone understood, during the talk, \r\nby the listeners. They are merely there to bring home the point:\r\nProfessional software engineering, like other professional engin-\r\neering branches rely on and use mathematics.\r\n\r\nAnd  it is all very simple to learn and practise anyway !\r\n\r\nWe end this talk with, to some, perhaps, controversial remarks:\r\nRequirements engineering, as pursued today, researched, taught \r\nand practised, is outdated, is thus fundamentally flawed. We shall \r\njustify this claim.',1,'');

INSERT INTO `seminar` VALUES (534,'2011-03-31','14:45','Far-134 (Video Conferencing Room)','Reinhard Kahle','http://www.mat.uc.pt/~kahle/index.en.html','Lisboa','http://www.di.fct.unl.pt/index_html/not_available_lang?set_language=en&cl=en','An applicative recursion scheme for FPH','Ben-Amram, Loff, and Oitavem introduced a characterization of the functions in the polynomial hierarchy using a monotonicity condition. Based on this characterization, we introduce an applicative theory whose provably total functions are exactly the functions computable in the polynomial hierarchy of time.\r\n\r\n(Joint work with Isabel Oitavem.)',2,'');

INSERT INTO `seminar` VALUES (537,'2011-05-25','12:30','Robert Recorde Room','John K. Tsotsos','http://web.me.com/john.tsotsos/Tsotsos/Home.html','York University, Canada','http://www.cse.yorku.ca/cshome/','Active Visual Search','(INVITED RIVIC GUEST)\r\n\r\nActive perception uses intelligent control strategies applied to the data acquisition process that depend on the current state of data interpretation and has a history that pre-dates computer vision. I will very briefly lay out this history and detail theoretical arguments on the computational nature of the general problem. The theory informs us that optimal solutions are not likely to exist. In this context, I consider the problem of visually finding an object in a mostly unknown space with a mobile robot. It is clear that all possible views and images cannot be examined in a practical system and as a result, this is cast as an optimization problem. The goal is to optimize the probability of finding the target given a fixed cost limit in terms of total number of robotic actions required to find the visual target. Due to the inherent intractability of this problem, we present an approximate solution and  investigate its performance and properties. This has been successfully implemented  on three different robots, the most recent being Honda''s ASIMO and examples of its performance will be shown.\r\n\r\n\r\nIf anyone wishes to see background papers for this, they can look at:\r\n\r\nAndreopoulos, A., Wersing, H., Janssen, H., Hasler, S., Tsotsos, J.K., Körner, E., Active 3D Object Localization using a Humanoid RObot, IEEE Transactions on Robotics, 27(1), p47-64, 2011.\r\n\r\nShubina, K., Tsotsos, J.K.  Visual Search for an Object in a 3D Environment using a Mobile Robot, Computer Vision and Image Understanding, 114, p535-547, 2010.\r\n\r\nYe, Y., Tsotsos, J.K., A Complexity Level Analysis of the Sensor Planning Task for Object Search, Computational Intelligence, 17(4), p605-620, Nov. 2001.\r\n\r\nYe, Y., Tsotsos, J.K., Sensor Planning for Object Search, Computer Vision and Image Understanding 73(2), p145-168, 1999.',1,'');

INSERT INTO `seminar` VALUES (538,'2011-06-15','10:30','Robert Recorde Room','Dines Bjørner','http://www2.imm.dtu.dk/~db/','Technical University of Denmark','http://www.imm.dtu.dk/English.aspx','Towards a calculus of domain description constructors','Domain descriptions are constructed by domain engineers. They apply a\r\n       number of analysis techniques to a domain to arrive at consistent and\r\n       relative complete descriptions. These consists of the definition of\r\n       domain phenomena in the form of sorts, actions, events and behaviours\r\n       as well as of derived concepts of the same four kinds. We view the \r\n       domain description process as a sequence of \"applications\" of a\r\n       small number of these hypothetical \"domain description constructors\"\r\n       on the domain and a repository of a set of domain description\r\n       units. These applications are \"mental\" and yield a set of domain\r\n       description units.\r\n\r\n      In this talk we suggest a number of \"domain description constructors\".\r\n\r\n     The talk reports on work in progress, that is, it is far from\r\n     completed. It is hoped that eventually a calculus will evolve and that\r\n     properties of such a calculus can be proved.',3,'');

INSERT INTO `seminar` VALUES (539,'2011-10-04','14:00','Robert Recorde Room','Professor Ke Chen','http://www.liv.ac.uk/~cmchenke/','Department of Mathematical Science, University of Liverpool','http://www.liv.ac.uk/maths/','Image Segmentation Models and Numerical Solution Methods','Edge detection algorithms were the traditional methods for finding\r\nfeature edges in an image but noise can seriously reduce the effectiveness of \r\nsuch models. More recently, variational segmentation models provide more effective and reliable tools for image \r\nprocessing applications. The Chan-Vese (2001) region based model in two dimensions is widely used.  \r\n\r\nIn this talk, I shall first present some new multigrid algorithms for this model in the three dimensional setting. \r\nThen I show some recent works for the task of selective segmentation\r\nwhere pre-defined geometric constraints guide the segmentation models.\r\nSuch problems are more common in medical imaging than the usual segmentation.\r\nNumerical experiments will demonstrate the advantages of the new new models over existing results. Collaborators related to this work include\r\nNoor Badshah (Peshawar, Pakistan),  Jian-ping Zhang and Bo Yu (Dalian, China) and Lavdie Rada (Liverpool).\r\n',6,'http://www.liv.ac.uk/~cmchenke/Ke_cu.jpg');

INSERT INTO `seminar` VALUES (541,'2011-10-21','14:00','Board Room','Lorenzo Malatesta','','University of Strathclyde, Glasgow','http://www.strath.ac.uk/cis/','Some proposals for the set-theoretic foundation of Category Theory','The problem of finding proper set-theoretic foundations for category theory has challenged mathematicians since the very beginning. In this talk we will survey some of the standard approaches that have been proposed in the past 70 years. By means of the central notions of class and universe we will sketch a possible conceptual recasting of these\r\nproposals.\r\n\r\nWe will focus on the intended semantics for the (problematic) notion of large category in each proposed foundation. Following Feferman, we will give a comparison and evaluation of their expressive power.\r\n',2,'http://local.cis.strath.ac.uk/images/people/13266.png');

INSERT INTO `seminar` VALUES (540,'2011-10-27','14:00','Far-134','Adriana Balan','','University of Bucharest','http://fmi.unibuc.ro/en/','Finitary functors: from Set to Preord','In this talk we shall explain how (finitary) Preord-functors can be obtained from Set-functors. We shall also look at some coalgebraic features of the obtained Preord-functors.',2,'');

INSERT INTO `seminar` VALUES (542,'2011-11-17','14:00','Far-134','Ken Madlener','http://www.cs.ru.nl/~kmadlene/','Radboud University Nijmegen','http://www.cs.ru.nl/','A new view on the robustness of behavioural equations ','Sound behavioural equations may become unsound after conservative extensions of the underlying operational semantics. The preservation of sound equations has been studied by Mosses, Mousavi and Reniers for several notions of bisimilarity. In particular, Formal Hypothesis (FH) bisimilarity, due to Robert de Simone, is preserved by disjoint extensions that do not add labels. In this talk I will revisit this result, but from the point of view of bi-algebraic semantics, due to Turi and Plotkin. In addition, I will present a work-in-progress formalization in the proof assistant Coq. ',2,'http://www.cs.ru.nl/~kmadlene/ken.jpg');

INSERT INTO `seminar` VALUES (545,'2011-12-01','15:00','Board Room','Arnold Beckmann','http://www.cs.swan.ac.uk/~csarnold/','Swansea','http://www.swan.ac.uk/compsci/index.html','Polynomial time computation on sets','Polynomial time computation on finite strings is a central notion in complexity theory. Polynomial time on infinite strings has been considered by several authors in the context of infinite time Turing machines. In this talk we will discuss how polynomial time computation can be defined on sets in general. Our approach is based on the Bellantoni-Cook schemes characterising polynomial time on finite strings in terms of \"safe recursion\". In particular we will analyse what complexity class on finite strings arise under various interpretations of finite strings as sets. For one natural such interpretation the class obtained can be characterised as alternating exponential time with polynomially-many alternations. A similar class has been considered before as the complexity of the theory of the real numbers as an ordered additive group. This is joint work with Sam Buss and Sy Friedman.',2,'http://www.cs.swan.ac.uk/~csarnold/photos/arnold-bwph-kl.jpg');

INSERT INTO `seminar` VALUES (543,'2011-11-24','14:00','Far-134','James Davenport','http://people.bath.ac.uk/masjhd/','Bath','http://www.bath.ac.uk/comp-sci/','Branch cuts and deciding if \"identities\" are true','\"Functions\" such as square root and logarithm are not actually well-defined on the complex plane, being capable of taking on multiple values. The table-maker, or the software library writer, is forced to introduce branch cuts, and sacrifice continuity for uniqueness. Unfortunately, we also sacrifice many identities on the road to uniqueness. Which, where and how do we find out (algorithmically) will be treated in this talk. In particular, why do some remain valid (such as <span style=\"white-space: nowrap\">&radic;<span style=\"text-decoration:overline;\">&nbsp;1-x&sup2;&nbsp;</span></span>=<span style=\"white-space: nowrap\">&radic;<span style=\"text-decoration:overline;\">&nbsp;1-x&nbsp;</span></span><span style=\"white-space: nowrap\">&radic;<span style=\"text-decoration:overline;\">&nbsp;1+x&nbsp;</span></span>), but others do not (such as <span style=\"white-space: nowrap\">&radic;<span style=\"text-decoration:overline;\">&nbsp;x&sup2;-1&nbsp;</span></span>=<span style=\"white-space: nowrap\">&radic;<span style=\"text-decoration:overline;\">&nbsp;x-1&nbsp;</span></span><span style=\"white-space: nowrap\">&radic;<span style=\"text-decoration:overline;\">&nbsp;x+1&nbsp;</span></span>)?',2,'');

INSERT INTO `seminar` VALUES (546,'2011-12-15','15:00','Robert Recorde Room','Max Wilson (+ Sorin Dinu, Horia Maior, Thomas Chamberlain, and Matthew Pike)','http://www.cs.swan.ac.uk/~csmax/','Swansea','http://www.cs.swan.ac.uk/','The ACM ICPC NWERC competition','This presentation will give an overview of the ACM International Collegiate Programming Competition - our participation in the regionals (NWERC), and how Swansea prepared, performed, and compared.\r\n\r\nWe''ll also go over the kinds of questions - the solutions to them (which involve optimised algorithms, and even 2SAT in one example). \r\n',2,'http://www.swan.ac.uk/media/Swansea-University-IMG_4197.jpg');

INSERT INTO `seminar` VALUES (549,'2012-03-01','14:00','Robert Recorde Room','Kathy Gray','http://cs.swan.ac.uk/~cskeg/','Swansea','','Semantics of a DNA Strand Displacement Model ','DNA strand displacement techniques have significant promise in the fields of medicine, bioengineering, and other biological sciences. Additionally, DNA strands can be used to create biological circuits (as opposed to digital circuits) including standard boolean logic gates, and Turing machines. However a major challenge in the construction of devices comprised of DNA has been to enable sound automated analysis of high-level designs for complex structures. \r\n\r\nIn collaboration with the MSR Biology research group, we have been addressing these problems with a programming language and modeling tool to specify DNA circuits, simulate their chemical reactions, and analyze the designs. This talk presents the operational semantics for our language, which models the chemical reactions involved in DNA strand displacement circuits. We will begin with the basic reductions and structures, as well as present new techniques for encoding modularity and scalability. \r\n\r\nNo knowledge of biology is expected.',2,'http://cs.swan.ac.uk/~cskeg/keg29.gif');

INSERT INTO `seminar` VALUES (552,'2012-02-16','14:00','Robert Recorde Room','Russell Miller','http://qcpages.qc.cuny.edu/~rmiller/','CUNY','http://www.qc.cuny.edu/academics/degrees/dmns/math/Pages/default.aspx','Is it harder to find a root of a polynomial or to factor it?','Given a field F, it is natural to ask two questions about polynomials p in F[X].  First, does p factor within F[X]?  And second, does p have a root in F?  We will use computability theory to compare the difficulty of these two questions for computable fields F, i.e. fields in which the set of elements of F is effectively enumerable and the field operations are given by Turing-computable functions.  It has been known since the work of Frohlich and Shepherdson in 1956 that for any single computable field F, these two problems are Turing-equivalent, but recent work by the speaker, subsequently strengthened by his student Rebecca Steiner, has used finer reducibilities to establish that in general one question is strictly more difficult than the other.  To find out which is which, come to the talk!\r\n',2,'');

INSERT INTO `seminar` VALUES (547,'2012-02-23','14:00','Far-134 (Video Conferencing Room)','John Power','','Bath','http://www.bath.ac.uk/comp-sci/','What I did on my holidays: setoids with Yosh','',2,'');

INSERT INTO `seminar` VALUES (553,'2012-03-15','14:00','Far-134 (Video Conferencing Room)','Liam O''Reilly','http://cs.swan.ac.uk/~csliam/','Swansea','','Structured Specification with Processes and Data ','The integration of processes and data is a long standing research topic. In this talk, we discuss this integration in the context of the language CSP-CASL, where CSP is used to describe processes aspects and CASL is used to describe data aspects.\r\n\r\nOur specific questions are: Is it possible to make structuring operations available for building up complex specifications in a compositional way? What is an appropriate notion of refinement in such a setting? Finally, is it possible to reason on such specifications in a modular way? Based on institution theory, we develop a framework for CSP-CASL in which all three questions have positive answers.\r\n',2,'http://cs.swan.ac.uk/~csliam/Images/Liam.jpg');

INSERT INTO `seminar` VALUES (556,'2012-03-22','14:00','Far-134 (Video Conferencing Room)','Cai Wingfield','http://cs.bath.ac.uk/~cajw20/','Bath','http://www.bath.ac.uk/comp-sci/','A graphical foundation for schedules','In 2007, Harmer, Hyland and Melliès gave a formal mathematical foundation for game semantics using a notion they called a schedule. Their definition was combinatorial in nature, but researchers often draw pictures when describing schedules in practice. Moreover, a proof that the composition of schedules is associative involves cumbersome combinatorial detail, whereas in terms of pictures the proof is  straightforward, reflecting the geometry of the plane. Here, we give a geometric formulation of schedule, show that it is equivalent to Harmer et al.’s definition, and illustrate its value by giving a proof of associativity of composition.',2,'');

INSERT INTO `seminar` VALUES (555,'2012-04-10','16:00','Board Room','Benno van den Berg','http://www.staff.science.uu.nl/~berg0002/','Utrecht','http://www.uu.nl/faculty/science/en/research/researchinstitutes/mathematical/Pages/default.aspx','Herbrand realizability','In a joint paper with Eyvind Briseid and Pavol Safarik devoted to formal systems for nonstandard analysis, we introduced \"Herbrand realizability\", a new realizability interpretation. Although the original motivation came from nonstandard analysis, it can also be explained as a modification of Ulrich Berger''s uniform arithmetic or Lifschitz'' calculable numbers. The idea there is to have two types of quantifiers, one with computational content and one without, so as to have more control over how one extracts programs from proofs. One drawback (if one sees it that way) is that one is also forced to have two types of disjunction. This is precisely what is avoided in Herbrand realizability. If time permits, I will also talk about a Dialectica variant of Herbrand realizability or its categorical aspects (a \"Herbrand topos\").',2,'http://www.mittag-leffler.se/pictures/presentations/0910f/bergvanden-09f.jpg');

INSERT INTO `seminar` VALUES (557,'2012-03-29','14:00','Robert Recorde Room','Kenji Miyamoto','http://www.mathematik.uni-muenchen.de/~miyamoto/','LMU Munich','http://www.mathematik.uni-muenchen.de/index.html','Program Extraction for Exact Real Arithmetic','In this talk, I show a case study of program extraction on exact real arithmetic. We constructively prove a proposition on two real numbers and from the proof we obtain an average function by our program extraction mechanism. The representation of real numbers in the program is the signed digit stream which also comes from the extraction mechanism. We have a formalized proof of this case study on the proof system Minlog. The extracted program is available on Minlog to execute. This work is a joint work with Prof. Helmut Schwichtenberg in Munich.\r\n\r\nKeywords: Coinduction, Corecursion, Program Extraction, Exact Real Arithmetic. ',2,'');

INSERT INTO `seminar` VALUES (558,'2012-04-02','14:00','Board Room','Mizuhito Ogawa','http://www.jaist.ac.jp/~mizuhito/','JAIST Kanazawa','http://www.jaist.ac.jp/index-e.html','Proofs of confluence in rewriting systems: from constructive to computable','Termination and confluence are two major target properties of rewriting systems. When a rewrite system is terminating, confluence is equivalent to whether each critical pair joins, shown by Knuth and Bendix, 1970. \r\n\r\nFor nonterminating term rewriting systems, a seminal result is by Rosen in 60''s followed by Huet 1980. A left-linear (i.e., no duplicated occurrences of the same variable in the lhs of each rule) term rewriting system (TRS, for short) is confluent if there are no critical pairs. Huet extended it to allow trivial critical pairs (and further allowing critical pairs that can be closed one parallel step with the specified direction). There are several extensions in 90''s. Among all proofs, confluence is reduced to termination of peak elimination procedure, and they give an explicit bound/measure on peak elimination procedure. \r\n\r\nFor non-linear TRSs, confluence becomes much harder problems, and sometimes it does hold even in a natural setting. There are two directions: \r\n\r\n(1) Instead of confluence, a weaker property, focus on unique normal form. Its origin can be traced back to Klop''s thesis 1977 and Chew''s thesis 1980. \r\n\r\n(2) Confluence on a restricted class, e.g., with the right-linear condition we expect to recover confluence (which is open from 1990). \r\n\r\nThe main difficulties of both again come from finding an explicit bound/measure on peak elimination. Recently, we have several attempts to tackle confluence of non-linear term rewriting systems, which are computable in the sense that termination of peak elimination procedure is proved classically, i.e., without giving explicit bounds/measures. \r\n\r\nWe also briefly mention these difficulties shared with extensions of lambda calculus and pure (sub)type systems. \r\n',2,'');

INSERT INTO `seminar` VALUES (559,'2012-04-12','09:30','Oldwalls, Gower','','','','','John V Tucker 60th Birthday: Algebraic and Logical Methods for Data and Modelling','Scientific meeting held in honour of the significant contributions made by JVT to Computer Science. Meeting held at Oldwalls on the Gower Peninsula on 12 April 2012. \r\n\r\nAlgebraic and Logical methods have proven to be invaluable tools for Computer Science. Algebras appear everywhere, from models of the data itself, to models of computation, and logical reasoning provide for stringent studies of data, models, and computations. Clearly, any computation will operate on data. However, the data actually used in a computation is generally only a model of the real data. Whether the data are images, fluids or abstract real numbers, the computer can only work with models of the data. Thus, algebraic and logical methods are imperative for topics ranging from fundamental theoretical computer science to applied computations.\r\n\r\nThe programme can be found <a href=\"http://cs.swan.ac.uk/~csjens/jvt/\">here</a>.',2,'http://cs.swan.ac.uk/~csjens/jvt/JVT_05.JPG');

INSERT INTO `seminar` VALUES (560,'2012-05-03','14:30','Robert Recorde Room','Grant Malcolm','http://www.csc.liv.ac.uk/~grant/','Liverpool','http://www.csc.liv.ac.uk/','Towards a Functional Approach to Modular Ontologies Using Institutions ','We propose a functional view of ontologies that emphasises their role in determining answers to queries, irrespective of the formalism in which they are written. A notion of framework is introduced that captures the situation of a global language into which both an ontology language and a query language can be translated, in an abstract way. We then generalise existing notions of robustness from the literature, and relate these to interpolation properties that support modularisation of ontologies. We also consider institutions of description Logics with individuals. ',2,'');

INSERT INTO `seminar` VALUES (561,'2012-05-10','14:00','Board Room','Andy Lawrence','http://cs.swan.ac.uk/~csal/','Swansea','','Extracting a DPLL Algorithm','We formalize a completeness proof for the DPLL proof system and extract a DPLL solver from it. When applied to a propositional formula in conjunctive normal form the program produces either a satisfying assignment or a derivation which shows that it is unsatisfiable. We use non-computational quantifiers to remove redundant computational content from the program and improve its performance. The formalization is carried out in the Minlog system.',2,'http://cs.swan.ac.uk/~csal/Images/me4.jpg');

INSERT INTO `seminar` VALUES (564,'2012-06-14','14:00','Far-134 (Video Conferencing Room)','Richard Evans','','','','Emergent Drama = Sociality + Individuality','The central theme of the talk is that interactive drama emerges when we place individual characters in social situations: drama = sociality + individuality. I will give a host of examples from my previous work: social situations and individuals in The Sims 3, SimPhilosopher, and Little Text People.  Talk structure: first, I will motivate the need for concurrent communicating social practices in people simulations. Then, I will motivate the advantages of a declarative representation of state over procedural languages (e.g. ABL). I will sketch the formal theory of Exclusion Logic which powers the social simulation. I will also describe how we model individual personality traits.',2,'');

INSERT INTO `seminar` VALUES (565,'2012-05-03','14:30','Robert Recorde Room','Grant Malcolm','http://www.csc.liv.ac.uk/~grant/','Liverpool','http://www.csc.liv.ac.uk/','Towards a Functional Approach to Modular Ontologies Using Institutions ','We propose a functional view of ontologies that emphasises their role in determining answers to queries, irrespective of the formalism in which they are written. A notion of framework is introduced that captures the situation of a global language into which both an ontology language and a query language can be translated, in an abstract way. We then generalise existing notions of robustness from the literature, and relate these to interpolation properties that support modularisation of ontologies. We also consider institutions of description Logics with individuals. ',3,'');

INSERT INTO `seminar` VALUES (566,'2012-03-15','14:00','Far-134 (Video Conferencing Room)','Liam O''Reilly','http://cs.swan.ac.uk/~csliam/','Swansea','','Structured Specification with Processes and Data ','The integration of processes and data is a long standing research topic. In this talk, we discuss this integration in the context of the language CSP-CASL, where CSP is used to describe processes aspects and CASL is used to describe data aspects.\r\n\r\nOur specific questions are: Is it possible to make structuring operations available for building up complex specifications in a compositional way? What is an appropriate notion of refinement in such a setting? Finally, is it possible to reason on such specifications in a modular way? Based on institution theory, we develop a framework for CSP-CASL in which all three questions have positive answers.',3,'http://cs.swan.ac.uk/~csliam/Images/Liam.jpg');

INSERT INTO `seminar` VALUES (562,'2012-05-24','14:00','Far-134 (Video Conferencing Room)','Liang-Ting Chen','http://www.cs.bham.ac.uk/~lxc982/','Birmingham','http://www.cs.bham.ac.uk/','Concrete Coalgebraic Modal Logic: Modalities beyond Set','Coalgebraic logic for Set coalgebras given by predicate lifting has been applied to different areas in computer science, e.g. modal logic, automata theory, and program verification. However, there are very few studies beyond Sets. Exceptions are, for example, the category of posets for positive modal logic (by Kapulkin, Balan, Kurz, Velebil) and the category of measurable spaces for stochastic coalgebraic logic . Although there are more general approaches applicable to abstract categories, it is not clear how to describe modalities explicitly. \r\n\r\nIn this talk, I will introduce a notion generalising predicate liftings, which can be defined for every concrete category with a dual adjunction. We prove the adequacy, discuss the one-step expressivity concretely and identify the logic induced by all predicate liftings for categories of descent type.',2,'');

INSERT INTO `seminar` VALUES (563,'2012-05-31','14:00','Far-134 (Video Conferencing Room)','Matthew Hague','http://igm.univ-mlv.fr/~hague/','Université Paris-Est','http://igm.univ-mlv.fr/institut/','A Saturation Method for Collapsible Pushdown Systems','We study the model-checking problem for models of higher-order programs. In particular, via higher-order recursion schemes and their connection to collapsible pushdown systems. We present a saturation method for global backwards reachability analysis of these models. Beginning with an automaton representing a set of configurations, we build an automaton accepting all configurations that can reach this set.  We also improve upon previous saturation techniques for higher-order pushdown systems by significantly reducing the size of the automaton constructed and simplifying the algorithm and proofs. This is joint work with C. Broadbent, A. Carayol and O. Serre in Paris.',2,'http://www.cs.ox.ac.uk/files/180//IMG_9155thumb.jpg');

INSERT INTO `seminar` VALUES (567,'2012-07-05','14:00','Board Room','Kenji Miyamoto','http://www.mathematik.uni-muenchen.de/~miyamoto/','LMU Munich','http://www.mathematik.uni-muenchen.de/index.html','Program Extraction from Nested Inductive/Coinductive Definitions ','We present our work on program extraction and a case study on uniformly continuous functions working in our proof  system Minlog. This is a joint work with Prof. Schwichtenberg in LMU Munich. \r\n\r\nUlrich Berger and Monika Seisenberger inductively/coinductively defined a predicate of the uniform continuity and informally extracted Haskell programs from their constructive proofs of it.  Our work enriches the Theory of Computable Functionals and its computer implementation Minlog in order to formalize case studies by Berger and Seisenberger.\r\n\r\nWe extract from formal proofs programs which translate a uniformly continuous function on Cauchy reals in [-1,1] into a non-well founded tree representation, and vice versa.  Via Kreisel''s modified realizability interpretation, the extracted programs involve certain recursion and corecursion operators which come from nested inductive/coinductive definitions.  The non-well founded tree representation of uniformly continuous functions is of ground type. In this way, we manage to understand uniformly continuous functions through approximating non-well founded objects. ',2,'');

INSERT INTO `seminar` VALUES (568,'2012-08-23','14:00','Board room','Mohammad Mousavi','http://www.win.tue.nl/~mousavi/','Eindhoven University of Technology','http://w3.win.tue.nl/en/','In Processes, We Believe! On Marrying Process Algebra and Epistemic Logic','Process algebras, on one hand, provide a convenient means for specifying protocols. Epistemic models, on the other hand, are appropriate for specifying knowledge-related properties of such protocols (e.g., anonymity or secrecy). These two approaches to specification and verification have so far developed in parallel and one has either to define ad-hoc correctness criteria for the process-algebraic model or use complicated epistemic models to specify the behavioral aspects.\r\n\r\nWe work towards bridging this gap by proposing a combined framework which allows for modeling the behavior of a protocol in a process language with an operational semantics and supports reasoning about properties expressed in a rich logic which combines temporal and epistemic operators.\r\n\r\nFurther, we report on an extension of this framework with cryptographic construct and its influence on the epistemic aspects and conclude with a brief comparison of our semantic framework with the interpreted systems model of Fagin and Vardi. This talk does not assume any pre-knowledge of either of the two fields (and in particular of process algebras).',2,'');

INSERT INTO `seminar` VALUES (570,'2012-12-13','14:00','Board Room','Tom Maibaum','http://www.cas.mcmaster.ca/~maibaum/Toms_Mac_Site/Home_Page.html','McMaster University','http://www.cas.mcmaster.ca/cas/','Intermodeling, queries, and Kleisli categories','Specification and maintenance of relationships between models are vital for MDE. We show that a wide class of such relationships can be specified in a compact and precise manner. This requires that intermodel mappings involve derived model elements computed by corresponding queries. Composition of such mappings is not straightforward and requires specialized algebraic machinery. We present a formal framework, in which such machinery can be defined generically for a wide class of metamodel definitions, enabling algebraic specification of practical intermodeling scenarios.\r\n\r\nThis work is in collaboration with Zinovy Diskin and Krzysztof Czarnecki.',3,'http://www.cas.mcmaster.ca/~maibaum/Toms_Mac_Site/Home_Page_files/IMG_3217.jpg');

INSERT INTO `seminar` VALUES (574,'2012-11-15','14:00','Far-134 (Video Conferencing Room)','Helen Treharne','http://www.surrey.ac.uk/computing/people/helen_treharne/','University of Surrey','http://www.surrey.ac.uk/computing/index.htm','The Behavioural Semantics of Event-B Refinement','Event-B provides a flexible framework for stepwise system development via refinement.  All such steps are accompanied with precise proof obligations. However, no behavioural semantics has been provided to validate the proof obligations, and no formal justification has previously been given for the application of these rules in a refinement chain.  To this end, we define a CSP semantics for Event-B and show how the different forms of Event-B refinement can be captured as CSP refinement. Interestingly the appropriate CSP refinement relationship is influenced by the particular Event-B development strategy taken.',3,'http://www.surrey.ac.uk/computing/images/people/helen_treharne_thumbnail.jpg');

INSERT INTO `seminar` VALUES (573,'2012-11-15','14:00','Far-134 (Video Conferencing Room)','Helen Treharne','http://www.surrey.ac.uk/computing/people/helen_treharne/','University of Surrey','http://www.surrey.ac.uk/computing/index.htm','The Behavioural Semantics of Event-B Refinement','Event-B provides a flexible framework for stepwise system development via refinement.  All such steps are accompanied with precise proof obligations. However, no behavioural semantics has been provided to validate the proof obligations, and no formal justification has previously been given for the application of these rules in a refinement chain.  To this end, we define a CSP semantics for Event-B and show how the different forms of Event-B refinement can be captured as CSP refinement. Interestingly the appropriate CSP refinement relationship is influenced by the particular Event-B development strategy taken.',2,'http://www.surrey.ac.uk/computing/images/people/helen_treharne_thumbnail.jpg');

INSERT INTO `seminar` VALUES (569,'2012-12-13','14:00','Board Room','Tom Maibaum','http://www.cas.mcmaster.ca/~maibaum/Toms_Mac_Site/Home_Page.html','McMaster University','http://www.cas.mcmaster.ca/cas/','Intermodeling, queries, and Kleisli categories','Specification and maintenance of relationships between models are vital for MDE. We show that a wide class of such relationships can be specified in a compact and precise manner. This requires that intermodel mappings involve derived model elements computed by corresponding queries. Composition of such mappings is not straightforward and requires specialized algebraic machinery. We present a formal framework, in which such machinery can be defined generically for a wide class of metamodel definitions, enabling algebraic specification of practical intermodeling scenarios.\r\n\r\nThis work is in collaboration with Zinovy Diskin and Krzysztof Czarnecki.',2,'http://www.cas.mcmaster.ca/~maibaum/Toms_Mac_Site/Home_Page_files/IMG_3217.jpg');

INSERT INTO `seminar` VALUES (575,'2012-11-30','15:00','Robert Recorde Room','John Tucker','http://cs.swan.ac.uk/~csjvt/','Swansea University','http://www.swan.ac.uk/compsci/','What can we compute? A history of the Church-Turing Hypothesis','In 1936, motivated by the philosophical problem of what are the limits to human knowledge, Alan Turing wrote his wonderful paper the nature of computation; he was 24 years old. In it is to be found three intellectual innovations:\r\n<ol><li> a mathematical model of a human making a calculation, namely the Turing machine;</li><li> the idea of a universal machine that can mimic all other machines, namely a general programmable computer; and </li><li> the discovery of a computation that is provably impossible to perform. </li></ol> In this lecture I will look at one of the many legacies of this work: the hypothesis that anything that can be calculated can be calculated by a Turing machine. This hypothesis is plays an important role in computer science, mathematics, neuroscience, and philosophy of science. I will concentrate on how the thesis arose and on its generalisations in algebra, programming and physics.\r\n\r\nThis talk is a joint-talk with the <a href=\"http://www.swan.ac.uk/science/scientistsscienceandsociety/\">Scientists, Science, and Society seminars</a>, as well as celebrating the <a href=\"http://cspcab2.swan.ac.uk/aty-swan/\">Alan Turing Centenary</a>.',2,'http://cs.swan.ac.uk/~csmg/JVT_05.JPG');

INSERT INTO `seminar` VALUES (571,'2012-11-08','14:00','Far-134 (Video Conferencing Room)','Guy McCusker','http://www.cs.bath.ac.uk/~gam23/','University of Bath','http://www.bath.ac.uk/comp-sci/','Quantitative relational models of lambda-calculi','The category of sets and relations, and its refinements, provides a setting for simple models of the lambda-calculus, including Scott''s graph model and Girard''s coherence spaces model. In such models, the denotation of a lambda term is a relation whose entries record qualitative facts about the behaviour of the term: \"what it can do.\"\r\n\r\nWe investigate how to augment such models with quantitative information, so that the model can tell us not only what a term can do, but (for instance) \"in how many ways\" (for nondeterministic calculi), \"with what probability\" (for probabilistic calculi), or \"in how many steps of computation\". We present a general construction of quantitative relational models and a generic soundness theorem for them, and indicate the links with known quantitative models such as probabilistic coherence spaces.\r\n\r\nThis is joint work with Jim Laird (Bath), Giulio Manzonetto (Paris 13) and Michele Pagani (Paris 13))',2,'http://a0.twimg.com/profile_images/453827014/mccusker_guy.jpg');

INSERT INTO `seminar` VALUES (572,'2012-11-22','14:00','Board Room','Karim Kanso','http://cs.swan.ac.uk/~cskarim/','Swansea University','http://cs.swan.ac.uk/','Agda as a Platform for the Development of Verified Railway Interlocking Systems','This talk identifies a technological framework that aids the development of verified railway interlocking systems in the Agda theorem prover. The talk is in two parts, part I deals with integrating interactive and automated theorem proving in type theory, and part II addresses verification in the railway domain.\r\n\r\nPart I presents a selection of techniques that combine automated and interactive theorem proving paradigms. On the automated side, a novel, type theoretic connection between interactive theorem provers and external theorem provers is theoretically developed and implemented for the interactive theorem prover Agda. Also, Part~I evaluates the technique against the current state-of-the-art techniques for integrating interactive and automated theorem provers. The greatest betterment is that it is more feasible to be applied to industrial problems, than existing techniques. When exploring problem sets -- mathematical and industrial -- we obtained promising results.\r\n\r\nTwo cases studies of the integration have been carried out. These are SAT solving and CTL model-checking. Then CTL model-checking is refined to symbolic model-checking, and subsequently further refined into a customised logic for verifying programs that are definable by decidable Boolean valued transition functions.\r\n\r\nThe part concludes by exploring, and implementing a more traditional integration. This is where the external theorem prover provides a certificate that Agda checks to be correct, and then converts into a proof-object. A numerical comparison between these implementations is presented.\r\n\r\nPart II discusses the railway domain and developing verified interlocking systems. This involves applying interactive theorem proving to prove a selection of signalling principles (lemmata from the railway domain) is sufficient to guarantee high-level safety requirements. This reduces the validation problem by narrowing the gap between the verified statement and the requirements. Then for a given (concrete) interlocking system programmed using ladder logic, it is shown how to determine using automated theorem proving whether it fulfils the required signalling principles. This results in a proof that the interlocking system fulfils the safety requirements. Following the proofs-as-programs paradigm, verified, executable programs are obtained, which we used for simulation purposes.\r\n\r\nAll work is carried out inside Agda; thus the obtained proofs are tractable. Agda also extracts the verified programs from the proofs. Working within a single tool increases the soundness assurances when compared to the alternative, where there are questions about the correctness of translations between the tools.\r\n\r\nThis framework has been successfully applied to two different systems: a digital interlocking and a mechanical interlocking.',2,'');

INSERT INTO `seminar` VALUES (576,'2012-12-06','14:00','Far-134 (Video Conferencing Room)','David Wilson','http://www.cs.bath.ac.uk/~djw42/','University of Bath','http://www.bath.ac.uk/comp-sci/','Real Geometry and Connectedness - A survey of Cylindrical Algebraic Decomposition','Since its introduction in 1975, cylindrical algebraic decomposition (CAD) has proven a useful practical tool for quantifi er elimination over real-closed fields. Despite a doubly exponential complexity in the number of variables, it has seen applications in other areas of computer algebra (such as Branch Cut Analysis) and Robot Motion Planning. A history of various developments will be given before discussing recent research work by the research team in Bath - including preconditioning with Gröbner Bases and Truth Table Invariant CADs. Finally, future research directions will be sketched out.',2,'');

INSERT INTO `seminar` VALUES (577,'2013-01-24','14:00-18:00','Robert Recorde Room','','','','','Wessex Theory Seminar at Swansea','For talks and abstracts please see the <a href=''https://wiki.bath.ac.uk/display/wessex/19th+Wessex+Theory+Seminar''>Wessex Theory Seminar website</a>.',2,'');

INSERT INTO `seminar` VALUES (578,'2013-02-07','14:00','Robert Recorde Room','Norbert Preining','http://www.preining.info/','JAIST, Japan','http://www.jaist.ac.jp/rcis/en','Gödel Logics, Order Theory, (Continuous) Fraïssé Conjecture','(joint work with Arnold Beckmann and Martin Goldstern)\r\n\r\nIn this talk we present the basics of Gödel logics and some of their properties, which leads us to the question of the total number of different Gödel logics (as sets of formulas). From there we will take a long detour via order theory, well-quasi- and better-quasi-orderings to a generalization of the famous Fraïssé conjecture from 1948.\r\nThis conjecture is concerned with the number of scattered linear orderings and their bi-embeddability, and was proven in the 70ies by Laver building on the work of Nash-Williams on various quasi-orderings in the 60ies. We extend this notion to continuous bi-embeddability, and show similar results to the original Fraïssé conjecture.\r\nFinally, returning to Gödel logics, we make use of this result to obtain a suprising theorem on the number of Gödel logics.',2,'');

INSERT INTO `seminar` VALUES (580,'2013-02-13','15:00','504 (Realisability Seminar)','Fredrik Nordvall Forsberg','http://cs.swansea.ac.uk/~csfnf/','Swansea University','http://cs.swansea.ac.uk/','My Summer in Munich: Real-world Program Extraction into Haskell programs','Talk in the <a href=''http://cs.swan.ac.uk/~csfnf/realisability/''>Realisability Seminar</a>.',2,'');

INSERT INTO `seminar` VALUES (579,'2013-02-21','14:00',' Far-134 (video conferencing room)','Anton Setzer','http://cs.swansea.ac.uk/~csetzer/','Swansea University','http://cs.swansea.ac.uk/','Coinduction, Corecursion, Copatterns','In computer science, most computations are in fact interactive programs, which correspond to computations which can potentially run forever. They can be represented as trees which have potentially infinite branches. Mathematically, these data types are coalgebraic data types.\r\n\r\nCoalgebraic data types are often represented in functional programming as codata types. Implicit in formulations of codata types is that codata types fulfil bisimulation equality, which is undecidable.This resulted in lack of subject reduction in the theorem prover Coq and a formulation of coalgebraic types in Agda, which is severely restricted.\r\n\r\nIn this talk we demonstrate how, when using the fact that coalgebras are the dual of algebras we obtain a formulation of coalgebras which is completely symmetrical to that of algebras. Introduction rules for algebras are given by the constructors, whereas elimination rules correspond to recursive termination checked pattern matching. Elimination rules for coalgebras are given by destructors, whereas introduction rules are given by recursive termination checked copattern matching. \r\n\r\nThe resulting theory fulfils subject reduction. It is conjectured that a termination checked version based on higher type primitive corecursion as dual to higher type primitive recursion is normalising.\r\n\r\n(Joint work with Andreas Abel (Munich), Brigitte Pientka and David Thibodeau (Montreal); based on the POPL 2013 article Copatterns: programming infinite structures by observations)\r\n ',2,'');

INSERT INTO `seminar` VALUES (582,'2013-03-14','14:00','Robert Recorde Room','Matthew Gwynne','http://cs.swansea.ac.uk/~csmg/','Swansea University','http://cs.swansea.ac.uk/','Towards a theory of good SAT representations ','We aim at providing a foundation of a theory of \"good\" SAT representations (CNF clause-sets) F of boolean functions f. The hierarchy UC_k of unit-refutation complete clause-sets of level k was introduced by the authors in [2,3,5], based on notions of hardness and generalised unit-clause propagation (UCP) from [6,7]. We argue UC_k provides the most basic target classes for representation. That is, for a good representation, F in UC_k is to be achieved for k as small as feasible.\r\n\r\nThe first level of the hierarchy, UC_1, is the same as the class UC of unit-refutation complete clause-sets, introduced in 1994 in [10]. The aim of UC was to offer a class of clause-sets which was good for knowledge compilation and representation. More formally, UC is the class of clause-sets where unit-clause propagation (UCP), a simple linear-time inference algorithm, is sufficient decide questions of clausal entailment. In 1995 in [8], the class SLUR (Single Lookahead Unit Resolution) was introduced as an umbrella class for efficient satisfiability (SAT) solving. The motivation was to offer an algorithm for efficiently deciding satisfiability for existing poly-time SAT classes, including renamable Horn, extended Horn, hidden extended Horn, simple extended Horn, and CC-balanced clause-sets. In [2,3,5], we generalise SLUR to a hierarchy SLUR_k, again using generalised UCP, and show that these two hierarchies are in fact equal (SLUR_k = UC_k). This brings together the two notions of representation and efficient SAT solving, and allows one to think of \"finding a good representation\" as a form of \"SAT knowledge compilation\". As a first application of this dual perspective, we use results from [1] to show that, for (fixed) k >= 1, deciding whether a clause-set is in UC_k is coNP-complete.\r\n\r\nUC_k is directly related to the space complexity of tree resolution. However, in general, it is known that modern SAT solvers can (in some sense) simulate stronger proof systems such as full-resolution. Using the notion of resolution width from [6,7], in [3,5] we introduce the hierarchy WC_k of clause-sets with width-hardness k; for all k the class UC_k is a subset of WC_k. In [4], we introduce lower bound methods for WC_k and use these to prove separation results between UC_(k+1) and UC_k, as well as between WC_(k+1) and WC_k. More formally, we show that for every k >= 1 there are sequences of boolean functions with polynomial size equivalent clause-set representations in UC_(k+1) which have no equivalent polynomial-size representations in WC_k. The boolean functions for these separations are \"doped\" minimally unsatisfiable clause-sets of deficiency 1; these functions have been introduced in [9], and we generalise their construction and show a correspondence to a strengthened notion of irredundant sub-clause-sets. Turning from lower bounds to upper bounds, we believe that many common CNF representations fit into the UC_k scheme, and we give some basic tools to construct representations in UC_1 with new variables, based on the Tseitin translation.\r\n\r\n\r\n[1] Ondrej Cepek, Petr Kucera, and Vaclav Vlcek. Properties of SLUR formulae.In Maria Bielikova, Gerhard Friedrich, Georg Gottlob, Stefan Katzenbeisser, and Gyorgy Turan, editors, SOFSEM 2012: Theory and Practice of Computer Science, volume 7147 of LNCS Lecture Notes in Computer Science, pages 177–189. Springer, 2012.\r\n\r\n[2] Matthew Gwynne and Oliver Kullmann. Generalising and unifying SLUR and unit-refutation completeness. In Peter van Emde Boas, Frans C. A. Groen, Giuseppe F. Italiano, Jerzy Nawrocki, and Harald Sack, editors, SOFSEM 2013: Theory and Practice of Computer Science, volume 7741 of Lecture Notes in Computer Science (LNCS), pages 220–232. Springer, 2013.\r\n\r\n[3] Matthew Gwynne and Oliver Kullmann. Generalising unit-refutation completeness and SLUR via nested input resolution. Technical Report arXiv:1204.6529v5 [cs.LO], arXiv, January 2013.\r\n\r\n[4] Matthew Gwynne and Oliver Kullmann. Towards a theory of good SAT representations. Technical Report arXiv:1302.4421v1 [cs.AI], arXiv, February 2013.\r\n\r\n[5] Matthew Gwynne and Oliver Kullmann. Generalising unit-refutation completeness and SLUR via nested input resolution. Journal of Automated Reasoning, 2013. To appear.\r\n\r\n[6] Oliver Kullmann. Investigating a general hierarchy of polynomially decidable classes of CNF’s based on short tree-like resolution proofs. Technical Report TR99-041, Electronic Colloquium on Computational Complexity (ECCC), October 1999.\r\n\r\n[7] Oliver Kullmann. Upper and lower bounds on the complexity of generalised resolution and generalised constraint satisfaction problems. Annals of Mathematics and Artificial Intelligence, 40(3-4):303–352, March 2004.\r\n\r\n[8] John S. Schlipf, Fred S. Annexstein, John V. Franco, and R.P. Swaminathan. On finding solutions for extended Horn formulas. Information Processing Letters, 54:133–137, 1995.\r\n\r\n[9]  Robert H. Sloan, Balazs Sorenyi, and Gyorgy Turan. On k-term DNF with the largest number of prime implicants. SIAM Journal on Discrete Mathematics, 21(4):987–998, 2007.\r\n\r\n[10] Alvaro del Val. Tractable databases: How to make propositional unit resolution complete through compilation. In Proceedings of the 4th International Conference on Principles of Knowledge Representation and Reasoning (KR’94), pages 551–561, 1994\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (581,'2013-03-07','14:00','Robert Recorde Room','Gregory Woods','','Swansea University','http://cs.swansea.ac.uk/','A Case Study on Imperative Program Extraction','The process of program extraction has long been associated with functional programs with little research in the direction of imperative program extraction. While many useful tools exist to extract functional programs (Agda, Isabelle, Coq and NuPRL) the simple fact is that most programs that are written are more towards the imperative paradigm.\r\n\r\nIn this talk we explore a case study which demonstrates that imperative program extraction is possible. The problem we choose to solve using this method is the classic problem of sorting a list of numbers. Many algorithms exist to solve this problem and we will focus on one of the most famous, Quicksort. We present a successful attempt at extracting a program, that yields imperative behaviour, from a constructive proof. The software used for this is the interactive theorem prover Minlog.\r\n',2,'');

INSERT INTO `seminar` VALUES (583,'2013-03-21','14:00','Robert Recorde Room','Casper Poulsen','','Swansea University','http://cs.swansea.ac.uk/','Partial Derivation in Modular Structural Operational Semantics','The scientific study of programming languages requires a formal specification of their semantics. However, the incentives of applying formal specification frameworks during programming language design are often outweighed by more pragmatic concerns, such as developing and maintaining an executable interpreter for the language under design.\r\n\r\nOne way of bridging the gap between formal specification and pragmatic programming language design is by making formal specifications pragmatic for the language developer. Modular structural operational semantics (MSOS), a modular variant of structural operational semantics (SOS), is a formalism that supports incremental and scalable language design, e.g., by taking a component-based approach to semantic specification.\r\n\r\nInterpreting the transitive closure of the transition function for a set of MSOS rules gives a prototype interpreter, where evaluation corresponds to proof derivation using the underlying MSOS rules. However, a naive implementation of such an interpreter has a worst-case interpretive overhead where each proof step requires a number of inferences that is linear in the depth of the input term. Furthermore, while small-step semantics have several declarative advantages, term reduction using small-step rules requires more inference steps than when using their big-step counterparts. For the programming language designer who is concerned with efficiency, the considerable interpretive overhead incurred by a naive interpretation may be unacceptable in practice.\r\n\r\nHere, we explore how to reduce interpretive overhead of small-step MSOS rules through partial evaluation techniques which, in our modular structural proof system setting, we will call <i>partial derivation</i>. Combining ideas from partial evaluation in logic programming, bisimulation theory, and refocusing in reduction semantics we show how to derive rules whose proofs require fewer inferences (and hence, whose evaluation is more efficient). Applying partial derivation to a semantics is a fully mechanisable transformation that gives a provably semantically equivalent set of rules. Furthermore, the techniques are broadly applicable, being constrained by only a very mild set of conditions for correctness. The transformations result in rules with a big-step flavour, hinting at the inter-derivability of small-step and big-step style semantics.\r\n\r\nAs a proof of concept, we have prototyped semantic rules in Prolog, where we can observe a significant reduction in the running time of interpreters based on partially derived semantics in comparison with their naive counterparts. We conclude that partial derivation is a viable technique for reducing interpretive overhead in modular structural proof systems and practical interpreters derived from these, and that partial derivation is a viable tool for prototypical and pragmatic language design.',2,'');

INSERT INTO `seminar` VALUES (584,'2013-05-02','14:00','Robert Recorde Room','Paolo Torrini','http://www.cs.le.ac.uk/people/pt95/','Swansea University','http://www.swan.ac.uk','Parametric polymorphism with references','Hindley-Milner polymorphism is a tractable form of parametric polymorphism that is widely used in functional languages (e.g. SML, OCaml, Haskell). Also known as ''let'' polymorphism, it allows for generalisation, in the body of ''let'' expressions, of type variables that do not occur free in the environment. Proof-theoretic soundness relies on the logic of propositional quantification as part of system F --- although proof systems for ''let'' polymorphism can be syntactically defined on top of a distinction between types and type schemes, that makes it possible to dispense with explicit quantifier introduction.\r\n\r\nIn languages with references, things are more complicated. If evaluating the definiens of a ''let'' expression requires allocation of new references, which depend on type variables that occur in the definiens type, the naive approach turns out to be semantically unsound.  Different solutions have been proposed and adopted in practice, based on different ways to approximate the set of type variables that are unsafe with respect to generalisation.\r\n\r\nThe general argument boils down to the fact that type variables can be generalised only when they do not occur free in the environment --- this time in an extended sense though, that should take the store into account. This suggests there may be natural ways to constrain generalisation, relying on more expressive forms of typing judgement, and in particular on substructural logic. ',2,'');

INSERT INTO `seminar` VALUES (585,'2013-04-29','14:00','Far-134 (video conferencing room)','Neil Ghani','https://personal.cis.strath.ac.uk/neil.ghani/','University of Strathclyde','http://www.strath.ac.uk/cis/','Fibrational Parametricity','Parametricity, also known as logical relations is a fundamental concept within programming languages designed to capture the idea that programs map related inputs to related outputs. Originally formulated by John Reynolds in the 1970s, parametricity has been a key tool in reasoning about programming languages ever since. However, as programming languages have advanced, parametricity has struggled to keep up. I think that part of the reason for this is that its not really clear what parametricity really is. We have lots of specific constructions of what a parametric model is but not overarching theory which can then be instantiated to a variety of different settings (operational, game-theoretic, constructive, domain theoretic etc).\r\n\r\nIn this talk I''ll explain some work we have been doing in Strathclyde recently whose goal is to suggest that while the usual semantics of programming languages can be given abstractly in terms of a categorical universe using concepts such as categories, functors and natural transformations, parametricity amounts to working in a fibrational universe consisting of fibred categories, fibred functors and fibred natural transformations. This work forms the basis of a new EPSRC 4-year grant so anyone interested in applying for the associated RA position is particularly welcome to attend.',2,'');

INSERT INTO `seminar` VALUES (586,'2013-06-20','14:00','Robert Recorde Room','Margarita Korovina','','A.P. Ershov Institute of  Informatics Systems','http://www.iis.nsk.su/en','Synthesis and verification of definable dynamics','In this talk I will present ongoing research which is aimed at creating\r\n a  logical framework for  synthesis and formal verification of definable dynamical systems.\r\nFirst, we discuss the problem of finite control synthesis for definable dynamics. I will show how quantifier elimination and real algebraic geometry methods could help to solve this problem for polynomial dynamics. Then,  we address reachability problem, i.e., whether trajectories of the dynamical systems reach safe/unsafe regions from initial regions. The key idea of our approach is based on computing combinatorial types of trajectories. I will show how it could be done using cylindrical cell decomposition for polynomial and Pfaffian dynamics.\r\n',2,'');

INSERT INTO `seminar` VALUES (587,'2013-07-04','14:00','Robert Recorde Room','Stanislav Speranski','','Novosibirsk','',' Quantified probability logics: expressibility vs. computability','The talk is devoted to various formal languages for reasoning about probabilities, namely to those augmented by quantifiers over so-called Bernoulli random variables (which correspond to spinning fair and biased coins). In a sense, such languages enable one to explicitly write specifications in probabilistic terms. Unfortunately, many standard problems concerning these languages turn out to be algorithmically undecidable. Still, understanding/measuring computational complexity of those problems is a very interesting and natural task in its own right --- and this will be the main topic of the talk.',2,'');

INSERT INTO `seminar` VALUES (588,'2013-07-11','14:00','Far-134 (video conferencing room)','Pasquale Malacaria','http://www.eecs.qmul.ac.uk/~pm/','Queen Mary, University of London','http://www.qmul.ac.uk','The Thermodynamics of Confidentiality','What has a property (confidentiality) of a human artifact (software) to do with the most basic laws of physics (second law of thermodynamics)? I came across these questions and some answers in recent years. I found it a fascinating tale about the physical value of information and the cost incurred in protecting it. Some of these results are fundamental limits on any physical device guaranteeing a certain degree of confidentiality while others relate to physical properties of timing channels. This talk will survey (in accessible form) some of these results/ideas, their interpretation and possible research directions. This is a joint work with Fabrizio Smeraldi. ',2,'');

INSERT INTO `seminar` VALUES (589,'2013-07-18','14:00','Robert Recorde Room','Oleg Kudinov and Vladislav Amstislavskiy','','Novosibirsk','','On the structures of continuous and smooth functions, and some ideas on decidability of elementary theories','Some ideas on decidablity of elementary theories\r\nOleg Kudinov, Sobolev Institute of Mathematics\r\n\r\nThe first part of the present talk is devoted to some new method, that is similar to the famous interpretation method, that could be used for establishing decidability results as well as for obtaining results on undecidability.\r\nAfter the origin of the method, only few applications were obtained by V. Amstislavskiy, related to the elementary theories of some lattices of continuous and smooth functions. It is a real challenge to find more applications or adopt the method for more complicated problems.\r\nThe second part of the talk is devoted to the situation around the famous problem in field theory, related to decidability of the elementary theory of the field Fp t . Mostly, the problem of model completeness of mentioned theory and the theory of some assosiated class of fields of positive characteristic will be considered.\r\n\r\nOn the structures of continuous and smooth functions\r\nVladislav Amstislavskiy. Sobolev Institute of Mathematics, Novosibirsk\r\n\r\nWe study some new applications of the generalized method of interpretations. With this method offered by Kudinov O.V. we proved decidability of the theory of the lattice of continuous functions from R to R and from Rn to R for n > 1. Using this method we also proved that the theories of the structures of continuous functions over some perfectly normal space are m&#8722; equivalent to the theories of open subsets of this space. Thereby, by proving that the theory of the structure of open subsets of some perfectly normal space is decidable, decidability of the theory of the structure of continuous functions over this space is proved as well.\r\n\r\nAll these results are about the lattices of continuous functions. In our recent work we study the question of decidability of the theory of differential functions (C 1 (R); &#8804;), where C 1 (R) is an algebraic structure of the set of differential functions from R to R and &#8804; is the pointwise order. To use the generalized method of interpretations it is required to understand where we can interpret this theory satisfying all the formal conditions of the method. The new applications of the generalized method of interpretations let consider it as a useful tool to prove decidability of theories.',2,'');

INSERT INTO `seminar` VALUES (590,'2013-07-24','14:00','Robert Recorde Room','Victor Selivanov','http://vseliv.nspu.ru/','A. P. Ershov Institute of Informatics Systems of Siberian Division of Russian Academy of Sciences','','Descriptive Set Theory and Computation Theory','We briefly discuss interaction between Descriptive Set Theory and Computation Theory. After a short historical introduction we discuss notions and methods relevant to the both fields. We will provide some additional details about infinite behaviour of finite automata, namely the Wagner hierarchy of regular omega-languages and its recent extension from the case of sets to the case of k-partitions of the Cantor space.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (591,'2013-09-24','15:00(!)','Robert Recorde Room','Peter Dybjer','','University of Gothenburg','','Tests, games, and Martin-Löf''s meaning explanations for intuitionistic type theory','In this informal talk I will present some of my latest thoughts on the connection between tests, games and the foundation of constructive logic. The starting point is Martin-Löf''s meaning explanations for intuitionistic type theory which were presented in the paper \"Constructive Mathematics and Computer Programming\" (LMPS 1979). Martin-Löf there explains the meaning of the judgement of the theory in terms of lazy evaluation to canonical form. I essentially follow this idea but think of his meaning explanations as being about real tests of programs. This leads me to propose an alternative explanation of the meaning of higher-order functions, as passing certain kinds of interactive tests in the style of game semantics. Technically, we use the connection between Hyland-Ong games and so called PCF Böhm trees to build a model of type theory. We discuss the connection between this \"meta-mathematical\" model and the \"pre-mathematical\" tests.',2,'');

INSERT INTO `seminar` VALUES (592,'2013-09-19','14:00','Robert Recorde Room','Naohi Eguchi','','University of Innsbruck','','Characterising Complexity Classes by Fixed Point Axioms','Any terminating computation can be understood via the fixed point of an operator since once it reaches the accepting state, the configuration of an underlying machine model no longer changes. In finite model theory, it is known that every polynomial-time predicate can be expressed by the first order predicate logic with the fixed point predicate of a monotone operator whereas every polynomial-space predicate can be expressed by the first order predicate logic with the\r\nfixed point predicate of a non-monotone operator. We introduce a fixed point axiom over a weak fragment of Peano\r\narithmetic, which is known as bounded arithmetic, providing new characterisations of polynomial-time/-space functions.',2,'');

INSERT INTO `seminar` VALUES (593,'2013-11-19','14:00','Robert Recorde Room','Chris Tofts','https://en.wikipedia.org/wiki/Chris_Tofts','HP Enterprise Services','','So What Is A Computation Theorist Doing As An Outsourcing Enterprise Architect?','As labour arbitrage has moved a significant number of IT jobs offshore the remaining technical jobs within the UK tend to be face to face sales focussed. As an example of the type of technical job that remains firmly grounded near to customers, I will outline how a reasonably large (> $50 million) deal progressed and the role the mathematics of computing systems\r\nplayed in the development of an effective solution. The example deal is a recent agreement between Deluxe Digital Cinemas EMEA and HP Enterprise Services to deliver movie files to cinemas and is likely to impact a multiplex near you in the next 18 months.',2,'');

INSERT INTO `seminar` VALUES (594,'2013-11-12','15:00','Robert Recorde Room','Jeroen Van der Meeren','http://cage.ugent.be/~jvdm/Site/Welcome.html','Ghent University','','Well-partial-orderings and their Strengths','Well-partial-orderings are widely usedin for example logic, computer science and mathematics. They are the essential ingredients of famous theorems like Higman’s lemma, Kruskal’s theorem and the graph minor relation. In computer science, they can be used for proving the termination of certain algorithms. Additionally, they have connections with the computation of the running times of these algorithms. In logic, well-partial-orderings are quite often related with the proof-theoretical ordinal of an axiomatic system. Moreover, they can be used in for example proof theory and reverse mathematics.\r\n\r\nA well-partial-ordering (hereafter wpo) is a well-founded partial ordering (X,&#8804;X)with no infinite antichains. Hence, wpo’s are the natural generalizations of well-orderings. The maximal order type of a well-partial-ordering (X,&#8804;X) is an important characteristic of the wpo which captures a lot of information about it. It is defined as the maximum of the order types of all well-orderings which are extensions of the ordering &#8804;X on X. There is a relation between the proof-theoretical strength of the sentence ‘X is a wpo’ and the maximal order type of X.\r\n\r\nThe maximal order type of the famous set of trees with Friedman’s gap-embeddability relation is unknown. In this talk, I will tackle this problem by discussing tree-like structures T(W), depending on a parameter W (introduced by Weiermann). I will talk about a general conjecture to compute its maximal order type and some new recent developments concerning this topic. Furthermore, I will discuss results on the proof-theoretical strength of the statement ‘T(W) is a wpo’.',2,'');

INSERT INTO `seminar` VALUES (595,'2013-11-27','16:00','Far-134 (video conferencing room)','Alexis Goyet','http://www.goyet.info/','University Paris Diderot (Paris 7)','','A dual calculus for unconstrained strategies','The aim of the lambda lambda-bar calculus is to represent as faithfully as possible the structure of non-deterministic, non-innocent, non-visible strategies in game semantics. Non-innocent strategies have been shown to model functional languages extended with references. The typical approach is to model the purely functional fragment with innocent strategies, to which a \"memory-cell\" strategy is added. Instead, our starting point is a simple concrete syntax of finite strategies, which are inherently non-innocent. This approach is syntax driven, and the resulting language is a dualization of the lambda calculus. A new binder, the lambda-bar, names arguments which have been passed to the environment (whereas the lambda names arguments which have been received). This makes explicit the act of answering a function call, and allows this answer to change over time, granting the power of effects.',2,'');

INSERT INTO `seminar` VALUES (597,'2013-11-20','16:00','Far-134 (video conferencing room)','Beniamino Accattoli','https://sites.google.com/site/beniaminoaccattoli/','Bologna University','','A Fresh Look at Linear Head Reduction','Linear logic decomposes intuitionistic implication in two connectives, the exponential modality and linear implication. Such a decomposition induces a new evaluation strategy, called linear head reduction, refining the key notion of head reduction in lambda-calculus. Linear head reduction (LHR) appeared very early in the linear logic literature. However, its presentations were intricate and hard to manipulate, so that it remained an exotic notion confined to the narrow circle of pure linear logicians. Recent progress in the theory of explicit substitutions provides a framework, the linear substitution calculus, where LHR admits a simple and manageable formulation. In this talk I will survey the new theory of LHR that arose recently, by revisiting and extending the results from the early days of linear logic. In particular, I will explain how LHR is the ''trait d''union'' between explicit substitutions, proof-nets, the pi-calculus, Turing machines and Krivine abstract machine.',2,'');

INSERT INTO `seminar` VALUES (596,'2013-11-25','16:00','Robert Recorde Room','Norbert Preining','http://www.preining.info/','Japan Advanced Institute of Science and Technology','http://www.jaist.ac.jp/','Intermediate predicate logics restricted to one monadic predicate symbol','We will show that the logics based on well-ordered and dually well-ordered linear Kripke frames with constant domains of length up to \\omega^\\omega can already be separated by the fragments of one monadic predicate symbol.\r\n\r\nThese investigations started from a very simple question:\r\n   How much can we express with one monadic predicate symbol over linear order.\r\nMore specifically, considering logics over linear Kripke frames with constant domains, we asked ourselves how many separate fragments of one monadic predicate symbol exist. Very early guesses were as low as 4 (`What can we express more than infima and suprema and their order?''). It soon turned out that this was a over-simplification, but although we have now a much better view of the expressive power of monadic predicate symbols over linear oders, we are still far from a full understanding.\r\n\r\nSeparation is achieved by expressing infima/suprema of arbitrary finite degree, and their orders. While this method is currently restricted to the two cases of well-ordered and dually well-ordered, we expect that by using ordinal notations and extending the classical Cantor-Bendixon rank we can extended the current results to a broader class of Kripke frames.',2,'');

INSERT INTO `seminar` VALUES (598,'2013-12-18','11:00','Board Room (314)','Thomas Powell','http://www.ihes.fr/~tpowell/','Institut des Hautes Études Scientifiques','http://www.ihes.fr/jsp/site/Portal.jsp?page_id=13','Bar recursive extensions of Goedel''s system T ','Extensions of Goedel''s system T with variants of bar recursion play a crucial role in proof theory, where they are used to give a computational interpretation to strong subsystems of mathematics based on the axiom of countable choice. The canonical example of this is Spector''s bar recursion, devised in the 1960s to solve the Dialectica interpretation of the double negation shift. However, the last decade or so has seen the development of a much broader variety of such extensions, including modified bar recursion, the symmetric `demand-driven'' functional of Berardi, Bezem and Coquand, the update and open recursors of Berger and more recently the products of selection functions of Escardo and Oliva. In this talk I discuss aspects of the computability theory of bar recursion and its variants, and in particular I give an account of recent work on establishing the relationship between these variants and classifying extensions of system T according to primitive recursive definability. ',2,'');

INSERT INTO `seminar` VALUES (600,'2013-12-12','14:00','Robert Recorde Room','Casper Bach Poulsen','http://cs.swan.ac.uk/~cscbp/','Swansea University','http://www.swan.ac.uk/compsci/','Refocusing in Structural Operational Semantics','In this talk, we consider a direct approach to deriving big-step SOS\r\nrules from small-step ones: we refocus the SOS rules themselves. By\r\nworking directly with the rules, we avoid the need to introduce\r\nabstract machines, relate them to SOS rules, and prove the correctness\r\nof abstract machine transformations. Use of this approach can\r\nsignificantly improve the efficiency of interpreters generated from\r\nSOS rules.',2,'');

INSERT INTO `seminar` VALUES (601,'2014-01-14','14:00','Robert Recorde Room','Phillip James','http://cs.swan.ac.uk/~cspj/','Swansea University','','Domain Specific Languages and Verification','The development and application of formal methods is a long standing research topic within the field of Computer Science. One particular challenge that remains is the uptake of formal methods into industrial practices. In this talk, we present a methodology for developing domain specific languages for modelling and verification that aims to aid the uptake of formal methods within industry. We will cover the successful application of this methodology within the railway domain. The presented methodology addresses three core issues surrounding faithful modelling, scalability of verification and accessibility to modelling and verification processes for practitioners within the domain.',2,'');

INSERT INTO `seminar` VALUES (602,'2014-03-17','16:00','Robert Recorde Room','Peter Schuster','http://www1.maths.leeds.ac.uk/~pschust/','University of Leeds','','Minimal Counterexamples and Minimal Logic ','In many a proof by contradiction of a universal statement the existence of a minimal counterexample is proved by the Lemma of Kuratowski-Zorn.\r\nWhenever minimal logic suffices for establishing the hypotheses, one can reread the proof as a direct and inductive proof with the principle of Open Induction by Jean-Claude Raoult.\r\n\r\n(This work was prompted by a communication by Ulrich Berger.)\r\n',2,'');

INSERT INTO `seminar` VALUES (603,'2014-02-11','16:00','Robert Recorde Room','Samson Abramsky','http://www.swansea.ac.uk/compsci/distinguishedlectures/samsonabramsky/','University of Oxford','','Talk in the Distinguished Lectures Series - Contextual Semantics: From Quantum Mechanics to Logic, Databases, Constraints, Complexity, and Natural Language Semantics','Quantum Mechanics presents a disturbingly different picture of physical reality to the classical world-view. These non-classical features also offer new resources and possibilities for information processing. At the heart of quantum non-classicality are the phenomena of non-locality, contextuality and entanglement. We shall describe recent work in which tools from Computer Science are used to shed new light on these phenomena. This has led to a number of developments, including a novel approach to classifying multipartite entangled states, and a unifying principle for Bell inequalities based on logical consistency conditions. At the same time, there are also striking and unexpected connections with a number of topics in classical computer science, including relational databases, constraint satisfaction, and natural language semantics.',2,'');

INSERT INTO `seminar` VALUES (599,'2014-02-04','14:00','Robert Recorde Room','Igor Razgon','http://www.dcs.bbk.ac.uk/staff/staffperson.php?name=igor','Birkbeck (University of London)','http://www.dcs.bbk.ac.uk/','Propositional rewriting techniques for knowledge representation','The following scenario is common in knowledge representation. There is a knowledge base and types of queries to be answered. The requirement is that all these queries must be answered in a polynomial time. However, some queries are intractable (e.g. NP-complete to answer) in the given representation of the knowledge base. A possible solution is *rewriting*: the knowledge base is compiled into a different format where the queries can be answered efficiently. Of course the compilation may take a lot of time. However, it is performed *offline*, at the preprocessing stage and if the knowledge base is not changed over a *long* period of time, the time savings from the query answering will amply compensate the additional preprocessing time.\r\n\r\nThe real difficulty of application of the above methodology is that the knowledge base resulting from the rewriting may become prohibitively large. Therefore the main effort of researchers is concentrated towards design of rewriting algorithms having a reasonable space complexity of their output.\r\n\r\nIn this talk I will concentrate on the *propositional* rewriting also known as knowledge compilation. In the relevant scenario the initial format of the knowledge base is Conjunctive Normal Form (CNF) and a typical query is whether or not the given partial assignment to its variables can be extended to a satisfying assignment of this CNF.\r\nThis kind of query is called *clausal entailment* and it is clearly NP-complete since it is a generalization of the satisfiability testing, a classical NP-complete problem.\r\n\r\nThe methodology of knowledge compilation is transformation of the input CNF into an equivalent *good* representation for which the clausal entailment query can be answered in a polynomial time. I will overview a number of such representations including: decision trees, ordered binary decision diagrams, free binary decision diagrams, decomposable negation normal forms. I will also overview the relationship between these representations, their advantages and disadvantages.\r\n\r\nIn the final part of my talk I will intuitively overview an approach to obtain a space-efficient good representation from the initial CNF. This approach is based on the assumption that the CNF is associated with a natural parameter that is very small compared to the size of the CNF. The resulting representation is exponential in terms of this small parameter but polynomial in the input size.\r\n',2,'');

INSERT INTO `seminar` VALUES (604,'2014-02-25','13:15','video conferencing room','Julian Gutierrez','http://www.cs.ox.ac.uk/people/julian.gutierrez/','University of Oxford','','Concurrent games on event structures','Various definitions of games have been proposed in the games and computer science literatures. In this talk I will present a model where concurrent games are represented by event structures; this model generalises sequential games represented as trees to a partial order setting. In particular I will describe some results about the existence of winning strategies for games satisfying two fundamental \r\nstructural conditions on event structures. Most of the main technical results to be presented in this talk can be found in a recent CONCUR''13 paper.',2,'');

INSERT INTO `seminar` VALUES (606,'2014-03-05','14:00','Robert Recorde Room','Dieter Spreen','http://www.uni-siegen.de/fb6/tcs/team/spreen/','Universitaet Siegen','','Information Frames','In 1982 Dana Scott introduced information systems as a logic-based approach to domain theory. An information system consists of a set of tokens to be thought of as atomic statements about a computational process, a consistency predicate telling us which finite sets of such statements contain consistent information, and an entailment relation saying what atomic statements are entailed by which consistent sets of these. Theories  of such a logic, also called states, i.e. finitely consistent and entailment-closed sets of atomic statements, form a bounded-complete domain with respect to set inclusion, and, conversely, every such domain can be obtained in this way, up to isomorphism. This gives Scott''s idea that domain elements represent information about states of a computation a precise mathematical meaning.\r\n\r\nThe role of bounded completeness becomes also clear in this context: States represent consistent information. So, any finite collection of substates must contain consistent information as well, and this fact is witnessed by any of its upper bounds.\r\n\r\nWhereas in Scott''s approach the consistency witnesses are hidden, in this paper we present an approach that makes them explicit. This allows to consider the more general situation in which there is no longer a uniform global consistency predicate. Instead there is consistency predicate for each atomic statement telling us which finite sets of atomic statements express information that is consistent with the given statement. As it turns out the theories, or states, of such a more general information system form an L-domain, and, up to isomorphism, each L-domain can be obtained in this way.\r\n\r\nSince every token in the just delineated kind of information system has its own consistency predicate, we can also think of each such system as a family of logics, or a Kripke frame. \r\n',2,'');

INSERT INTO `seminar` VALUES (607,'2013-03-05','14:00','Robert Recorde Room','Dieter Spreen','http://www.uni-siegen.de/fb6/tcs/team/spreen/','Universitaet Siegen','','Information Frames','In 1982 Dana Scott introduced information systems as a logic-based approach to domain theory. An information system consists of a set of tokens to be thought of as atomic statements about a computational process, a consistency predicate telling us which finite sets of such statements contain consistent information, and an entailment relation saying what atomic statements are entailed by which consistent sets of these. Theories  of such a logic, also called states, i.e. finitely consistent and entailment-closed sets of atomic statements, form a bounded-complete domain with respect to set inclusion, and, conversely, every such domain can be obtained in this way, up to isomorphism. This gives Scott''s idea that domain elements represent information about states of a computation a precise mathematical meaning.\r\n\r\nThe role of bounded completeness becomes also clear in this context: States represent consistent information. So, any finite collection of substates must contain consistent information as well, and this fact is witnessed by any of its upper bounds.\r\n\r\nWhereas in Scott''s approach the consistency witnesses are hidden, in this paper we present an approach that makes them explicit. This allows to consider the more general situation in which there is no longer a uniform global consistency predicate. Instead there is consistency predicate for each atomic statement telling us which finite sets of atomic statements express information that is consistent with the given statement. As it turns out the theories, or states, of such a more general information system form an L-domain, and, up to isomorphism, each L-domain can be obtained in this way.\r\n\r\nSince every token in the just delineated kind of information system has its own consistency predicate, we can also think of each such system as a family of logics, or a Kripke frame. \r\n',2,'');

INSERT INTO `seminar` VALUES (609,'2014-03-13','14:00','Robert Recorde Room','Egon Boerger','http://www.di.unipi.it/~boerger/','University of Pisa','','Closing the Gap between Business Process Models and their Implementation: Towards Certified BPMs','The gap between on the one side the users'' understanding of Business Process Models (BPMs), even if described using standardized languages like BPMN, and on the other side the run behavior of model implementations is still with us. We explain how Abstract State Machines (ASMs), tailored as a domain specific (to a large extent diagrammatic) modeling language, allow the BP experts to design BPMs with the help of a graphical editor in such a way that the underlying ASM models constitute a reliable precise contract --- a contract which guarantees the BP domain experts that the application-domain focussed understanding of the BPMs they design is also a correct understanding of the code behavior provided by the implementation of the models by software experts. This opens the way to the development of certifiably correct BPMs and their implementations. We instantiate the claim by ASM models for the behavioral meaning of the graphical notations used in Metasonic''s industrial BPM tool suite.\r\n\r\n(Joint work with A. Fleischmann from Metasonic)',2,'');

INSERT INTO `seminar` VALUES (610,'2014-03-20','14:00','Robert Recorde Room','Haakon Robbestad Gylterud','http://people.su.se/~hrobb/','Stockholm University','','Univalent Multisets','Multisets, like sets, consist of elements and the order of appearance of these elements is irrelevant. What distinguishes multisets from sets is the fact that number of occurrences of an element matters. In this talk I will show how one may capture this intuition in Martin-Löf Type Theory.\r\n\r\nFirst, I will  present a technical result on the identity types of W-types in type theory (without the Univalence Axiom). In light of this result I will give an analysis of the underlying type of Aczel''s model of Constructive Zermelo Fraenkel set theory (CZF) in presence of the Univalence Axiom. The conclusion is that Aczel''s type, considered with the identity type as equality, consists of iterative, transfinite multisets.\r\n',2,'');

INSERT INTO `seminar` VALUES (613,'2014-05-29','14:00','Robert Recorde Room','Marcelo Fiore','http://www.cl.cam.ac.uk/~mpf23/','University of Cambridge','','Algebraic Theories and Control Effects','I will start by analysing the second-order equational theory of substitution algebras [1] as a computational effect, and therein give an interpretation of substituting as a code-jumping mechanism [2].  Subsequently, I will introduce more general second-order equational theories of inception algebras, considering examples both from logic and computation to which I will give computational interpretations as further programming control effects.\r\n\r\n[1] M Fiore, G Plotkin and D Turi (1999).  Abstract syntax and variable binding.  \r\n<http://www.cl.cam.ac.uk/~mpf23/papers/Types/binding.ps.gz>\r\n\r\n[2] M Fiore and S Staton (2014).  Substitution, jumps, and algebraic effects.\r\n<http://www.cl.cam.ac.uk/~mpf23/papers/Semantics/subeff.pdf>\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (612,'2014-04-03','14:00','Robert Recorde Room','Jean-Jose Razafindrakoto','','Swansea University','','Provably Total Search Problems in Fragments of Bounded Arithmetic Below Polynomial-time','',2,'');

INSERT INTO `seminar` VALUES (611,'2014-04-02','15:00','Robert Recorde Room','Hideki Tsuiki','http://www.i.h.kyoto-u.ac.jp/~tsuiki/index-e.html','Kyoto University','','Dyadic subbases derived from dynamical systems','For computation over real numbers and more generally over topological spaces, we need to consider two things. One is that each point is represented as an infinite data, and the other thing is that the space itself has a connected topological structure.\r\nIn this talk, we first present an approach to real number computation based on modified Gray expansion. With this approach, the unit interval is represented in the space of sequences with bottoms, and such a sequence is input and output by an IM2-machine, which make multiple-head indeterministic stream access to the tapes. \r\nThis expansion is defined through the dynamical system of the tent function and thus it has a recursive structure which enables recursive function definitions for IM2-machines.\r\nNext, we study its generalizations to computation over compact Hausdorff spaces in general and consider requirements on dynamical systems so that it induces expansions suitable for such recursive function definitions.\r\nFinally, we give characterization of such dynamical systems for the two-dimensional case.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (615,'2014-06-10','14:00','Access Grid Room','Neil Sculthorpe','http://www.cs.swan.ac.uk/~csnas/','Swansea University','','The Constrained-Monad Problem','In Haskell, there are many data types that would form monads were it not for the presence of type-class constraints on the operations on that data type.\r\nThis is a frustrating problem in practice, because there is a considerable amount of support and infrastructure for monads that these data types cannot use.  This talk will demonstrate that a monadic computation can be restructured into a normal form such that the standard monad class can be used.\r\nThe technique is not specific to monads --- it can also be applied to other structures, such as applicative functors.  One significant use case for this technique is Domain Specific Languages, where it is often desirable to compile a deep embedding of a computation to some other language, which requires restricting the types that can appear in that computation.\r\n\r\n\r\nhttp://www.cs.swan.ac.uk/~csnas/papers_and_talks/constrained-monad-problem.pdf\r\n',2,'');

INSERT INTO `seminar` VALUES (614,'2014-06-20','14:00','Board Room','Cliff Jones','http://homepages.cs.ncl.ac.uk/cliff.jones/','Newcastle University','','Historical notes on formal language descriptions','This talk looks at the evolution of ways of recording the semantics of programming languages. Starting in the early 1960s, an attempt is made to look at the motivation -- as well as the details -- of the major efforts. This work is being undertaken as part of the PLanCompS project and should result in both a historical source paper and indexed versions of several ALGOL 60 descriptions.',2,'');

INSERT INTO `seminar` VALUES (616,'2014-07-07','14:00','Robert Recorde Room','Stuart MacDonald','http://www.swansea.ac.uk/staff/law/stuartmacdonald/','Swansea University','','The Cyberterrorism Project','The Cyberterrorism Project (www.cyberterrorism-project.org) is a multidisciplinary research project that examines a range of terrorists’ online activities and questions of response. It was established at Swansea University in 2011 by researchers from Law, Politics and Engineering, and has already published a number of research outputs and hosted international symposia. The project has also developed partnerships with Universities across the UK and Europe (in Norway, France, the Netherlands, Spain, Switzerland, Macedonia and Turkey) and beyond (Canada, Australia and the US) as well as other organisations including the Home Office, NATO’s Centre of Excellence on Defence Against Terrorism and the US Office for Naval Research Global. This seminar will begin by providing an overview of the project’s ethos and an outline of its research activities to date. The remainder of the seminar will present the project’s future research agenda and explore ideas and suggestions for potential future collaborations.\r\n\r\nhttp://www.cyberterrorism-project.org/activities/',2,'');

INSERT INTO `seminar` VALUES (617,'2014-10-28','15:00','Video Conferencing Room','Ross Duncan','http://personal.strath.ac.uk/ross.duncan/','University of Strathclyde','','Quantum Computation in (almost) any Category:  an Introduction to the ZX-calculus','As everyone knows by now, quantum computers are going revolutionise everything.  However the features that make them powerful also make them difficult to analyse in our conventional frameworks.  Can category theory help?  Yes!  In this talk I’ll show how quantum theory can be “reconstructed” in any category having certain structural features, and present the ZX-calculus, a graphical presentation of one such category which can be used to verify concrete quantum protocols and algorithms.  It is a good demonstration of how an abstract point of view can give a handle on problems which are difficult to treat using standard techniques.',2,'');

INSERT INTO `seminar` VALUES (618,'2014-10-16','12:00','Robert Recorde Room','Bashar Igried','http://www.swansea.ac.uk/compsci/postgraduate/','Swansea University','','Modelling and Verification of RBC Handover Using CSP ','This paper proposes the modelling and veri&#64257;cation of the RBC/RBC Handover using the process algebra communicating sequential processes (CSP). We then use the model checker FDR2 to check if it is free from Deadlock and Livelock. ',2,'');

INSERT INTO `seminar` VALUES (619,'2014-12-04','16:00','Board Room','Georg Moser','http://cl-informatik.uibk.ac.at/users/georg/','University of Innsbruck','','Amortised Resource Analysis and Typed Polynomial Interpretations','We  will present  a novel resource  analysis for  typed term rewrite  systems based  on a  potential-based type  system. This  type system  gives  rise to  polynomial  bounds  on the  innermost  runtime complexity. We relate the thus obtained amortised resource analysis to polynomial interpretations  and obtain  the perhaps  surprising result that whenever a rewrite system R  can be well-typed, then there exists a polynomial  interpretation that  orients R. For this  we adequately adapt the standard  notion of polynomial interpretations  to the typed setting.\r\n\r\nThis is joint work with Martin Hofmann.\r\n',2,'');

INSERT INTO `seminar` VALUES (621,'2014-12-04','12:00','Board Room','Thomas Powell','http://cl-informatik.uibk.ac.at/users/tpowell/','University of Innsrbuck','','The complexity of term rewrite systems','Term rewrite systems form a powerful abstract model of computation, which can be used to analyse real-world programming languages. In this talk I will focus on the development of methods to obtain complexity bounds on term rewrite systems. Rather than presenting completed work, I will describe some new ideas and directions in which I feel that progress could be made. In particular I shall discuss the application of proof interpretations to automatically extract complexity bounds from termination proofs, and will also talk about notions of complexity for higher-type rewrite systems. ',2,'');

INSERT INTO `seminar` VALUES (620,'2014-12-11','16:00','Video Conferencing Room','Ekaterina Komendantskaya','http://staff.computing.dundee.ac.uk/katya/','University of Dundee','','Automated theorem proving, structurally.','In constructive proof theory, proving that a proposition A has a proof in the context Gamma amounts to showing that type A is inhabited by a proof p in the context Gamma, namely it amounts to constructing p. This principle underlies most modern interactive theorem provers, e.g. Coq or Agda.\r\n\r\nFirst-order automated theorem proving, in contrast, has much weaker, if any, support for capturing structural (constructive) properties of proofs. To prove that a proposition A follows from a logic program Gamma, the algorithm of SLD-resolution should derive a contradiction from assumption that A is false. The proof structure remains irrelevant in this decision procedure, as long as resolution algorithm succeeds in finding a contradiction.\r\n\r\nThe resolution approach has advantages, the main of which is efficient proof automation. However, neglecting proof structure comes at a price. It is extremely hard to analyse structural properties of programs. One striking example is the fact that in 40 years since introduction of logic programming, the community has never reached a consensus on the notion of universal  termination of logic programs, let alone semi-deciding that property. In contrast, universal termination of Coq programs can be  semi-decided by  imposing the structural recursion check. In logic programming we can only talk about termination of individual SLD-derivations, for goals of certain kinds, so we can only work with various forms of existential termination.\r\n\r\nIn this talk, I will show how the recent coalgebraic semantics of logic programming inspired a new structural approach to untyped theorem proving. Structural automated proving is the analogue of constructive approach but realised in the untyped first-order setting. In particular, it allows to formulate a new general theory of universal productivity and coinduction in logic programming for the first time.\r\n\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (622,'2015-01-22','15:00','Board Room','Graham Hutton','http://www.cs.nott.ac.uk/~gmh/','University of Nottingham','','Calculating Correct Compilers','In this talk we present a new approach to the problem of calculating compilers. In particular, we develop a simple but general technique that allows us to derive correct compilers from high-level semantics by systematic calculation, with all the required compilation machinery falling naturally out of the calculation process. The approach is based upon the use of standard equational reasoning techniques, and has been applied to calculate compilers for a wide range of language features and their combination.  The talk will explain the basic ideas using a small example language, and is aimed at a general audience.\r\n\r\nSpeaker Bio: Graham Hutton is Professor of Computer Science at the University of Nottingham, where he co-leads the Functional Programming Lab.  He is an editor of the Journal of Functional Programming, member of IFIP WG 2.1 on Algorithmic Languages and Calculi, and has served as Vice-Chair of the ACM Special Interest Group on Programming Languages and Steering Committee Chair of the International Conference on Functional Programming.  His research interests are in developing simple but powerful techniques for writing and reasoning about programs, by recognising and exploiting their underlying mathematical structure.  His book Programming in Haskell was published by Cambridge University Press in 2007.\r\n',2,'');

INSERT INTO `seminar` VALUES (623,'2015-03-13','15:00','Board Room','Nicola Gambino','http://www1.maths.leeds.ac.uk/~pmtng/','University of Leeds','','An introduction to Univalent Foundations of Mathematics','This talk will give an introduction to the Univalent Foundations of Mathematics programme, formulated by the Fields Medallist Vladimir Voevodsky around 2009, which seeks to develop a new approach to the foundations of mathematics on the basis of dependent type theories extended with new axioms inspired from topology. In particular, I will explain Voevodsky’s Univalence Axiom and illustrate how propositions and sets are treated in Univalent Foundations. No prerequisites of topology will be assumed, but some familiarity with dependent type theory may be helpful.',2,'');

INSERT INTO `seminar` VALUES (624,'2015-03-26','14:00','Robert Recorde Room','Samuel Buss','http://www.math.ucsd.edu/~sbuss/','University of California','','Complexity of propositional proofs: some theory and examples.','We discuss the problem of separating Frege and extended Frege proof systems.  These are \"textbook\" proof systems for propositional logic based on modus ponens as the only rule of inference.  Open questions about these systems are closely related to problems in computational complexity about formula and circuit complexity, as well to problems in proof search. Recent results by several researchers have given a number of unexpected examples of short Frege proofs. This includes new Frege proofs of the pigeonhole principle (!) and a generalization known as the Kneser-Lovasz coloring principle, new proofs of Frankl''s theorem, and new proofs of matrix identities. The new Kneser-Lovasz proof is direct and simple, and avoids the combinatorial algebraic geometry implicit in prior proofs. This talk will provide an introduction to Frege proofs and their complexity, and the new proofs of the pigeonhole principle and the Kneser-Lovasz theorem which can be formalized as short (quasipolynomial size) Frege proofs. Part of this is joint work with James Aisenberg and Maria Luisa Bonet.',2,'');

INSERT INTO `seminar` VALUES (625,'2015-06-15','14:00','Robert Recorde Room','Irina Marucia','','Swansea University, formerly VERIMAG/University of Grenoble','','Inferring Memory Policies from the Formal Language Semantics','In this work we propose an approach to the analysis of formal language\r\nsemantics. We target memory policies, namely, whether the formal specification\r\nunder consideration follows a particular standard when defining how the\r\nlanguage constructs work with the memory. More specifically, we consider Maude\r\nspecifications of formal programming language semantics and we investigate\r\nthese specifications at the meta-level in order to identify the memory\r\nelements (e.g., variables and values) and how the language syntactic\r\nconstructs employ the memory and its elements. The current work is motivated\r\nby previous work on generic slicing in Maude, in the pursuit of making our\r\ngeneric slicing as general as possible. In this way, we integrate the current\r\ntechnique into an existing implementation of a generic semantics-based program\r\nslicer.\r\n',2,'');

INSERT INTO `seminar` VALUES (626,'2015-06-16','16:00','Robert Recorde Room','Anton Setzer','','Swansea University','','How to reason informally coinductively','In our article [1] we introduced the representation of final\r\ncoalgebras, which correspond to non-well-founded data\r\nstructures, as defined by their elimination rules rather\r\nthan by their introduction rules.\r\n\r\nWhen determined by their introduction rules, elements of\r\nfinal coalgebras are given by possibly non-well-founded many\r\napplications of the constructors. For instance a stream is\r\ngiven by an infinite application of the cons operation, cons\r\nn 1 (cons n 2 (cons n 3 · · · )). Then increasing stream\r\nstarting with n is given as inc n = cons n (inc (n + 1))\r\nwhich reduces to inc n = cons n (cons (n + 1) (cons (n + 2)\r\n(· · · ))). The problem is that this results in\r\nnon-normalisation and proper infinite terms.\r\n\r\nWhen defined by their introduction rules, a coalgebra is\r\ngiven by the result of applying destructors (eliminators to\r\nit). For instance a stream is given by applying the\r\noperations head : Stream ? N and tail : Stream ? Stream to\r\nit. As an example we have head (inc n) = n and tail (inc n)\r\n= inc (n + 1). The problem of non-normalisation disappears\r\nunder certain restrictions, for instance inc n is in normal\r\nform, unfolding its infinite nature requires repeated\r\napplications of tail to it.\r\n\r\nCoalgebras are given as weakly final or as final coalgebras\r\nfor a functor F. For instance the set of streams is given as\r\na final coalgebra for the functor F : Set ? Set, where Set\r\nis the category of sets, with object part F(X) = N × X. This\r\nmeans that there exists a function Stream ? F(Stream) (which\r\nis just head, tail , and for any other coalgebra f : X ?\r\nF(X) there exists a unique g : X ? Stream such that\r\nF(g) o f = <head,tail> o g\r\n\r\nFor weakly final coalgebras the condition on the uniqueness\r\nof g is omitted.\r\n\r\nThe principle of final coalgebras is equivalent to the\r\nprinciple of guarded recursion together with the fact that\r\nbisimilarity implies equality. Bisimilarity is in itself an\r\nexample of an indexed coalgebra, in case of Stream we have\r\nBisim : Stream × Stream ? Set. Therefore iteration over\r\nBisim allows to show equality over Stream and other final\r\ncoalgebras. This principle amounts to a coinduction\r\nprinciple over these coalgebras.\r\n\r\nIn this talk we will discuss how to reason using this\r\ncoalgebra principle informally, rather than referring to\r\nformal schemes or the existence of a bisimulation\r\nrelation. This is similar to the way we reason about\r\ninductive data types informally rather than referring to\r\nthem being defined as largest fixed points or to formal\r\ninduction schemes. We will apply this to proving\r\nbisimilarity of elements of process algebras.\r\n\r\nReferences\r\n[1] Andreas Abel, Brigitte Pientka, David Thibodeau, and\r\n    Anton Setzer. Copatterns: Programming infinite\r\n    structures by observations. In Roberto Giacobazzi and\r\n    Radhia Cousot, editors, Proceedings  of the 40th annual\r\n    ACM SIGPLAN-SIGACT Symposium on Principles of\r\n    Programming Languages, POPL ’13, pages 27–38, New York,\r\n    NY, USA, 2013. ACM.\r\n',2,'');

INSERT INTO `seminar` VALUES (627,'2015-08-21','15:30','Board Room',' Fredrik Nordvall Forsberg','','University of Strathclyde','','Church encodings and naturality',' Church encodings can be used to construct weakly initial algebras in\r\n impredicative type systems such as System F or the Calculus of\r\n Constructions. In the latter, we can also ask whether the induction\r\n principle for the data type is derivable, but a result by Herman\r\n Geuvers says that this is never the case, no matter which encoding is\r\n used. However, if we add identity types to the (extensional) Calculus\r\n of Constructions, this changes: by cutting down the Church encoding\r\n to only the \"natural transformations\", we can construct strongly\r\n initial algebras of arbitrary (even non-strictly positive) functors.\r\n\r\n I''ll give an introduction to impredicative encodings, and then\r\n consider a baby version of the above result, and how it can be\r\n extended to intensional type theories.\r\n',2,'');

INSERT INTO `seminar` VALUES (630,'2015-10-16','15:30','Robert Recorde Room','Xu Wang','','Swansea University, formerly University of Oxford','','From compatibility game to realisability game: synthesis made simple  on timed interface automata','This is the second part of our talk on the synthesis of timed\r\ninterface automata. We start with the interface synthesis based on\r\ncompatibility game. Then we motivate the game of realisability, which\r\narise out of an anomaly in time, and demonstrate that its duality with\r\ncompatibility can give rise a surprisingly simple theory on advanced\r\ntimed synthesis, i.e. quotient and conjunction synthesis.',2,'');

INSERT INTO `seminar` VALUES (629,'2015-10-02','15:30','Robert Recorde Room',' Xu Wang','','Swansea University, formerly University of Oxford','','The story of two games: how to synthesise timed interface automata','Synthesis of quantitative interfaces for components of cyber-physical systems\r\nis an important research problem. This problem in its real-time case has been\r\npreviously tackled in the timed interface [2002] and timed specification\r\n[2010] theories, where major restriction has to be imposed. In this talk we\r\nshow that a new theory, based a new timed interface/game model, can provide an\r\nelegant solution to the problem without sacrificing generality. A key insight\r\nof our theory lies in the discovery of a duality between the realisability and\r\ncompatibility games on timed interface automata. We envisage similar\r\ntechniques are also applicable to probabilistic and hybrid systems.\r\n',2,'');

INSERT INTO `seminar` VALUES (631,'2015-10-27','13:15','Callahan 222 (via 218)','Guillaume Munch-Maccagnoni','','University of Cambridge','','Polarised realizability structures, models, and depolarisation','Polarisation describes the presence of an evaluation order, and is\r\ncharacterised denotationally by a non-associativity of compositions.\r\nWe recently proposed a polarised, Curry-style approach to the lambda-calculus\r\nwith extensional sums, in correspondence with polarised intuitionistic\r\nlogic. We suggested that associativity of composition in this context\r\nshould not be seen as a syntactic axiom, but as an emergent property\r\nakin to termination. Traditionally, issues with sums in denotational\r\nsemantics have rather been considered to be with extensionality than\r\nwith the associativity. This will be explained in an introductory fashion in\r\na first part.\r\n\r\nIn a second part, I will more formally relate the termination in the\r\nlambda-calculus with sums to depolarisation, i.e. associativity of\r\ncomposition, or more familiarly the fact that the order of evaluation\r\ndoes not matter. First, a general setting of polarised realizability\r\nstructures for polarised calculi with or without control operators is developed.\r\nThen, a general technique to build observational models from these\r\nstructures is explained. Finally, under broad conditions, the observational\r\nmodels that the non-associative syntactic structure gives rise to satisfy\r\nthe associativity of composition (and are therefore cartesian closed\r\ncategories with binary co-products). I will sketch an analogy between\r\nintuitionistic depolarisation and parametricity.\r\n',2,'');

INSERT INTO `seminar` VALUES (632,'2015-11-05','14:00','The Board Room','Jan Bergstra','','University of Amsterdam','','Meadows and fractions','Meadows are field-like structures with a division operator made total by haven division by zero resulting in zero. I will formally introduce meadows, survey recent results about these and in particular I will outline a theory of fractions based on meadows.',2,'');

INSERT INTO `seminar` VALUES (633,'2015-12-10','14:00','Room 504 ','Magne Haveraaen','','University of Bergen','','Specifying software the Magnolia way','Magnolia is an experimental programming language with a module system built upon the theory of institutions. Institution theory identifies signatures (declarations), concepts (axiomatic specifications), programs (models), and satisfactions (relating programs to concepts) as the units of modularity. Module reuse follows from signature morphisms (transformations of declarations). Magnolia implementations are programs parameterised by signatures (generic programming). An extension of the satisfaction relates implementations to concepts. Data abstraction is achieved by explicit internalisation of data invariants and congruences.\r\n\r\nThe presentation will cover the basic features, or lack thereof, of Magnolia, and the ensuing implications for software development, software security and reliability.',2,'');

INSERT INTO `seminar` VALUES (634,'2016-01-19','14:00','Robert Recorde Room','Margarita Korovina','','A.P. Ershov Institute of  Informatics Systems, Novosibirsk','','Formal Verification of Safety-Critical Systems','In this talk we present ongoing research which is aimed at creating a logical framework for  formal verification of definable dynamical systems. We address reachability problem, i.e., whether trajectories of the dynamical systems reach safe/unsafe regions from initial regions. The key idea of our approach is based on computing combinatorial types of trajectories.  We  show how it could be done using cylindrical cell decomposition for polynomial and Pfaffian dynamics.\r\n',2,'');

INSERT INTO `seminar` VALUES (635,'2016-01-20','15:00','Robert Recorde Room','Margarita Korovina','','A.P. Ershov Institute of  Informatics Systems, Novosibirsk','','Complexity for Partial Computable Functions over Computable  Perfect Polish Spaces','In the framework of effectively enumerable  topological spaces we introduce the notion of a partial computable function.  We show that the class of partial computable functions is closed under composition and  the real-valued partial computable functions defined on a computable perfect  Polish spaces have  a principal computable numbering. With respect  to the principal computable numbering  of the real-valued partial computable functions we investigate complexity of important problems  such as totality and root existence. It turns  out that  that for some problems  the corresponding complexity  does not depend on the choice of Polish space while for other ones the corresponding choice plays a crucial role.\r\n',2,'');

INSERT INTO `seminar` VALUES (636,'2016-01-20','16:00','Robert Recorde Room','Achim Jung','','University of Birmingham','','On the sobriety of domains','There are two ways in which a domain (in the sense of Dana Scott) may arise from countable data: The classic way is via order-theoretic approximation inside the domain, and leads to the notion of algebraic and continuous domains. Alternatively, one can view a domain as arising from the lattice of predicates that may be formulated for a data type. This latter approach was pioneered and developed by Samson Abramsky in his Domain Theory in Logical Form. I will explain these two approaches and then present an example that illustrates some of the subtlety that we may observe with the latter.\r\n',2,'');

INSERT INTO `seminar` VALUES (637,'2016-03-17','15:00','The Board Room','Nao Hirokawa','','JAIST, Naomi, Kanazawa','','Basic Normalization','The Normalization Theorem (O''Donnell 1977) states that for every left-normal orthogonal rewrite system, the leftmost outermost strategy reduces any term to the normal form if it exists.  Although the theorem ensures the normalization property of important systems such as Combinatory Logic, the left-normality condition rules out most of functional programs.  We revisit the problem to seek a solution for normalization of the leftmost outermost strategy. This work is based on joint work with Aart Middeldorp and Georg Moser.\r\n',2,'');

INSERT INTO `seminar` VALUES (638,'2016-02-25','15:00','Robert Recorde Room','Oliver Kullmann','','Swansea University','','Today a theory of good \"SAT representations\"','\"Encoding\" a problem as a SAT problem, that''s now a \"standard\" method, due to decent SAT solvers available. But what does it really mean, to represent a problem in propositional logic? As experience shows, the representation can be crucial. Some fragments of a theory of \"good SAT representations\", based on complexity measures for resolution, will be discussed in my talk (at a basic level).',2,'');

INSERT INTO `seminar` VALUES (639,'2016-03-03','15:00','The Board Room','Alison Jones','','Swansea University','','Extracting Monadic Parsers from Proofs','This talk outlines a proof-theoretic approach to developing correct and terminating monadic parsers. Using modified realizability, we extract formally verified and terminating programs from formal proofs. By extracting both primitive parsers and parser combinators, it is ensured that all complex parsers built from these are also correct, complete and terminating for any input. We demonstrate the viability of our approach by means of two case studies: we extract (1) a small arithmetic calculator and (2) a non-deterministic natural language parser. The work is being carried out in the interactive proof system Minlog.',2,'');

INSERT INTO `seminar` VALUES (640,'2016-03-11','15:00','The Board Room','David Chisnall','','Cambridge University','','Hardware-enforced memory safety for C (is hard)','The C specification is carefully designed to permit a variety of different implementations of memory, including those that use a fully copying garbage collector. Unfortunately, the range of behaviour permitted by the specification is of little relevance to people wishing to run the billions of lines of existing C code, much of which depends on implementation-specific (and undefined) behaviour.  These include the ability to compare pointers to different objects, to cast pointers to integers, to construct pointers beyond the end of an object, and many more examples.\r\n\r\nWe originally designed the CHERI CPU (currently an FPGA-based softcore) to support coarse-grained in-process compartmentalisation with cheap sharing with a capability-oriented view on virtual memory.  In this model, all memory must be access via a valid, unforgeable, reference (a memory capability).  We then attempted to define a C compilation target where all pointers were represented by capabilities, as opposed to integers in most conventional C implementations.  This talk will discuss the various challenges we encountered and the gap between a memory safe C implementation that conforms to the specification and works for some simple programs, and a memory-safe C implementation that can handle real-world C code.\r\n\r\nThis talk will include material first presented at ASPLOS 2015 in the paper ''Beyond the PDP-11: Architectural Support for a Memory-Safe C Abstract Machine’.\r\n',2,'');

INSERT INTO `seminar` VALUES (641,'2016-04-12','15:00','Robert Recorde Room','Olaf Beyersdorff','','Leeds University','','Proof Complexity of Quantified Boolean Formulas','The main aim in proof complexity is to understand the complexity of theorem proving. Arguably, what is even more important is to establish techniques for lower bounds, and the recent history of computational complexity speaks volumes on how difficult it is to develop general lower bound techniques. Understanding the size of proofs is important for at least two reasons. The first is its tight relation to the separation of complexity classes: NP vs. coNP for propositional proofs, and NP vs. PSPACE in the case of proof systems for quantified boolean formulas (QBF). The second reason to study lower bounds for proofs is the analysis of SAT and QBF solvers: powerful algorithms that efficiently solve the classically hard problems of SAT and QBF for large classes of practically relevant formulas.\r\n\r\nIn this talk we give an overview of the relatively young field of QBF proof complexity. We explain the main resolution-based proof systems for QBF, modelling CDCL and expansion-based solving. In the main part of the talk we will give an overview of current lower bound techniques (and their limitations) for QBF systems. In particular, we exhibit a new and elegant proof technique for showing lower bounds in QBF proof systems based on strategy extraction. This technique provides a direct transfer of circuit lower bounds to lengths of proofs lower bounds. \r\n\r\n',1,'');

INSERT INTO `seminar` VALUES (642,'2016-04-12','15:00','Robert Recorde Room','Olaf Beyersdorff','','Leeds University','','Proof Complexity of Quantified Boolean Formulas','The main aim in proof complexity is to understand the complexity of theorem proving. Arguably, what is even more important is to establish techniques for lower bounds, and the recent history of computational complexity speaks volumes on how difficult it is to develop general lower bound techniques. Understanding the size of proofs is important for at least two reasons. The first is its tight relation to the separation of complexity classes: NP vs. coNP for propositional proofs, and NP vs. PSPACE in the case of proof systems for quantified boolean formulas (QBF). The second reason to study lower bounds for proofs is the analysis of SAT and QBF solvers: powerful algorithms that efficiently solve the classically hard problems of SAT and QBF for large classes of practically relevant formulas.\r\n\r\nIn this talk we give an overview of the relatively young field of QBF proof complexity. We explain the main resolution-based proof systems for QBF, modelling CDCL and expansion-based solving. In the main part of the talk we will give an overview of current lower bound techniques (and their limitations) for QBF systems. In particular, we exhibit a new and elegant proof technique for showing lower bounds in QBF proof systems based on strategy extraction. This technique provides a direct transfer of circuit lower bounds to lengths of proofs lower bounds. \r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (643,'2016-04-29','14:00','Board Room','Grant Malcolm','','Liverpool University','','Structures of Transition Systems','',2,'');

INSERT INTO `seminar` VALUES (644,'2016-07-19','14:00','Faraday Lecture Theatre J','Adrian R. D. Mathias','','ERMIT, Universitie de la Reunion','','A role for well-foundedness in symbolic dynamics','Lluis Alseda, of the Universitat Autonoma de Catalunya, and his co-workers formulated in 1993 some problems in topological dynamics concerning continuous functions and omega-limit sets, and involving iterations and ordinals. As a set theorist visiting Barcelona, my interest was aroused.\r\n\r\nIn this talk, I shall show how the Alseda problems in dynamics translate to questions about the well-foundedness of certain simply-definable trees, thus allowing classical results from descriptive set theory to be applied.\r\n\r\nAn unexpected aspect was that although the iterations concerned resembled the Cantor-Bendixson iterations which always stop at a countable stage, the Alseda iterations proved in some instances to continue till the first uncountable ordinal.\r\n\r\nThe links to the PDF abstract and handout of the talk are listed below:\r\nhttps://www.dropbox.com/s/w9pbpdgi12lflz5/swanabst.pdf?dl=0\r\nhttps://www.dropbox.com/s/c68t0jnuhzkjv50/swanshortabst.pdf?dl=0\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (645,'2016-10-20','15:00','Room 909 (Talbot Lower Ground)','Jens Blanck','','Swansea University','','Implementing Computable Analysis','A tutorial on how to compute with uncountable data.',2,'');

INSERT INTO `seminar` VALUES (646,'2016-11-10','15:00','Board Room (Faraday Tower)','Bernd-Holger Schlingloff','','Humboldt-Universität zu Berlin','','Collaborative Embedded Systems – A Case Study','A collaborative embedded systems (CES) is an intelligent agent in a cyber-physical system which cooperates with others by negotiation to fulfill a common task. In this paper, we consider autonomous transport robots as CES. These robots are used in production environments like factories and storage halls to realize the flow of materials within the production process.\r\n\r\nWe describe the software hierarchy of the agents with self-localization, route planning and job scheduling. Then we discuss implementation strategies and possible benefits of a collaborative approach. Finally, we report on our modelling of the system for simulation and verification.\r\n\r\n',2,'');

INSERT INTO `seminar` VALUES (647,'2017-01-10','11:00','CoFo Seminar Room, Talbot Building, Room 909 (Lower Ground)','Peter Mosses','http://www.cs.swansea.ac.uk/~cspdm/','Swansea University','http://www.swansea.ac.uk/compsci/','SIS, a semantics implementation system','In the 1970s, I developed SIS, a system for executing programs based on their denotational semantics. Its implementation involved partial evaluation of lambda-notation. In this talk, I recall the development of SIS, and relate SIS to the tool support for the component-based approach to semantics proposed by the PLanCompS project.',1,'http://www.cs.swansea.ac.uk/~cspdm/images/PDM2013-150x200.jpg');

INSERT INTO `seminar` VALUES (648,'2017-06-16','15:00','Board Room (Faraday 314)','John Plessis','','Swansea University','','Reducing Pilot Error: Automate or Cooperate?','Over the last three decades there has been a rapid increase in flight deck automation. This has resulted in pilots becoming systems managers attempting to monitor mode-rich systems that possess both high levels of autonomy and authority. Consequently, the ability of the pilot to maintain situational awareness has become increasingly complex, expecially when the agency of the automation enables it to be both silent and powerful. It has been arguedthat increasing the level of automation is the means by which pilot error is reduced. However, a key question remains: what constitutes a pilot error? This talk will explore pilot error in terms of a more constructivist approach whereby error is explored systematically rather than casually - it is about uncovering systematic patterns whereby the successful construction of safety degrades. Using this constructivist view of pilot error, it will be suggested that increasing pilot automation co-operation, rather than simply increasing automation, may provide a useful way forward in reducing pilot error.\r\n',2,'');

INSERT INTO `seminar` VALUES (649,'2017-06-29','16:00','Board Room (Faraday 314)','Jean Razafindrakoto','','Swansea University','','Total Search Problems in Bounded Arithmetic and Improved Witnessing','We define a new class of total search problems as a subclass of Megiddo and Papadimitriou''s class of total $\\NP$ search problems, in which solutions are verifiable in $\\AC^0$. We denote this class $\\forall\\exists\\AC^0$. We show that all total $\\NP$ search problems are equivalent wrt. $\\AC^0$-many-one reductions to search problems in $\\forall\\exists\\AC^0$. Furthermore, we show that $\\forall\\exists\\AC^0$ contains well-known problems such as the Stable Marriage and the Maximal\r\nIndependent Set problems. We introduce the class of Inflationary Iteration problems in $\\forall\\exists\\AC^0$ and show that it characterizes the provably total $\\NP$ search problems of the bounded arithmetic theory corresponding to polynomial-time. Cook and Nguyen introduced a generic way of defining a bounded arithmetic theory $\\VC$ for complexity classes $\\C$ which can be obtained using a complete problem. For such $C$ we will define a new class $\\KPT[C]$ of $\\forall\\exists\\AC^0$ search problems based on Student-Teacher games in which the student has computing power limited to $\\AC^0$. We prove that $\\KPT[C]$ characterizes the provably total $\\NP$ search problems of the bounded arithmetic theory corresponding to $\\C$. All our characterizations are obtained via \"new-style\" witnessing theorems, where reductions are provable in a theory corresponding to $\\AC^0$.',2,'');


CREATE TABLE `series` (
  `seriesno` int(11) NOT NULL DEFAULT 0,
  `name` text NOT NULL,
  `preamble` text DEFAULT NULL,
  `pageprefix` text DEFAULT NULL,
  PRIMARY KEY (`seriesno`)
);
INSERT INTO `series` VALUES (1,'Departmental Colloquium','<p>Departmental Colloquia are organised by Computer Science and are given by invited speakers (<a href=\"portraits.php\">portraits</a>). Research teams within the department also organise their own <a href=\"group.html\">seminar series</a>.<br/>','seminars');

INSERT INTO `series` VALUES (3,'Computer Science Algebraic Specification Seminar Series',NULL,'algseminars');

INSERT INTO `series` VALUES (2,'Computer Science Proof, Complexity and Verification Seminar Series',NULL,'pcvseminars');

INSERT INTO `series` VALUES (4,'Theoretical Computer Science',NULL,'tcseminars');

INSERT INTO `series` VALUES (5,'Departmental Seminars',NULL,'deptseminars');

INSERT INTO `series` VALUES (6,'Visual Computing',NULL,'vicseminars');
